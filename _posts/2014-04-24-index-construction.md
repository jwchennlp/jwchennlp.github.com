---
layout: post
title: "索引构建"
modified: 2014-04-24 14:09:41 +0800
tags: [信息检索,索引构建,基于块的索引构建,内存式单遍扫描索引构建]
image:
  feature: abstract-4.jpg
  credit: dargadgetz
  creditlink: http://www.dargadgetz.com/ios-7-abstract-wallpaper-pack-for-iphone-5-and-ipod-touch-retina/
comments: true
share: true
---

索引构建主要是对建立好的词典中的每个词项，构建词项关于文档集合的索引记录表。一般索引构建算法会受硬件设施的制约。    

##硬件基础
----------
构建信息检索系统时，很多决策都依赖于系统所运行的硬件环境。与信息检索系统相关的硬件基本性能参数如下：      

* 系统访问内存中数据的速度比访问硬盘中数据要快的多，访问内存中的一个字节只需要几个时钟周期（大约5×10-9s），从磁盘传输一个字节的时间则长得多（大概2×10-8s）。因此，为了更快的响应速度，我们应该尽可能将数据放在内存中，特别是那种频繁访问的数据。这种将频繁使用的数据放入内存中的机制称为caching（缓存）。    
* 进行磁盘读写时，磁头移动到数据所在的磁道需要一定的时间，该时间称为寻道时间，对典型的磁盘来说平均在5ms左右。寻道过程中并不进行数据的传输。于是，为了时数据传输率最大，连续读取的数据块也应该在磁盘上连续存放。      
* 操作系统往往以数据块为单位进行读写。因此，从磁盘读取一个字节和一个数据块所耗费的时间可能一样多。我们将内存中保存读写块的那块区域称之为缓冲区（buffer）。       
* 数据从磁盘传输到内存是由系统总线而不是处理器来实现的，这以为着在磁盘I/O时处理器仍然可以处理数据。我们可以利用这一点来加速数据的传输过程，比如将数据压缩后存储在磁盘上。假定采用一种高效的解压缩算法的话，那么从磁盘读取压缩数据再解压缩所花时间往往比直接读取未压缩数据所花时间少。       

##基于块的排序索引方法
---------
第一章建立倒排索引时，所有的处理过程都是在内存中完成的。我们将文档一次性读入内存，而后建立文档的词典，并建立词典中的词项的倒排记录表。如果当文档集过大，大到难以一次性读入内存时，上述方法便失效。   

由于内存的不足，我们可以采用磁盘的外部排序的方法（external sorting algorithm）。我们知道读取数据过程中的寻道时间与数据传输相比是十分耗时的，所以我们应该尽量将数据按块的方式存储以减少寻道的次数。BSBI（blocked sort-based indexing algorithm，基于块的排序索引算法）是一种解决的方法。算法实现如下：       
第1步：将文档切分成均匀的若干个部分。     
第2步：对每个部分的词项ID-文档ID对排序。    
第3步：将中间产生的临时排序结果存储在磁盘上。     
第4步：将所有的中间文件合并形成最终结果。   

在第2步中我们将词项用词项id代替，词项id是能代表词项的唯一标识，这样做能提高索引构建效率。

{% highlight python %}      
{% raw %}           
BSBIndex-construction()     
n <- 0      
while(all documents have not been processed)        
do n <- n+1                 
    block <- ParseNextBlock()       
    BSBI-INVERT(block)            
    WriteBlockToDisk(block,fn)      
    MergeBlocks(f1,....,fn;fmerge)      
{% endraw %}             
{% endhighlight %}              

合并时，同时打开所有块对应的文件，内存中维护10个块的读缓冲区和一个为最终合并索引准备的写缓冲区。每次迭代中，利用优先级队列（即堆结构）或者类似的数据结构选择最小的未处理词项id进行处理。读入该词项的倒排记录表进行合并，合并结果返回磁盘中。需要时，再次从文件中读入数据到每个读缓冲区。  

由于该算法主要的时间耗费在排序上，因此其时间复杂度为O（T*logT),其中T是要排序的项目数的上界（即词项ID-文档—ID对的个数），然而，实际的索引构建的时间往往取决与文档温习（ParseNextBlock）和最后合并（MergeBlocks）。

由于我们知道，为了提高索引构建效率，我们将词项映射成词项ID，初始的倒排记录表形式为：     

{% highlight python %}      
    wordi -> doc1|doc2.....|docn                    
{% endhighlight %}          
在进行词项id的映射之后，每个词项ID-文档ID对就是简单的（wid,did）的形式了。这样做为什么能提高效率呢？虽然映射过程需要话费一定的时间，可是映射之后，每个块得到的都是这样的二值对，这样可以以词项ID为主键，以文档ID为次键按照快速排序一类方法进行排序，这样使得倒排记录的构建变得简单。     

##内存式单遍扫描索引构建方法 
------------
BSBI方法需要将词项映射成词项ID，所以必须在内存中维护一个（词项，词项ID）表的数据结构。当对大规模文档来说，这种数据结构的大小将超过内存大小。
SPIMI（single-pass in-memory indexing,内存式单遍扫描索引构建算法）使用词项而不是词项ID作为词典，它将为个块的词典读入磁盘，对于下一个块则采用新的词典。只要硬盘空间足够大，SPIMI就能够索引任何大小的文档集。     

SPIMI算法流程如下所示：      
{% highlight c linenos %}
SPIMI-Invert(token-stream)      
output_file = NewFile()     
dictionary = NewHash()      
while(free memory available)        
do token <- next(token-stream)      
    if term(token) not in dictionary        
        then posting_list = AddToDictionary(dictionary,term(token))     
        else posting_list = GetPostingList(dictionary,term(token))      
        if full(posting_list)       
        then posting_list = DoublePostingList(dictionary,term(token))       
        AddToPostingList(posting_list,dicID(token))     
sorted_term <- SortTerms(dictionary)        
WriteBlockToDisk(sorted_term,dictionary,output_file)        
return output_file      
{% endhighlight %}

####BSBI和SPIMI的区别
BSBI在读入一块内存中的文档内容时，会构建这块文档的词项ID—文档ID对序列，在对序列进行排序后，构建这块文档的倒排索引表，也就是说倒排索引的构建是对读入的整个文件块这个整体。SPIMI当然也是将初始大规模文档划分成等大小的块，并按块读入内存，新建一个初始为空的字典，首先他直接以词项作为词典单位，也就是说在遍历内存中的文档时，对文档进行词条话和词干化后，查看每个词，如果这个词不再字典中，则将词加如词典中，并新建一个关于此词项的倒排记录表，如果词项在字典中存在，则需要在此词项的到拍记录表的基础上进行添加操作。由于实现并不清楚每个词项的倒排记录表的长度，所以初始设定倒排记录表的长度为某个较小的值，当倒排记录表已满时，可以按倍数进行扩展。

SPIMI的倒排记录表是动态增长的，同时立刻就可以实现全体倒排记录表的收集。这样做有两个好处： 

* 由于不需要排序操作，所以处理的速度更快。  
* 由于保留了倒排记录表对词项的归属关系，因此能够节省内存，词项的ID也不需要保存。

SPIMI算法的时间负责度是O（T），因为它不需要对词项ID-文档ID排序，所以操作最多和文档集大小成线性关系。

##分布式索引构建方法
-----------
实际中，文档集合一般相当大，一台计算机很难实现高效的实现索引构建。尤其是对于万维网来说。因此Web搜索引擎通常使用分布式索引构建（distribuction index）算法来构建索引，其索引结果也是分布式的，它往往按照词项或是文档分割后分布在多台计算机上。   

这里介绍的分布式索引构建方法是MapReduce的一个应用。MapReduce是一个分布式的计算框架，它面向大规模计算机集群而设计。集群中有一个主控节点（master node）,主要负责任务在工作节点的分配和重分配。重分配是实现分布式框架的鲁棒性，因为集群在工作当中，可能工作节点会出现故障，这个时候主节点应当能识别这些故障并将故障机器的任务重新分配给其它可工作的工作节点。    
   
一般来说MapReduce会通过键-值对（Key-Value pair）的转换处理，将一个大型的计算问题转换成较小的子问题。在索引构建中，键-值对就是（词项ID,文档ID）。在分布式索引构建中，词项到词项ID的映射同样要分布式进行，因此分布式的索引构建方法要比单机上的索引构建方法复杂的多。一种简单方法就是维护一张高频词到其ID的映射表，并将它复制到所有节点的计算机上，而对低频词则直接使用词项本身。

MapReduce的Map过程将输入的数据片映射成键值对，这个映射过程对英语BSBI和SPIMI算法中的分析任务，执行Map过程的机器也称之为分析器（parser）。每个分析器将输出结果保存在本地的中间文件。

Reduce主要是对中间结果进行合并，形成最终的索引。对每个词项（键值），获取此词项的所有文档集合并构建词项的倒排记录表主要通过倒排器来实现。   

##动态索引构建方法
------------
上述建立索引的方法都是基于静态文档的，在很多情况下，文档都会随着时间动态变化的。那么，当文档更新速度很慢时，我们可以采用定期更新索引的策略。如果文档更新速度很快时，则实时更新索引的方法将十分耗时。

可以采用如下方法实现动态索引的构建，这里我们主要维护两个索引，第一个主索引是对初始的文档集构建的索引，第二个辅助索引是在主索引建立之后随着时间推移，而更新的索引，辅助索引存放在内存中，这样实时检索时通过查询主索引和辅助索引实现。如果是对主索引在未来时间的更新，可以通过一个无效位向量实现，用无效位向量来标致文档的删除，同时在辅助索引中加入此文档的更新，便实现了主索引内容的更新。同时随着时间的推移，辅助索引的容量是不断增大的。当辅助索引长度大一某一值时，我们可以将辅助索引并入到主索引中。

将辅助索引并入主索引的开销主要取决于索引为文件中的存储方式。如果将每个词项对应的倒排记录表存储为一个文件，则此词项的辅助索引和主索引的合并通过简单的将辅助索引扩展到主索引的倒排记录表即可。显示情况是因为文件管理的各种限制，将所有词项的倒排记录表分别存储为文件是不可行的。替代方案是将所有词项的倒排记录表存储为一个大的文件。
     




