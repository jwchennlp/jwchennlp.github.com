<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">My blog</title>
<generator uri="https://github.com/mojombo/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://jwchennlp.github.com/feed.xml" />
<link rel="alternate" type="text/html" href="http://jwchennlp.github.com" />
<updated>2014-06-08T06:43:40-04:00</updated>
<id>http://jwchennlp.github.com/</id>
<author>
  <name>jwchen</name>
  <uri>http://jwchennlp.github.com/</uri>
  <email>hit1093710417@email.com</email>
</author>


<entry>
  <title type="html"><![CDATA[Chinese Word Segmentation]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/chinese-word-segmentation/" />
  <id>http://jwchennlp.github.com/chinese-word-segmentation</id>
  <updated>2014-06-08 06:52:56 UTCT00:00:00-00:00</updated>
  <published>2014-06-08T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;section&quot;&gt;1.介绍&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;通过之前隐马尔可夫模型(HMM)的讲解及其适用问题的分析,对HMM应该有一个大致的认知.同时,我们知道HMM在很多领域都有运用.现在我们具体实现HMM在中文分词中的运用.		&lt;/p&gt;

&lt;p&gt;中文分词 (Chinese Word Segmentation) 指的是将一个汉字序列切分成一个一个单独的词.我们知道,在英文中单词是以空格作为分割符的,而中文中每个字之间都是紧密挨着的,所以中文的分词则要显得困难很多.&lt;/p&gt;

&lt;p&gt;当前的中文分词主要有一下3个方向:&lt;/p&gt;

&lt;p&gt;1.基于规则的分词&lt;/p&gt;

&lt;p&gt;也就是说可以按照某些规则规则去匹配句子中符合某一规范的词,较为常见为构造一个词典,在对句子遍历的过程中,查看词是否出现在句子中.按照扫描方法可以分为正向匹配和逆向匹配.按长度不同可以分为最大匹配和最小匹配.		&lt;/p&gt;

&lt;p&gt;2.基于统计的分词 	&lt;/p&gt;

&lt;p&gt;首先给出大量已经分好词的文本,利用统计机器学习模型学习词划分的规律,从而实现对未知文本的词划分.		&lt;/p&gt;

&lt;p&gt;3.统计和规则相结合的分词&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;2.实现&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这里用到的是&lt;a href=&quot;http://sighan.cs.uchicago.edu/bakeoff2005/&quot;&gt;SIGHAN&lt;/a&gt;里面的语料.&lt;/p&gt;

&lt;p&gt;中文分词问题可以理解为,给定一个句子(S=$s_1s_2…s_n$),我们需要找出最有可能的一个分词策略.如北京市有关部门,理想的分词结果应该是”北京市/有关/部门”.这里需要考虑一个问题,如果采用HMM,未分词的句子是观察状态(O),则隐含状态(S)是什么呢?&lt;/p&gt;

&lt;p&gt;这里我们定义隐含状态的4个类别State={B,E,M,S}:&lt;/p&gt;

&lt;p&gt;B:一个词的开始	
E:一个词的结束		
M:一个词的中间		
S:单字成词		&lt;/p&gt;

&lt;p&gt;这是北京市有关部门的分词结果可以表示为”BMEBEBE”.	&lt;/p&gt;

&lt;p&gt;定义好隐含状态之后,我们发现对每个句子的最有可能的分词策略便是找出最可能的隐含状态序列,这是HMM中讲到的解码(decode)问题.	&lt;/p&gt;

&lt;p&gt;HMM模型定义为一个五元组&lt;script type=&quot;math/tex&quot;&gt;\lambda=(S,O,\pi,a,b)&lt;/script&gt;其中S为隐含状态集合,O为观察状态集合,$\pi$为隐含状态的初始概率,a为隐含状态的转移概率,b为在从隐含状态到观察状态的混淆概率(发射概率).现在要做的就是根据已经表述好的文本语料的出各参数的值.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\pi=P(S)=[p(B),p(E),p(M),p(S)]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a_{ij}=P(s_j｜s_i)=\frac{count(s_i,s_j)}{count(s_i)},1\leq i\leq N-1;N为隐状态长度&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{it}=p(o_t｜s_i)= \frac{count(s_i,o_t)}{count(s_i)},1\leq i\leq N;1\leq t\leq T,T为观察状态长度&lt;/script&gt;

&lt;p&gt;对于已经分好词的预料,对于某一篇文档d={&lt;script type=&quot;math/tex&quot;&gt;o_1o_2,...,o_{n(d)}&lt;/script&gt;},有相应的标注结果&lt;script type=&quot;math/tex&quot;&gt;s_1s_2,...,s_{n(d)}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;根据文档信息和表标注息可以得出预料中某词$o_t$对应于隐状态$s_i$的次数,$count(o_t,s_i)$,当前词对于的隐状态为$s_i$,下一词对应隐状态$s_j$的次数,$count(s_i,s_j)$&lt;/p&gt;

&lt;p&gt;由于文档开始的第一个词隐状态只能是B或者是S,所以只需要计算P(B)和P(S),$P(B)=\frac{count(B)}{count(B)+count(S)}$.&lt;/p&gt;

&lt;p&gt;在计算隐含状态的转移概率时,B-B,B-S,E-E,E-M,M-B,M-S,S-E,S-M都为0,所以只需要计算剩下的8种组合.	&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm11.png&quot; /&gt;&lt;/center&gt;
&lt;!--
|		|B 		|E 		|M 		|S 		|		
|:-----:|:-----:|:-----:|:-----:|:-----:|
|	B	|	0 	|		|		|	0	|
|	E	|		|	0	|	0	|		|
|	M	|	0	|		|		|	0	|
|	S	|		|	0	|	0	|		|	
--&gt;

&lt;p&gt;由于b计算的是隐含状态-观察状态矩阵,首先我们的观察状态集合该如何定义呢?		&lt;/p&gt;

&lt;p&gt;观察状态集合可以理解为字的集合,因为分好词的语料库很难包含所有的字,所以理想状态是用分好词的语料库和待分词的文档集合的所有字构成观察状态集,但是在计数($count(o_t,s_i)$)时只基于分好词的语料库技术.这样将导致那些只出现在待分词文档中的词的混淆概率为0,这样使得在viterbi算法过程中包含此词的句子的$\delta值0$,无法求得隐含序列.&lt;/p&gt;

&lt;p&gt;对于这种情况,可以采用平滑技术进行处理,这里我们采用的是加1平滑,效果更好的可以采用&lt;a href=&quot;http://zh.wikipedia.org/wiki/%E5%9B%BE%E7%81%B5%E4%BC%B0%E8%AE%A1&quot;&gt;good-turing平滑&lt;/a&gt;.所以:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{it}=p(o_t｜s_i)= \frac{count(s_i,o_t)+1}{count(s_i)},1\leq i\leq N;1\leq t\leq T,T为观察状态长度&lt;/script&gt;

&lt;p&gt;在计算好参数{$\pi,a,b$}之后,采用上节实现的viterbi算法求解.采用SIGHAN的评测标准,P=80.3%,R=78.6%,F_1=79.5%	&lt;/p&gt;

&lt;p&gt;如下为部分句子的分词结果:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm12.png&quot; /&gt;&lt;/center&gt;
&lt;!--
|原始句子|分词结果|
|:-----:|:----:|
|中华人民共和国今天成立了|中华人民共和国/今天/成立/了|
|日理万机的周总理|日理/万机/的/周/总理|
|北京市|北京/市|
|北京市有关部门|北京/市有/关部门|
|北京有关部门|北京/有关/部门|
|改判被告人死刑立即执行|改判/被/告人/死/刑立/即/执行|
--&gt;

&lt;p&gt;可以看出来,正常情况的分词效果还是比价理想的.不过当长词(北京市)及长词里面有短词时(北京),分类效果有时会倾向于分成短词,并在后续的分词结果中出错.&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;4.注意的问题&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;正常情况下一个词的混淆概率$p(o_t｜s_i)$应该很小.在viterbi算法中t+1时刻位于隐含状态j的局部概率为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta_t(j) = max_{i \in N}(\delta_{t-1}(i)a_{ij}b_{jo_t})&lt;/script&gt;

&lt;p&gt;可以看出,当长度为N的观察序列的$\delta$值需要累乘N个混淆概率,这很容易使得$\delta$值为0. 这里我们可以用对数的方式来$\log\delta来替代\delta$或者对于一篇文档,我们可以按标点符号进行分割,计算每个分割后的子文档的隐含序列.最后将隐含序列进行累加即可.		&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/chinese-word-segmentation/&quot;&gt;Chinese Word Segmentation&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on June 08, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Hmm Hidden Markov Model_140608165432]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/hmm-hidden-markov-model_140608165432/" />
  <id>http://jwchennlp.github.com/hmm-hidden-markov-model_140608165432</id>
  <published>2014-06-04T00:00:00-04:00</published>
  <updated>2014-06-04T00:00:00-04:00</updated>
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset='utf-8'/&gt;
    &lt;title&gt;2014-06-04-hmm-hidden-markov-model.md—/home/awen/blog/jwchennlp.github.com/_posts&lt;/title&gt;
    &lt;style type=&quot;text/css&quot;&gt;
    body{font-family:Helvetica,arial,sans-serif;font-size:14px;line-height:1.6;padding-top:10px;padding-bottom:10px;background-color:white;padding:30px;color:#333}body&gt;*:first-child{margin-top:0!important}body&gt;*:last-child{margin-bottom:0!important}a{color:#4183c4;text-decoration:none}a:hover{text-decoration:underline}a.absent{color:#c00}a.anchor{display:block;padding-left:30px;margin-left:-30px;cursor:pointer;position:absolute;top:0;left:0;bottom:0}html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td,article,aside,canvas,details,embed,figure,figcaption,footer,header,hgroup,menu,nav,output,ruby,section,summary,time,mark,audio,video{margin:0;padding:0;border:0}kbd{background:#f1f1f1;background:-moz-linear-gradient(#f1f1f1,#ddd);background:-webkit-linear-gradient(#f1f1f1,#ddd);-ms-filter:&quot;progid:DXImageTransform.Microsoft.gradient(startColorstr='#f1f1f1', endColorstr='#dddddd')&quot;;border-radius:2px;border:1px solid #ddd;border-bottom-color:#ccc;border-right-color:#ccc;padding:1px 4px;line-height:10px;font-family:&quot;Helvetica Neue&quot;,Helvetica,Arial,sans-serif}.container{max-width:920px;margin:0 auto 20px auto}#header{background:#fafafa;background:-moz-linear-gradient(#fafafa,#eaeaea);background:-webkit-linear-gradient(#fafafa,#eaeaea);-ms-filter:&quot;progid:DXImageTransform.Microsoft.gradient(startColorstr='#fafafa', endColorstr='#eaeaea')&quot;;border-bottom:1px solid #cacaca;box-shadow:0 1px 0 rgba(255,255,255,0.4),0 0 10px rgba(0,0,0,0.1)}#markup{padding:3px}#markup article{padding-top:30px}.markdown-body{font-size:14px;line-height:1.6}.markdown-body&gt;*:first-child{margin-top:0!important}.markdown-body&gt;*:last-child{margin-bottom:0!important}.markdown-body a.absent{color:#c00}.markdown-body a.anchor{bottom:0;cursor:pointer;display:block;left:0;margin-left:-30px;padding-left:30px;position:absolute;top:0}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{cursor:text;font-weight:bold;margin:20px 0 10px;padding:0;position:relative}.markdown-body h1 .mini-icon-link,.markdown-body h2 .mini-icon-link,.markdown-body h3 .mini-icon-link,.markdown-body h4 .mini-icon-link,.markdown-body h5 .mini-icon-link,.markdown-body h6 .mini-icon-link{color:#000;display:none}.markdown-body h1:hover a.anchor,.markdown-body h2:hover a.anchor,.markdown-body h3:hover a.anchor,.markdown-body h4:hover a.anchor,.markdown-body h5:hover a.anchor,.markdown-body h6:hover a.anchor{line-height:1;margin-left:-22px;padding-left:0;text-decoration:none;top:15%}.markdown-body h1:hover a.anchor .mini-icon-link,.markdown-body h2:hover a.anchor .mini-icon-link,.markdown-body h3:hover a.anchor .mini-icon-link,.markdown-body h4:hover a.anchor .mini-icon-link,.markdown-body h5:hover a.anchor .mini-icon-link,.markdown-body h6:hover a.anchor .mini-icon-link{display:inline-block}.markdown-body h1 tt,.markdown-body h1 code,.markdown-body h2 tt,.markdown-body h2 code,.markdown-body h3 tt,.markdown-body h3 code,.markdown-body h4 tt,.markdown-body h4 code,.markdown-body h5 tt,.markdown-body h5 code,.markdown-body h6 tt,.markdown-body h6 code{font-size:inherit}.markdown-body h1{color:#000;font-size:28px}.markdown-body h2{border-bottom:1px solid #ccc;color:#000;font-size:24px}.markdown-body h3{font-size:18px}.markdown-body h4{font-size:16px}.markdown-body h5{font-size:14px}.markdown-body h6{color:#777;font-size:14px}.markdown-body p,.markdown-body blockquote,.markdown-body ul,.markdown-body ol,.markdown-body dl,.markdown-body table,.markdown-body pre{margin:15px 0}.markdown-body hr{background:url(&quot;/public/github-dirty-shade.png&quot;) repeat-x scroll 0 0 transparent;border:0 none;color:#ccc;height:4px;padding:0}.markdown-body&gt;h2:first-child,.markdown-body&gt;h1:first-child,.markdown-body&gt;h1:first-child+h2,.markdown-body&gt;h3:first-child,.markdown-body&gt;h4:first-child,.markdown-body&gt;h5:first-child,.markdown-body&gt;h6:first-child{margin-top:0;padding-top:0}.markdown-body a:first-child h1,.markdown-body a:first-child h2,.markdown-body a:first-child h3,.markdown-body a:first-child h4,.markdown-body a:first-child h5,.markdown-body a:first-child h6{margin-top:0;padding-top:0}.markdown-body h1+p,.markdown-body h2+p,.markdown-body h3+p,.markdown-body h4+p,.markdown-body h5+p,.markdown-body h6+p{margin-top:0}.markdown-body li p.first{display:inline-block}.markdown-body ul,.markdown-body ol{padding-left:30px}.markdown-body ul.no-list,.markdown-body ol.no-list{list-style-type:none;padding:0}.markdown-body ul li&gt;*:first-child,.markdown-body ol li&gt;*:first-child{margin-top:0}.markdown-body ul ul,.markdown-body ul ol,.markdown-body ol ol,.markdown-body ol ul{margin-bottom:0}.markdown-body dl{padding:0}.markdown-body dl dt{font-size:14px;font-style:italic;font-weight:bold;margin:15px 0 5px;padding:0}.markdown-body dl dt:first-child{padding:0}.markdown-body dl dt&gt;*:first-child{margin-top:0}.markdown-body dl dt&gt;*:last-child{margin-bottom:0}.markdown-body dl dd{margin:0 0 15px;padding:0 15px}.markdown-body dl dd&gt;*:first-child{margin-top:0}.markdown-body dl dd&gt;*:last-child{margin-bottom:0}.markdown-body blockquote{border-left:4px solid #ddd;color:#777;padding:0 15px}.markdown-body blockquote&gt;*:first-child{margin-top:0}.markdown-body blockquote&gt;*:last-child{margin-bottom:0}.markdown-body table{border-collapse:collapse;border-spacing:0}.markdown-body table th{font-weight:bold}.markdown-body table th,.markdown-body table td{border:1px solid #ccc;padding:6px 13px}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{max-width:100%}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame&gt;span{border:1px solid #ddd;display:block;float:left;margin:13px 0 0;overflow:hidden;padding:7px;width:auto}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{clear:both;color:#333;display:block;padding:5px 0 0}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center&gt;span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right&gt;span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right&gt;span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{background-color:#f8f8f8;border:1px solid #eaeaea;border-radius:3px 3px 3px 3px;margin:0 2px;padding:0 5px;white-space:nowrap}.markdown-body pre&gt;code{background:none repeat scroll 0 0 transparent;border:medium none;margin:0;padding:0;white-space:pre}.markdown-body .highlight pre,.markdown-body pre{background-color:#f8f8f8;border:1px solid #ccc;border-radius:3px 3px 3px 3px;font-size:13px;line-height:19px;overflow:auto;padding:6px 10px}.markdown-body pre code,.markdown-body pre tt{background-color:transparent;border:medium none}.codehilite{background:#fff}.codehilite .c{color:#998;font-style:italic}.codehilite .err{color:#a61717;background-color:#e3d2d2}.codehilite .k{color:#000;font-weight:bold}.codehilite .o{color:#000;font-weight:bold}.codehilite .cm{color:#998;font-style:italic}.codehilite .cp{color:#999;font-weight:bold}.codehilite .c1{color:#998;font-style:italic}.codehilite .cs{color:#999;font-weight:bold;font-style:italic}.codehilite .gd{color:#000;background-color:#fdd}.codehilite .gd .x{color:#000;background-color:#faa}.codehilite .ge{color:#000;font-style:italic}.codehilite .gr{color:#a00}.codehilite .gh{color:#999}.codehilite .gi{color:#000;background-color:#dfd}.codehilite .gi .x{color:#000;background-color:#afa}.codehilite .go{color:#888}.codehilite .gp{color:#555}.codehilite .gs{font-weight:bold}.codehilite .gu{color:#aaa}.codehilite .gt{color:#a00}.codehilite .kc{color:#000;font-weight:bold}.codehilite .kd{color:#000;font-weight:bold}.codehilite .kp{color:#000;font-weight:bold}.codehilite .kr{color:#000;font-weight:bold}.codehilite .kt{color:#458;font-weight:bold}.codehilite .m{color:#099}.codehilite .s{color:#d14}.codehilite .na{color:#008080}.codehilite .nb{color:#0086b3}.codehilite .nc{color:#458;font-weight:bold}.codehilite .no{color:#008080}.codehilite .ni{color:#800080}.codehilite .ne{color:#900;font-weight:bold}.codehilite .nf{color:#900;font-weight:bold}.codehilite .nn{color:#555}.codehilite .nt{color:#000080}.codehilite .nv{color:#008080}.codehilite .ow{color:#000;font-weight:bold}.codehilite .w{color:#bbb}.codehilite .mf{color:#099}.codehilite .mh{color:#099}.codehilite .mi{color:#099}.codehilite .mo{color:#099}.codehilite .sb{color:#d14}.codehilite .sc{color:#d14}.codehilite .sd{color:#d14}.codehilite .s2{color:#d14}.codehilite .se{color:#d14}.codehilite .sh{color:#d14}.codehilite .si{color:#d14}.codehilite .sx{color:#d14}.codehilite .sr{color:#009926}.codehilite .s1{color:#d14}.codehilite .ss{color:#990073}.codehilite .bp{color:#999}.codehilite .vc{color:#008080}.codehilite .vg{color:#008080}.codehilite .vi{color:#008080}.codehilite .il{color:#099}
    &lt;/style&gt;
    &lt;style type=&quot;text/css&quot;&gt;
      .markdown-body hr{background:url(&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC&quot;)}
    &lt;/style&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class=&quot;container&quot;&gt;
      &lt;div id=&quot;markup&quot;&gt;
        &lt;article id=&quot;content&quot; class=&quot;markdown-body&quot;&gt;
          &lt;h2&gt;1.介绍&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;隐马尔可夫模型(Hidden Markov Model,HMM)是一种统计模型,用它来描述一个含有未知参数的马尔可夫过程.在模型中包括可观察的参数和隐藏的参数,一般要求解的问题是通过观察到的参数来评估过程中的隐含参数.隐马尔可夫模型在语音识别,中文分词,词性标注,机器翻译等领域都有十分广泛的运用.       &lt;/p&gt;
&lt;h3&gt;模型表示&lt;/h3&gt;
&lt;p&gt;隐马尔可夫模型(HMM)可以用如下的五元组来表示,包括2状态集合和概率矩阵:&lt;/p&gt;
&lt;p&gt;(1).隐含状态S={&lt;mathjax&gt;$s_1,s_2,...,s_n$&lt;/mathjax&gt;}       &lt;/p&gt;
&lt;p&gt;隐含状态是马尔可夫模型中所隐含的状态.这些状态无法通过直接观测而得到.     &lt;/p&gt;
&lt;p&gt;(2).可观测状态O={&lt;mathjax&gt;$o_1,o_2,...,o_m$&lt;/mathjax&gt;}              &lt;/p&gt;
&lt;p&gt;可观察状态是马尔可夫模型中可以观测到的状态.(可观察状态数目和隐含状态数目可以不相等).        &lt;/p&gt;
&lt;p&gt;(3).初始状态概率矩阵&lt;mathjax&gt;$\pi$&lt;/mathjax&gt;           &lt;/p&gt;
&lt;p&gt;表示隐含状态在初始时刻t=1时的概率矩阵.初始状态概率矩阵为&lt;mathjax&gt;$\pi=[p(s_1),p(s_2),...,p(s_n)]$&lt;/mathjax&gt;      &lt;/p&gt;
&lt;p&gt;(4).隐含状态的概率转移矩阵&lt;mathjax&gt;$A_{ij}$&lt;/mathjax&gt;   &lt;br&gt;
表示在HMM模型在各个隐含状态之间的转移概率.其中&lt;mathjax&gt;$$A_{ij}=p(s_j｜s_i)$$&lt;/mathjax&gt;表示在t时刻隐含状态为&lt;mathjax&gt;$s_i时,t+1时刻隐含状态为s_j$&lt;/mathjax&gt;的概率.       &lt;/p&gt;
&lt;p&gt;(5).隐含状态到观察状态的概率转移矩阵&lt;mathjax&gt;$$B_{ij}$$&lt;/mathjax&gt;  &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$B_{ij}=p(o_j｜s_i)$$&lt;/mathjax&gt;表示在隐含状态&lt;mathjax&gt;$s_i的情况下,观察状态为o_j$&lt;/mathjax&gt;的概率.      &lt;/p&gt;
&lt;h3&gt;实例&lt;/h3&gt;
&lt;p&gt;考虑这样一个例子,有一个隐士,他不知道自己所在地的天气情况(天晴,下雨,多云,对应于隐含状态S).但是他养了一株水藻,他可以观察到水藻的状态(干燥,湿润,湿透,对应于观察状态O).并且对每一个天气,水藻呈现不同状态的概率已知,例如天晴时水藻干燥,湿润和湿透的概率(对应于隐状态转移矩阵A)分别为0.4,0.3,0.3.同时你知道,今天的天气情况下明天的天气情况的概率(如今天天晴时,明天天晴,下雨,多云的概率分别为0.5,0.1,0.对应于观察状态在应状态下的概率转移矩阵B).并且,我们假定从以某一天为开始,这一天的天气情况概率分布(对应于初始概率&lt;mathjax&gt;$\pi$&lt;/mathjax&gt;)我们也知道.     &lt;/p&gt;
&lt;p&gt;假设隐士观察了水藻一个礼拜,这一个礼拜水藻的状为(干燥,干燥,湿润,湿润,干燥,湿透,干燥).现在问题来了,你能不能计算出这一系列状态出现的概率?能不能计算出隐士所在地方这一个礼拜最可能天气情况?  &lt;/p&gt;
&lt;p&gt;带着这些问题你将更好的理解HMM模型的应用.&lt;/p&gt;
&lt;h3&gt;基本问题&lt;/h3&gt;
&lt;p&gt;HMM可用于解决如下三个问题:&lt;/p&gt;
&lt;p&gt;1.评估问题(evaluate)        &lt;/p&gt;
&lt;p&gt;给定观察序列&lt;mathjax&gt;$O=o_1o_2...o_t和模型参数\lambda=(S,O,A,B,\pi)$&lt;/mathjax&gt;,计算在HMM模型下观察序列出现的概率.运用前向算法(forwad algorithm)进行求解.   &lt;/p&gt;
&lt;p&gt;2.解码问题(decode)&lt;/p&gt;
&lt;p&gt;给定观察序列&lt;mathjax&gt;$O=o_1o_2...o_t和模型参数\lambda=(S,O,A,B,\pi)$&lt;/mathjax&gt;,根据观察序列计算对应的最有可能的隐状态序列.在实际问题中,我们往往更关心的是马尔可夫模型中的隐含状态,可以运用viterbi算法进行求解.      &lt;/p&gt;
&lt;p&gt;3.学习问题      &lt;/p&gt;
&lt;p&gt;HMM模型的参数&lt;mathjax&gt;$\lambda=(A,B,\pi)$&lt;/mathjax&gt;未知,如何调整这些参数以使得观察序列O的概率尽可能的大,通常采用Baum-Welch算法解决.  &lt;/p&gt;
&lt;p&gt;下面我们详细讨论这3个问题.  &lt;/p&gt;
&lt;h2&gt;2.评估问题(evaluate)&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;假设模型参数&lt;mathjax&gt;$\lambda=(A,B,\pi)$&lt;/mathjax&gt;已知,考虑上面提到的例子,假设3天间我们观察到的水藻状态为(干燥,湿润,湿透),这三天中的任一天都可能是多云,晴天或是雨天,对于观察序列及隐藏序列,我们可以用如下的网格来表示:           &lt;/p&gt;
&lt;p&gt;&lt;center &gt;&lt;img src=&quot;data:image/png;base64,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&quot;&gt;&lt;/center&gt;           &lt;/p&gt;
&lt;p&gt;网格中的每一列表示可能的天气状态,并且每一天中的每个天气都与一个到相近天气状态相连,表示为在当前天气状态下到下一个天气状态的概率.每一列的下面是某个时间点上的观察状态.我们发现,对于如上的描述,这三天可能出现的天气序列有&lt;mathjax&gt;$3^3$&lt;/mathjax&gt;=27种,这27种天气情况转化为观察序列的概率和便是观察序列在模型下出现的概率,表示为:&lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$P(O｜HMM) = p(O｜sunny,sunny,sunny)+p(O｜sunny,sunny,rainy) \\
+...+P(O｜cloudy,cloudy,cloudy)$$&lt;/mathjax&gt;    &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$O=(dry,damp,soggy)$&lt;/mathjax&gt;,即为观察到的状态序列.这种基于穷举的方法求解效率很低,假设观察序列长度为T,隐含状态数目为N,所有可能的状态序列为&lt;mathjax&gt;$N^T$&lt;/mathjax&gt;,没一个状态序列的时间复杂度为&lt;mathjax&gt;$O(T)$&lt;/mathjax&gt;,所以总时间复杂度为&lt;mathjax&gt;$O(TN^T)$&lt;/mathjax&gt;.        &lt;/p&gt;
&lt;p&gt;下面采用前向算法(foward algorithm)进行优化求解.       &lt;/p&gt;
&lt;h3&gt;局部概率&lt;/h3&gt;
&lt;p&gt;首先定义局部概率(partial probability),它是指到达某个中间状态的概率.&lt;/p&gt;
&lt;p&gt;对于观察序列&lt;mathjax&gt;$O=o_1o_2...o_n,o_i可以理解为t=i时刻观察到的观察状态$&lt;/mathjax&gt;,关于观察状态和隐含状态用网格表示为: &lt;/p&gt;
&lt;p&gt;&lt;center &gt;&lt;img src=&quot;data:image/png;base64,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&quot;&gt;&lt;/center&gt;       &lt;/p&gt;
&lt;p&gt;那么t=2时,隐状态为&quot;cloudy&quot;的局部概率可以表示为:      &lt;/p&gt;
&lt;p&gt;&lt;center &gt;&lt;img src=&quot;data:image/png;base64,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&quot;&gt;&lt;/center&gt;   &lt;/p&gt;
&lt;p&gt;公式表述为&lt;mathjax&gt;$\alpha_{t=2}(c)=p(damp｜c)*(p(c｜s)+p(c｜c)+p(c｜r))$&lt;/mathjax&gt;,其中c,r,s分别是cloudy,rainy和sunny的简称.        &lt;/p&gt;
&lt;p&gt;那么延伸一下,假设有N个隐含状态,这t+1时刻处于隐含状态j的隐含概率可以表述为:       &lt;/p&gt;
&lt;p&gt;&lt;center &gt;&lt;img src=&quot;data:image/png;base64,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&quot;&gt;&lt;/center&gt;   &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\alpha_{t+1}(j) = b(o_{t+1}｜j)\sum_{i=1}^N\alpha_t(i)a_{ij}$$&lt;/mathjax&gt;     &lt;/p&gt;
&lt;p&gt;其中&lt;mathjax&gt;$$b(o_{t+1}｜j)$$&lt;/mathjax&gt;表示的是在t+1时刻,观察到的状态&lt;mathjax&gt;$$o_{t+1}$$&lt;/mathjax&gt;在隐含状态j下的概率,&lt;mathjax&gt;$$a_{ij}$$&lt;/mathjax&gt;表示隐含状态i到j的转移概率 .&lt;/p&gt;
&lt;p&gt;在t=1时,没有路径指向当前时间的隐含状态,t=1时的局部概率定义为:     &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\alpha_{1}(j)=b(o_1｜j)\pi(j)$$&lt;/mathjax&gt;    &lt;/p&gt;
&lt;p&gt;在我们求出t=1时个隐含状态的局部概率之后,就可以递归的计算t=2,t=3,...时各个隐含状态的局部概率,直到求得t=T(T为观察序列的长度)时为止.&lt;/p&gt;
&lt;p&gt;在t=1时,求每个隐含状态的局部概率时间复杂度为O(1),在t&amp;gt;1时,球每个隐含状态的时间复杂度为O(N),则t&amp;gt;1时求每一列的时间复杂度为O(N*N),T为观察序列的长度,则前向算法的时间复杂度为O(TN^2). &lt;/p&gt;
&lt;h2&gt;3.解码问题(decode)&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;假设模型参数&lt;mathjax&gt;$\lambda=(A,B,\pi)$&lt;/mathjax&gt;已知,考虑上面提到的例子,假设3天间我们观察到的水藻状态为(干燥,湿润,湿透),需要求解与观察状态对应的最有可能的隐含状态序列.对与上面描述的天气的例子,其网格图为:    &lt;/p&gt;
&lt;p&gt;&lt;center &gt;&lt;img src=&quot;data:image/png;base64,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&quot;&gt;&lt;/center&gt;       &lt;/p&gt;
&lt;p&gt;可以知道,最有可能的天气(隐含)序列是每一列中天气组合(总共27种)中的一项,所以最有可能的隐含序列&lt;mathjax&gt;$\hat S$&lt;/mathjax&gt;可以表述为:    &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\hat S=argmax_{s\in S}p(O｜s)$$&lt;/mathjax&gt;&lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$其中观察O=(dry,damp,soggy),s为27种隐含序列中的一种$$&lt;/mathjax&gt;      &lt;br&gt;
同样,我们可以通过穷举法计算每一种可能出现的隐状态序列的概率,概率值最高的便是要求的隐含状态序列.这显然又是十分耗时的工程,我们可以采用viterbi算法优化求解.      &lt;/p&gt;
&lt;h3&gt;局部概率和局部最佳路径&lt;/h3&gt;
&lt;p&gt;对于上面的程序,先假设在t=3时,天气状态为cloudy时概率最大,那么从t=2到t=3的cloudy状态有3条路径,最佳路径必定是这三条路径中的一条.假设t=2时的从状态rainy到t=3的cloudy的概率最大,则可以说明t=2时的cloudy路径为局部最佳路径,路径对应的概率称为局部概率(&lt;mathjax&gt;$\delta$&lt;/mathjax&gt;).&lt;/p&gt;
&lt;p&gt;&lt;center &gt;&lt;img src=&quot;data:image/png;base64,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&quot;&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;延伸一下,假设有N个隐含状态,在t+1时刻的位于隐含状态j的局部概率为:    &lt;/p&gt;
&lt;p&gt;&lt;center &gt;&lt;img src=&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXcAAACICAIAAACTETzRAAAAA3NCSVQICAjb4U/gAAAAGXRFWHRTb2Z0d2FyZQBnbm9tZS1zY3JlZW5zaG907wO/PgAABONJREFUeJzt3dFyozgQBdAwtf//y8wDVYyXYIOBBqn7nKddjyuVyHDplgQexnH8AQjz5+lfAEhOygCx/nv6F+AOwzC8/q82+R6GfSJlkpsO9MXxvfriVz+Bz84PeyZSJrNhGFaP6enFd//KSYZ9wbxMWptH8ziOi5J+9Ycs/oPPLhn2ZKQMEEvK5LSzLC94XQ1l2FdJGd6aZyvnCYWnfyO6JGWAWNaY2KCE4SS1DOtWw0XicICUyWnn/OKeZdfZdb9dWlcNezJSBohVK1Or+XzNrHZFvY1hXyj3B1fjhppHGPZXUqYENwc/wrBPpAwQy+wvEEvKcIFhGGyl4R0dExBLLUMI1Q0ztQxR5pRxjBUnZYBYOiZupZMqSC3DA8rugq1JygCxPMWKJpgqTsy8DE3wCJvEpAwNWb2Jmd6Zl6FpOqkEpAwQy+wvnVHddEctQ68KPtqyU2Z/6ZWp4l5IGfJw+0Kb1Jxko5NqjVqGbHRSrZH65OfmzGdJGSCW/TJUZNPNndQy1KWTuoeUKcGXHD7CsE90TMmd+cLmgifJVZ3U4WH//Z4EBZeUyezdzpHpxW/3lVTYh3LJH3jtsCdgv0xam0fzOI579pJ4vtRXW4pPDvucRPNP++m8kPmRMrBpPvPv3OCX6W6JcsVbEfvL8g/vLDgvc9Ilw/7z/5FPMOxqGTgortyYkyVBxPyY/WXTa79w4KB/d1lO83rEbG7oD7+flCHWu5MkwetBU7OL+ihB0EgZOCj05F8sNnXNvExOO1ep91wnMy12nLQ5DueHfVEf5cgatQx79V63n9H7ef6s7ls+PthcLvXpRzDsC+X+4GrO3MfEYYb9lZQpwf66/S589Ixhn3SQMsfuZI17z/630Z2C7cwNrDHBPyImguSmLs/lvIeVbIrS9t5GLQPEMi9DFXbWPUXHRHImXx6nYwJi6ZhISHPUFB0TeWiO2iRlSEW+NMi8DBDLvAy98nitXuiY6JLbGjviowJi6ZjogOaoazomWqc56p3PD4ilY6ItmqN8dEy0wgNfstIxAbF0TDxGc1SEjokHaI5K0TEBsXRM3EFnVJmOqYQHv+SwcnPkuyUnOqbkfGHzIwz7KymT2ee9+XbuBzHsC+Zl0to8msdxNF1yOcP+m5QBYkmZnHaW5QWvq6EM+yprTHzyejJUm03gKmoZ3lpcb0tdfrmQlGHDOI6qGM7QMbGLoOEwtUxOO+cXC+7dCGXYV0kZIJaUSWvzulrtinoPw/6beZnM5iPeDTV3MuwLUia56Zg+f3Nw2TPkmKuGPYdyxRv7/a78HS0cYF6GtxaZImI4Ri0DxFLLALGkDBBLygCxWlzJbnxpw5oufKXFlIl2OCY8+gAOaDFlXnc0KRmgd+XmZeZ65EBh4kkrcECqlPHt7tCgJCkz58tmrTG/QVWySlJzuRbnZb4ynxLnU6Pxta2dzG03qPgkY5JaBmhW97XMvCB1/nKR4FLzOrf97Z+z+rACzjvzoeSQpJaZV3/2nyROJ7hHkpSZ7FxpTnw9MbfdIB9Kux1T6EdSsLHKMbdNj1LVMkCD2q1luJbKhaeoZXIyt92gsh+KlMlGzdKg4h9K0QV84DZqGSCWlAFiSRkglpQBYkkZIJaUAWJJGSCWlAFiSRkglpQBYkkZIJaUAWJJGSCWlAFiSRkg1l84DCfkiLp0TAAAAABJRU5ErkJggg==&quot;&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\delta_t(j) = max_{i \in N}(\delta_{t-1}(i)a_{ij}b_{jo_t})$$&lt;/mathjax&gt;  &lt;/p&gt;
&lt;p&gt;其中&lt;mathjax&gt;$b_{jo_t}指的是在t时刻的观察值o_t在隐含状态j下的概率$&lt;/mathjax&gt;,在t=1时,没有路径指向当前的隐含状态,其局部概率为:        &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\delta_1{j} = b_{jo_1}\pi(j)$$&lt;/mathjax&gt;        &lt;/p&gt;
&lt;p&gt;这样通过计算t=1时各个隐含状态的局部概率,就可以计算t=2,...t=T时各状态的局部概率.其实,在t=T时,计算出来概率&lt;mathjax&gt;$\delta_t(j)$&lt;/mathjax&gt;便是最后与观察序列对应的且最后一个隐含状态为j的最终概率,&lt;mathjax&gt;$$j=max_{j\in N} \delta_t(j)$$&lt;/mathjax&gt;可以求出最后一个观察状态对应的隐含状态.那么如何求之前T-1个观察状态对应的隐含状态?这里我们需要借用反向指针来实现.       &lt;/p&gt;
&lt;p&gt;我们知道计算t时刻隐含状态j的局部概率&lt;mathjax&gt;$$\delta_{t}(j)$$&lt;/mathjax&gt;,需要的知道t-1时刻的&lt;mathjax&gt;$$\delta_{t-1}$$&lt;/mathjax&gt;,我们需要记录t-1时刻的某个状态i,有i状态到达t时刻的状态j是到达状态j的最佳路径.通过反向指针来记录这种状态:      &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\phi_t(j) = argmax_{i\in N}(\delta_{t-1}(i)aij)$$&lt;/mathjax&gt;     &lt;/p&gt;
&lt;p&gt;其中,&lt;mathjax&gt;$$\phi_t(j)表示指向t时刻状态j的隐含状态,具体所指应该是t-1时刻的某个状态i$$&lt;/mathjax&gt;.     &lt;/p&gt;
&lt;p&gt;其实初看这个公式的有些奇怪,我们在计算局部概率&lt;mathjax&gt;$\delta$&lt;/mathjax&gt;的时候,同时考虑了局部概率&lt;mathjax&gt;$\delta和转移概率a及混淆概率(从隐含概率到观察概率,b)$&lt;/mathjax&gt;.这是因为,我们希望&lt;mathjax&gt;$\phi$&lt;/mathjax&gt;可以能回答这个问题&quot;如果我们在这里,最可能通过哪条路径到达下一个状态?&quot;,这个问题与隐藏有关,而与观察状态无关,故而可以忽略混淆矩阵的影响.     &lt;/p&gt;
&lt;h3&gt;小结&lt;/h3&gt;
&lt;p&gt;viterbi算法提供了一种有效的计算方法来分析HMM模型的观察序列,并捕获最有可能的隐藏序列.它利用递归减少计算两,并使用整个序列的上下文来做判断,从而对包含&quot;噪声&quot;的序列也能进行良好的分析.       &lt;/p&gt;
&lt;p&gt;在使用时,viterbi算法对于网格中的没一个隐状态都计算一个局部概率,同时包含一个反向指针来指示最有可能的到达该单元的路径.当完成整个计算之后,首先在终止时刻找到最可能的隐含状态,然后通过反响指针回溯到t=1时刻,这样回溯路径上的状态序列就是最可能的隐含状态序列.       &lt;/p&gt;
&lt;h2&gt;4.学习问题&lt;/h2&gt;
&lt;hr&gt;
&lt;p&gt;如果模型参数的先验分布已知,也就是参数&lt;mathjax&gt;$\lambda=(\pi,a,b)$&lt;/mathjax&gt;已知的情况下,对于某一观察序列,可以计算出观察序列出现的概率及与观察序列对应的最有可能的隐含序列.如果模型的参数事先并不知道,那么能够在给定某一观察序列的情况下估计模型的参数?&lt;/p&gt;
&lt;p&gt;这种情况下,我们可以用极大似然估计来估计模型参数,问题可以定义为:       &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\lambda=argmax_{\lambda}l(O｜\lambda) \\
         =argmax_{\lambda}\sum_{i=1}^T\log p(o_t｜\lambda) \\
         =argmax_{\lambda}\sum_{i=1}^T\log \sum_{s_t} p(o_t,s_t｜\lambda)$$&lt;/mathjax&gt;    &lt;br&gt;
其中&lt;mathjax&gt;$\lambda$&lt;/mathjax&gt;是HMM模型的参数集合,O是观察序列,长度为T.&lt;mathjax&gt;$s_t$&lt;/mathjax&gt;表示t时刻可能的隐含状态.       &lt;/p&gt;
&lt;p&gt;由于含有隐变量,很难通过极大似然估计获取参数解.对于这一类含有隐变量的参数估计问题,可以采用EM算法进行参数评估.       &lt;/p&gt;
&lt;p&gt;这里我们主要采用前向-后向算法(Forward-backward algorithm)算法进行问题的近似求解,前向-后向算法是EM算法的一个特例.       &lt;/p&gt;
&lt;p&gt;这具体讲解之前,先引入几个概念:&lt;/p&gt;
&lt;p&gt;首先我们已经知道前向变量&lt;mathjax&gt;$\alpha$&lt;/mathjax&gt;的意义,&lt;mathjax&gt;$$\alpha_t(j)$$&lt;/mathjax&gt;表示t时刻位于隐含变量j的局部概率.       &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\alpha_1(j) = \pi(j)b_j(o_1),t=1$$&lt;/mathjax&gt;        &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\alpha_{t+1}(j) = b_j(o_{t+1})\sum_{i=1}^N\alpha_t(i)a_{ij},t&amp;gt;1$$&lt;/mathjax&gt;     &lt;/p&gt;
&lt;p&gt;类似的,我们可以定义后向变量&lt;mathjax&gt;$\beta$&lt;/mathjax&gt;,&lt;mathjax&gt;$\beta_t(j)表示观察序列o_{t+1}...o_T$&lt;/mathjax&gt;在t时刻隐含变量为j的概率,形式话定义为:      &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\beta_t(j) =p(o_{t+1}...o_T｜q_t = s_j;\lambda),i\leq t\leq T,1\leq j\leq N$$&lt;/mathjax&gt;  &lt;/p&gt;
&lt;p&gt;初始化,令t=T时刻的所有状态的后向变量为1:     &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\beta_T(j) = 1,1\leq j\leq N$$&lt;/mathjax&gt;&lt;/p&gt;
&lt;p&gt;当t&amp;lt;T时,通过下图t和t+1时刻的隐含变量之间的关系可以的出t时刻的后向变量为:       &lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src=&quot;data:image/png;base64,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&quot;&gt;&lt;/center&gt;       &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\beta_t(j) = \sum_{i=1}^N\beta_{t+1}(i)a_{ji}b_i(o_{t+1}),1\leq j\leq N,1\leq t\leq T-1$$&lt;/mathjax&gt;     &lt;/p&gt;
&lt;p&gt;给定观察序列O和HMM模型,定义t时刻处于隐含状态&lt;mathjax&gt;$s_j$&lt;/mathjax&gt;的概率变量为:       &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\gamma_t(j) = p(q_t=s_j｜O,\lambda) \\
              =\frac{\alpha_t(j)\beta_t(j)}{p(O｜\lambda)} \\
              =\frac{\alpha_t(j)\beta_t(j)}{\sum_{i=1}^N\alpha_t(j)\beta_t(j)}$$&lt;/mathjax&gt;&lt;/p&gt;
&lt;p&gt;其中分母的作用是确保&lt;mathjax&gt;$$\sum_{i=1}^N\alpha_t(j)\beta_t(j)=1$$&lt;/mathjax&gt;           &lt;/p&gt;
&lt;p&gt;给定观察序列O和HMM,定义t时刻处于隐含状态&lt;mathjax&gt;$s_i$&lt;/mathjax&gt;,且t+1时刻处于隐含状态&lt;mathjax&gt;$s_j$&lt;/mathjax&gt;的概率变量为:       &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\xi_t(i,j) = p(q_t=s_i,q_{t+1}=s_j｜O,\lambda) \\
             = \frac{\alpha_t(i)a_{ij}\beta_{t+1}(j)b_{j}(o_{t+1})}{p(O｜\lambda)} \\
             =\frac{\alpha_t(i)a_{ij}\beta_{t+1}(j)b_{j}(o_{t+1})}{\sum_{i=1}^n\sum_{j=1}^N\alpha_t(i)a_{ij}\beta_{t+1}(j)b_{j}(o_{t+1})}$$&lt;/mathjax&gt;     &lt;/p&gt;
&lt;p&gt;并且,&lt;mathjax&gt;$$\gamma_t(i) = \sum_{j=1}^N\xi_t(i,j)$$&lt;/mathjax&gt;     &lt;/p&gt;
&lt;p&gt;现在回到参数的求解过程中来.      &lt;/p&gt;
&lt;p&gt;EM算法是一个迭代的过程,通过迭代来执行E步和M布来达到参数的近似最优解.具体到我们的问题中,E步得到隐变量的概率分布(通过隐变量的后验概率).在实现过程中,我们知道与隐变量相关的是隐变量概率转移矩阵和观察状态在隐变量下的混淆矩阵.所以按照如上的方式计算&lt;mathjax&gt;$$\gamma_t(i)和\xi_t{i,j}$$&lt;/mathjax&gt;   &lt;/p&gt;
&lt;p&gt;在M步中,需要更新模型参数:      &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$\overline\pi_(i)$&lt;/mathjax&gt;是在初始时刻出现状态i的频率的期望值,&lt;mathjax&gt;$\overline\pi_(i)=\gamma_1(i)$&lt;/mathjax&gt;     &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\overline\alpha_{ij}$$&lt;/mathjax&gt;是从状态i转移到状态j的次数的期望值/从状态i转移出去的次数的期望值:     &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\overline\alpha_{ij}=\frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}$$&lt;/mathjax&gt; &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$\overline b_j(k)$&lt;/mathjax&gt;是在状态j下观察到的可观察状态k的次数的期望/从状态j下观察到的所有可观察状态的次数的期望     &lt;/p&gt;
&lt;p&gt;&lt;mathjax&gt;$$\overline b_j(k) =\frac{\sum_{t=1,s.t.o_t=k}^T\gamma_t(j)}{\sum_{t=1}^T\gamma_t(j)}$$&lt;/mathjax&gt;&lt;/p&gt;
&lt;h3&gt;参考内容&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;www.52nlp.cn/category/hidden-markov-model&quot;&gt;我爱自然语言处理-隐马尔可夫模型&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;维基百科-隐马尔可夫模型&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/jwchennlp/HMM&quot;&gt;HMM实现源码(python) github.com/jwchennlp/HMM&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/zhangchaoyang/articles/2220398.html&quot;&gt;前向-后向算法(forward-backward algorithm) http://www.cnblogs.com/zhangchaoyang/articles/2220398.html&lt;/a&gt;&lt;/p&gt;
        &lt;/article&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/body&gt;
  &lt;script type=&quot;text/x-mathjax-config&quot;&gt;
    MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], [&quot;\\(&quot;,&quot;\\)&quot;] ],
          displayMath: [ ['$$', '$$'], [&quot;\\[&quot;, &quot;\\]&quot;] ],
          processEscapes: true
        },
        TeX: {
          equationNumbers: {
            autoNumber: 'AMS'
          }
        },
        &quot;HTML-CSS&quot;: {
          imageFont: null
        }
      });
  &lt;/script&gt;
  &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/2.1-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt;&lt;/script&gt;
&lt;/html&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/hmm-hidden-markov-model_140608165432/&quot;&gt;Hmm Hidden Markov Model_140608165432&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on June 04, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[HMM(Hidden Markov Model)]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/hmm-hidden-markov-model/" />
  <id>http://jwchennlp.github.com/hmm-hidden-markov-model</id>
  <updated>2014-06-04 09:35:00 UTCT00:00:00-00:00</updated>
  <published>2014-06-04T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;section&quot;&gt;1.介绍&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;隐马尔可夫模型(Hidden Markov Model,HMM)是一种统计模型,用它来描述一个含有未知参数的马尔可夫过程.在模型中包括可观察的参数和隐藏的参数,一般要求解的问题是通过观察到的参数来评估过程中的隐含参数.隐马尔可夫模型在语音识别,中文分词,词性标注,机器翻译等领域都有十分广泛的运用.		&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;模型表示&lt;/h3&gt;

&lt;p&gt;隐马尔可夫模型(HMM)可以用如下的五元组来表示,包括2状态集合和概率矩阵:&lt;/p&gt;

&lt;p&gt;(1).隐含状态S={$s_1,s_2,…,s_n$}		&lt;/p&gt;

&lt;p&gt;隐含状态是马尔可夫模型中所隐含的状态.这些状态无法通过直接观测而得到.		&lt;/p&gt;

&lt;p&gt;(2).可观测状态O={$o_1,o_2,…,o_m$}				&lt;/p&gt;

&lt;p&gt;可观察状态是马尔可夫模型中可以观测到的状态.(可观察状态数目和隐含状态数目可以不相等).		&lt;/p&gt;

&lt;p&gt;(3).初始状态概率矩阵$\pi$			&lt;/p&gt;

&lt;p&gt;表示隐含状态在初始时刻t=1时的概率矩阵.初始状态概率矩阵为$\pi=[p(s_1),p(s_2),…,p(s_n)]$		&lt;/p&gt;

&lt;p&gt;(4).隐含状态的概率转移矩阵$A_{ij}$		
表示在HMM模型在各个隐含状态之间的转移概率.其中&lt;script type=&quot;math/tex&quot;&gt;A_{ij}=p(s_j｜s_i)&lt;/script&gt;表示在t时刻隐含状态为$s_i时,t+1时刻隐含状态为s_j$的概率.		&lt;/p&gt;

&lt;p&gt;(5).隐含状态到观察状态的概率转移矩阵&lt;script type=&quot;math/tex&quot;&gt;B_{ij}&lt;/script&gt;	&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;B_{ij}=p(o_j｜s_i)&lt;/script&gt;表示在隐含状态$s_i的情况下,观察状态为o_j$的概率.		&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;实例&lt;/h3&gt;

&lt;p&gt;考虑这样一个例子,有一个隐士,他不知道自己所在地的天气情况(天晴,下雨,多云,对应于隐含状态S).但是他养了一株水藻,他可以观察到水藻的状态(干燥,湿润,湿透,对应于观察状态O).并且对每一个天气,水藻呈现不同状态的概率已知,例如天晴时水藻干燥,湿润和湿透的概率(对应于隐状态转移矩阵A)分别为0.4,0.3,0.3.同时你知道,今天的天气情况下明天的天气情况的概率(如今天天晴时,明天天晴,下雨,多云的概率分别为0.5,0.1,0.对应于观察状态在应状态下的概率转移矩阵B).并且,我们假定从以某一天为开始,这一天的天气情况概率分布(对应于初始概率$\pi$)我们也知道.		&lt;/p&gt;

&lt;p&gt;假设隐士观察了水藻一个礼拜,这一个礼拜水藻的状为(干燥,干燥,湿润,湿润,干燥,湿透,干燥).现在问题来了,你能不能计算出这一系列状态出现的概率?能不能计算出隐士所在地方这一个礼拜最可能天气情况?	&lt;/p&gt;

&lt;p&gt;带着这些问题你将更好的理解HMM模型的应用.&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;基本问题&lt;/h3&gt;

&lt;p&gt;HMM可用于解决如下三个问题:&lt;/p&gt;

&lt;p&gt;1.评估问题(evaluate) 		&lt;/p&gt;

&lt;p&gt;给定观察序列$O=o_1o_2…o_t和模型参数\lambda=(S,O,A,B,\pi)$,计算在HMM模型下观察序列出现的概率.运用前向算法(forwad algorithm)进行求解.	&lt;/p&gt;

&lt;p&gt;2.解码问题(decode)&lt;/p&gt;

&lt;p&gt;给定观察序列$O=o_1o_2…o_t和模型参数\lambda=(S,O,A,B,\pi)$,根据观察序列计算对应的最有可能的隐状态序列.在实际问题中,我们往往更关心的是马尔可夫模型中的隐含状态,可以运用viterbi算法进行求解.		&lt;/p&gt;

&lt;p&gt;3.学习问题 		&lt;/p&gt;

&lt;p&gt;HMM模型的参数$\lambda=(A,B,\pi)$未知,如何调整这些参数以使得观察序列O的概率尽可能的大,通常采用Baum-Welch算法解决.	&lt;/p&gt;

&lt;p&gt;下面我们详细讨论这3个问题.	&lt;/p&gt;

&lt;h2 id=&quot;evaluate&quot;&gt;2.评估问题(evaluate)&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;假设模型参数$\lambda=(A,B,\pi)$已知,考虑上面提到的例子,假设3天间我们观察到的水藻状态为(干燥,湿润,湿透),这三天中的任一天都可能是多云,晴天或是雨天,对于观察序列及隐藏序列,我们可以用如下的网格来表示:			&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm1.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;网格中的每一列表示可能的天气状态,并且每一天中的每个天气都与一个到相近天气状态相连,表示为在当前天气状态下到下一个天气状态的概率.每一列的下面是某个时间点上的观察状态.我们发现,对于如上的描述,这三天可能出现的天气序列有$3^3$=27种,这27种天气情况转化为观察序列的概率和便是观察序列在模型下出现的概率,表示为:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(O｜HMM) = p(O｜sunny,sunny,sunny)+p(O｜sunny,sunny,rainy) \\
+...+P(O｜cloudy,cloudy,cloudy)&lt;/script&gt;

&lt;p&gt;$O=(dry,damp,soggy)$,即为观察到的状态序列.这种基于穷举的方法求解效率很低,假设观察序列长度为T,隐含状态数目为N,所有可能的状态序列为$N^T$,没一个状态序列的时间复杂度为$O(T)$,所以总时间复杂度为$O(TN^T)$.		&lt;/p&gt;

&lt;p&gt;下面采用前向算法(foward algorithm)进行优化求解.		&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;局部概率&lt;/h3&gt;
&lt;p&gt;首先定义局部概率(partial probability),它是指到达某个中间状态的概率.&lt;/p&gt;

&lt;p&gt;对于观察序列$O=o_1o_2…o_n,o_i可以理解为t=i时刻观察到的观察状态$,关于观察状态和隐含状态用网格表示为:	&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm2.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;那么t=2时,隐状态为”cloudy”的局部概率可以表示为:		&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm3.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;公式表述为$\alpha_{t=2}(c)=p(damp｜c)*(p(c｜s)+p(c｜c)+p(c｜r))$,其中c,r,s分别是cloudy,rainy和sunny的简称.		&lt;/p&gt;

&lt;p&gt;那么延伸一下,假设有N个隐含状态,这t+1时刻处于隐含状态j的隐含概率可以表述为:		&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm4.png&quot; /&gt;&lt;/center&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{t+1}(j) = b(o_{t+1}｜j)\sum_{i=1}^N\alpha_t(i)a_{ij}&lt;/script&gt;

&lt;p&gt;其中&lt;script type=&quot;math/tex&quot;&gt;b(o_{t+1}｜j)&lt;/script&gt;表示的是在t+1时刻,观察到的状态&lt;script type=&quot;math/tex&quot;&gt;o_{t+1}&lt;/script&gt;在隐含状态j下的概率,&lt;script type=&quot;math/tex&quot;&gt;a_{ij}&lt;/script&gt;表示隐含状态i到j的转移概率 .&lt;/p&gt;

&lt;p&gt;在t=1时,没有路径指向当前时间的隐含状态,t=1时的局部概率定义为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{1}(j)=b(o_1｜j)\pi(j)&lt;/script&gt;

&lt;p&gt;在我们求出t=1时个隐含状态的局部概率之后,就可以递归的计算t=2,t=3,…时各个隐含状态的局部概率,直到求得t=T(T为观察序列的长度)时为止.&lt;/p&gt;

&lt;p&gt;在t=1时,求每个隐含状态的局部概率时间复杂度为O(1),在t&amp;gt;1时,球每个隐含状态的时间复杂度为O(N),则t&amp;gt;1时求每一列的时间复杂度为O(N*N),T为观察序列的长度,则前向算法的时间复杂度为O(TN^2).	&lt;/p&gt;

&lt;h2 id=&quot;decode&quot;&gt;3.解码问题(decode)&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;假设模型参数$\lambda=(A,B,\pi)$已知,考虑上面提到的例子,假设3天间我们观察到的水藻状态为(干燥,湿润,湿透),需要求解与观察状态对应的最有可能的隐含状态序列.对与上面描述的天气的例子,其网格图为:	&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm1.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;可以知道,最有可能的天气(隐含)序列是每一列中天气组合(总共27种)中的一项,所以最有可能的隐含序列$\hat S$可以表述为:	&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat S=argmax_{s\in S}p(O｜s)&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;其中观察O=(dry,damp,soggy),s为27种隐含序列中的一种&lt;/script&gt;		
同样,我们可以通过穷举法计算每一种可能出现的隐状态序列的概率,概率值最高的便是要求的隐含状态序列.这显然又是十分耗时的工程,我们可以采用viterbi算法优化求解.		&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;局部概率和局部最佳路径&lt;/h3&gt;

&lt;p&gt;对于上面的程序,先假设在t=3时,天气状态为cloudy时概率最大,那么从t=2到t=3的cloudy状态有3条路径,最佳路径必定是这三条路径中的一条.假设t=2时的从状态rainy到t=3的cloudy的概率最大,则可以说明t=2时的cloudy路径为局部最佳路径,路径对应的概率称为局部概率($\delta$).&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm5.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;延伸一下,假设有N+1个隐含状态,在t+1时刻的位于隐含状态j的局部概率为:	&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm6.png&quot; /&gt;&lt;/center&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta_t(j) = max_{i \in N}(\delta_{t-1}(i)a_{ij}b_{jo_t})&lt;/script&gt;

&lt;p&gt;其中$b_{jo_t}指的是在t时刻的观察值o_t在隐含状态j下的概率$,在t=1时,没有路径指向当前的隐含状态,其局部概率为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta_1{j} = b_{jo_1}\pi(j)&lt;/script&gt;

&lt;p&gt;这样通过计算t=1时各个隐含状态的局部概率,就可以计算t=2,…t=T时各状态的局部概率.其实,在t=T时,计算出来概率$\delta_t(j)$便是最后与观察序列对应的且最后一个隐含状态为j的最终概率,&lt;script type=&quot;math/tex&quot;&gt;j=max_{j\in N} \delta_t(j)&lt;/script&gt;可以求出最后一个观察状态对应的隐含状态.那么如何求之前T-1个观察状态对应的隐含状态?这里我们需要借用反向指针来实现.		&lt;/p&gt;

&lt;p&gt;我们知道计算t时刻隐含状态j的局部概率&lt;script type=&quot;math/tex&quot;&gt;\delta_{t}(j)&lt;/script&gt;,需要的知道t-1时刻的&lt;script type=&quot;math/tex&quot;&gt;\delta_{t-1}&lt;/script&gt;,我们需要记录t-1时刻的某个状态i,有i状态到达t时刻的状态j是到达状态j的最佳路径.通过反向指针来记录这种状态:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\phi_t(j) = argmax_{i\in N}(\delta_{t-1}(i)aij)&lt;/script&gt;

&lt;p&gt;其中,&lt;script type=&quot;math/tex&quot;&gt;\phi_t(j)表示指向t时刻状态j的隐含状态,具体所指应该是t-1时刻的某个状态i&lt;/script&gt;.		&lt;/p&gt;

&lt;p&gt;其实初看这个公式的有些奇怪,我们在计算局部概率$\delta$的时候,同时考虑了局部概率$\delta和转移概率a及混淆概率(从隐含概率到观察概率,b)$.这是因为,我们希望$\phi$可以能回答这个问题”如果我们在这里,最可能通过哪条路径到达下一个状态?”,这个问题与隐藏有关,而与观察状态无关,故而可以忽略混淆矩阵的影响.		&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;小结&lt;/h3&gt;

&lt;p&gt;viterbi算法提供了一种有效的计算方法来分析HMM模型的观察序列,并捕获最有可能的隐藏序列.它利用递归减少计算两,并使用整个序列的上下文来做判断,从而对包含”噪声”的序列也能进行良好的分析.		&lt;/p&gt;

&lt;p&gt;在使用时,viterbi算法对于网格中的没一个隐状态都计算一个局部概率,同时包含一个反向指针来指示最有可能的到达该单元的路径.当完成整个计算之后,首先在终止时刻找到最可能的隐含状态,然后通过反响指针回溯到t=1时刻,这样回溯路径上的状态序列就是最可能的隐含状态序列.		&lt;/p&gt;

&lt;h2 id=&quot;section-7&quot;&gt;4.学习问题&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;如果模型参数的先验分布已知,也就是参数$\lambda=(\pi,a,b)$已知的情况下,对于某一观察序列,可以计算出观察序列出现的概率及与观察序列对应的最有可能的隐含序列.如果模型的参数事先并不知道,那么能够在给定某一观察序列的情况下估计模型的参数?&lt;/p&gt;

&lt;p&gt;这种情况下,我们可以用极大似然估计来估计模型参数,问题可以定义为:		&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lambda=argmax_{\lambda}l(O｜\lambda) \\
		 =argmax_{\lambda}\sum_{i=1}^T\log p(o_t｜\lambda) \\
		 =argmax_{\lambda}\sum_{i=1}^T\log \sum_{s_t} p(o_t,s_t｜\lambda)&lt;/script&gt;		
其中$\lambda$是HMM模型的参数集合,O是观察序列,长度为T.$s_t$表示t时刻可能的隐含状态.		&lt;/p&gt;

&lt;p&gt;由于含有隐变量,很难通过极大似然估计获取参数解.对于这一类含有隐变量的参数估计问题,可以采用EM算法进行参数评估.		&lt;/p&gt;

&lt;p&gt;这里我们主要采用前向-后向算法(Forward-backward algorithm)算法进行问题的近似求解,前向-后向算法是EM算法的一个特例.		&lt;/p&gt;

&lt;p&gt;这具体讲解之前,先引入几个概念:&lt;/p&gt;

&lt;p&gt;首先我们已经知道前向变量$\alpha$的意义,&lt;script type=&quot;math/tex&quot;&gt;\alpha_t(j)&lt;/script&gt;表示t时刻位于隐含变量j的局部概率.		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_1(j) = \pi(j)b_j(o_1),t=1&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_{t+1}(j) = b_j(o_{t+1})\sum_{i=1}^N\alpha_t(i)a_{ij},t&gt;1&lt;/script&gt;

&lt;p&gt;类似的,我们可以定义后向变量$\beta$,$\beta_t(j)表示观察序列o_{t+1}…o_T$在t时刻隐含变量为j的概率,形式话定义为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_t(j) =p(o_{t+1}...o_T｜q_t = s_j;\lambda),i\leq t\leq T,1\leq j\leq N&lt;/script&gt;

&lt;p&gt;初始化,令t=T时刻的所有状态的后向变量为1:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_T(j) = 1,1\leq j\leq N&lt;/script&gt;

&lt;p&gt;当t&amp;lt;T时,通过下图t和t+1时刻的隐含变量之间的关系可以的出t时刻的后向变量为:		&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;../images/1406/hmm10.png&quot; /&gt;&lt;/center&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta_t(j) = \sum_{i=1}^N\beta_{t+1}(i)a_{ji}b_i(o_{t+1}),1\leq j\leq N,1\leq t\leq T-1&lt;/script&gt;

&lt;p&gt;给定观察序列O和HMM模型,定义t时刻处于隐含状态$s_j$的概率变量为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma_t(j) = p(q_t=s_j｜O,\lambda) \\
			  =\frac{\alpha_t(j)\beta_t(j)}{p(O｜\lambda)} \\
			  =\frac{\alpha_t(j)\beta_t(j)}{\sum_{i=1}^N\alpha_t(j)\beta_t(j)}&lt;/script&gt;

&lt;p&gt;其中分母的作用是确保&lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^N\alpha_t(j)\beta_t(j)=1&lt;/script&gt;			&lt;/p&gt;

&lt;p&gt;给定观察序列O和HMM,定义t时刻处于隐含状态$s_i$,且t+1时刻处于隐含状态$s_j$的概率变量为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\xi_t(i,j) = p(q_t=s_i,q_{t+1}=s_j｜O,\lambda) \\
			 = \frac{\alpha_t(i)a_{ij}\beta_{t+1}(j)b_{j}(o_{t+1})}{p(O｜\lambda)} \\
			 =\frac{\alpha_t(i)a_{ij}\beta_{t+1}(j)b_{j}(o_{t+1})}{\sum_{i=1}^n\sum_{j=1}^N\alpha_t(i)a_{ij}\beta_{t+1}(j)b_{j}(o_{t+1})}&lt;/script&gt;

&lt;p&gt;并且,&lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i) = \sum_{j=1}^N\xi_t(i,j)&lt;/script&gt;		&lt;/p&gt;

&lt;p&gt;现在回到参数的求解过程中来.		&lt;/p&gt;

&lt;p&gt;EM算法是一个迭代的过程,通过迭代来执行E步和M布来达到参数的近似最优解.具体到我们的问题中,E步得到隐变量的概率分布(通过隐变量的后验概率).在实现过程中,我们知道与隐变量相关的是隐变量概率转移矩阵和观察状态在隐变量下的混淆矩阵.所以按照如上的方式计算&lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)和\xi_t{i,j}&lt;/script&gt;	&lt;/p&gt;

&lt;p&gt;在M步中,需要更新模型参数:		&lt;/p&gt;

&lt;p&gt;$\overline\pi&lt;em&gt;(i)$是在初始时刻出现状态i的频率的期望值,$\overline\pi&lt;/em&gt;(i)=\gamma_1(i)$		&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline\alpha_{ij}&lt;/script&gt;是从状态i转移到状态j的次数的期望值/从状态i转移出去的次数的期望值:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\overline\alpha_{ij}=\frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}&lt;/script&gt;

&lt;p&gt;$\overline b_j(k)$是在状态j下观察到的可观察状态k的次数的期望/从状态j下观察到的所有可观察状态的次数的期望		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\overline b_j(k) =\frac{\sum_{t=1,s.t.o_t=k}^T\gamma_t(j)}{\sum_{t=1}^T\gamma_t(j)}&lt;/script&gt;

&lt;h3 id=&quot;section-8&quot;&gt;参考内容&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;www.52nlp.cn/category/hidden-markov-model&quot;&gt;我爱自然语言处理-隐马尔可夫模型&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;section-9&quot;&gt;维基百科-隐马尔可夫模型&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/jwchennlp/HMM&quot;&gt;HMM实现源码(python) github.com/jwchennlp/HMM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/zhangchaoyang/articles/2220398.html&quot;&gt;前向-后向算法(forward-backward algorithm) http://www.cnblogs.com/zhangchaoyang/articles/2220398.html&lt;/a&gt;&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/hmm-hidden-markov-model/&quot;&gt;HMM(Hidden Markov Model)&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on June 04, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[pLSA]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/plsa/" />
  <id>http://jwchennlp.github.com/plsa</id>
  <updated>2014-06-02 01:28:01 UTCT00:00:00-00:00</updated>
  <published>2014-06-02T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;在对LSA的介绍中,我们知道LSA的核心思想是将建立的文档-词项矩阵运用SVD将高维空间映射到到隐语义空间,这样可以较好的解决同义词的问题.但语义的权重不好解释.&lt;/p&gt;

&lt;h2 id=&quot;aspect-model&quot;&gt;1.层面模型(aspect model)&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;pLSA是以层面模型进行建模,层面模型是一个统计模型.它是关联于潜在类别Z的共现数据(co-occurence)的潜在变量模型.关于D*W(文档-词项)的联合概率定义如下:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(d,w) = p(d)p(w｜d),p(w｜d)=\sum_{z\in Z}p(w｜z)p(z｜d)&lt;/script&gt;

&lt;p&gt;当然我们也可以对P(w,d)做如下变化:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(d,w) =\sum_{z\in Z}p(z)p(w｜z)p(d｜z)&lt;/script&gt;

&lt;p&gt;用概率图表示为:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/plsa-1.png&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于图(a),d代表文档,Z代表隐变量(文档主题),W为观察到的单词.$p(d_i)表示单词出现在文档d_i的概率$,$p(z_k｜d_i)表示在文档d_i中$,		
出现$主题z_k下的单词的序列(可以理解为主题z_k也是有一系列表现此主题的单词构成)$,$P(w_j｜z_k)表示在主题z_k下出现单词w_j的$			
概率.并且每个主题上的所有词服从多项式分布,每个文档上的所有主题服从多项式分布.整个文档的生成过程为:		&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;以$p(d_i)的概率选中文档d_i$		&lt;/li&gt;
  &lt;li&gt;以$p(z_k｜d_i)的概率选中主题z_k$		&lt;/li&gt;
  &lt;li&gt;以$p(w_j｜z_k)的概率选中词w_j$		&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;其中$(d_i,w_j)是可以可观测值,z_k是隐变量,我们的工作便是估计P(w_j｜z_k)和p(z_k｜d_i)的参数$.&lt;/p&gt;

&lt;p&gt;假设$\theta_i表示所有主题在文档d_i的一个多项式分布,则\theta_i可以表示成一个向量,每个元素\theta_{ik}$表示主题k在出现在文档i的概率,即:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z_k｜d_i) = \theta_{ik}, \sum_{z_k\in Z}\theta_{ik}=1&lt;/script&gt;

&lt;p&gt;假设$\phi_k表示所有词在主题z_k上的一个多项式分布,则\phi_k可以表示成一个向量,每个元素\phi_{kj}$表示单词j出现在主题k的概率,即:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(w_j｜z_k) = \phi_{kj},\sum_{w_j\in W}\phi_{kj} = 1&lt;/script&gt;

&lt;p&gt;所以参数评估可以形式化表现为评估参数$\Theta,\Phi$:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Theta=[\theta_1,\theta_2,...,\theta_N],d_i\in D&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi = [\phi_1,\phi_2,...,\phi_k],z_k\in Z&lt;/script&gt;

&lt;p&gt;由于词与词之间是相互独立的,且文档与文档之间也是相互独立的.所以我们可以得到整个语料库的词的分布:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(W｜d_i) =\prod_{j=1}^Mp(d_i,w_j)^{n(d_i,w_j)}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(W｜D) = \prod_{i=1}^N\prod_{j=1}^Mp(d_i,w_j)^{n(d_i,w_j)}&lt;/script&gt;

&lt;p&gt;其中,$n(d_i,w_j)表示在文档i中词j出现的次数$,当我们采用极大使然估计来实现参数评估时:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l(\Theta,\Phi)=\sum_{i=1}^N\sum_{j=1}^Mn(d_i,w_j)\log{p(d_i,w_j)} \\
					  =\sum_{i=1}^N\sum_{j=1}^Mn(d_i,w_j)\log{p(d_i)\sum_{z_k\in Z}p(w_j｜z_k)p(z_k｜d_i)} \\
					  =\sum_{i=1}^N\sum_{j=1}^Mn(d_i,w_j)(\log{p(d_i)+\sum_{z_k\in Z}\theta_{ik}\phi_{kj}})&lt;/script&gt;

&lt;p&gt;显然,对于含有隐变量的极大使然估计,因为我们不知道隐变量的分布,所以极大似然估计方法得不到参数解.这里我们可以采用EM算法进行参数评估.		&lt;/p&gt;

&lt;h2 id=&quot;em&quot;&gt;2.EM参数评估&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;EM算法可以用于含隐变量的参数评估,它是一种近似求解方法,主要是通过迭代的方法来获取近似最优解.每次迭代包含E步和M步,E步是要建立极大似然函数的下界,求得隐变量的后验分布.M步则是根据隐变量的后验分布来优化要估计的参数.&lt;/p&gt;

&lt;h3 id=&quot;e&quot;&gt;E步&lt;/h3&gt;

&lt;p&gt;在pLSA的参数估计中,可见变量是d和w,隐含变量是主题z,所以隐含变量关于d和w的后验概率为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z_k｜d_i,w_j) = \frac{p(z_k,d_i,w_j)}{\sum_{z_k\in Z}p(d_i,w_j,z_k)} \\
				 =\frac{p(d_i)p(z_k｜d_i)p(w_j｜z_k,d_i)}{\sum_{z_k\in Z}p(d_i)p(z_k｜d_i)p(w_j｜z_k,d_i)} \\
				 =\frac{p(z_k｜d_i)p(w_j｜z_k)}{\sum_{z_k\in Z}p(z_k｜d_i)p(w_j｜z_k)} \\
				 =\frac{\theta_{ik}\phi_{kj}}{\sum_{z_k\in Z}\theta_{ik}\phi_{kj}}&lt;/script&gt;

&lt;p&gt;在第一次的迭代时,会基于猜测或其他方法假定参数&lt;script type=&quot;math/tex&quot;&gt;\theta_{ik},\phi_{kj}&lt;/script&gt;的值.这样便能获得隐变量的后验分布.		&lt;/p&gt;

&lt;h3 id=&quot;m&quot;&gt;M步&lt;/h3&gt;

&lt;p&gt;在M步,将E步得到的隐变量的后验分布代入似然估计中,通过极大似然估计,更新参数&lt;script type=&quot;math/tex&quot;&gt;\theta_{ik},\phi_{kj}&lt;/script&gt;的值.似然函数的期望为:			&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E[l]=\sum_{i=1}^N\sum_{j=1}^Mn(d_i,w_j)\sum_{k=1}^Kp(z_k｜d_i,w_j)log[\theta_{ik}\phi_{kj}]&lt;/script&gt;

&lt;p&gt;这是一个多元函数求极值的问题,其中约束条件有:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{z_k\in Z}\theta_{ik}=1&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{w_j\in W}\phi_{kj} = 1&lt;/script&gt;

&lt;p&gt;将问题转化成拉格朗日乘法,得到的拉格朗日函数为:			&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H=E[l]+\sum_{k=1}^K\gamma_k(1-\sum_{j=1}^M\phi_{kj}+\sum_{i=1}^N\rho_i(1-\sum_{k=1}^K\phi_ik)&lt;/script&gt;

&lt;p&gt;这是一个关于&lt;script type=&quot;math/tex&quot;&gt;\theta_{ik}和\phi_{kj}&lt;/script&gt;的函数,分别对其求偏导,得到:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/plsa-2.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;最后求出期望最大化的新的参数值为:			&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/plsa-3.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;3.总结&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;从前面的推理来看,pLSA和LSA好像并没有什么联系.LSA是基于向量空间模型的SVD分解来进行隐空间投射,来挖掘文档之间的语义层的联系.而pLSA模型是基于层面模型的关于潜在变量的统计建模过程.我们知道pLSA是在文档和词项之间加入了一层隐含变量(主题),我们不妨做如下假定:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;U=(p(d_i｜z_k))_{i,k},V=(p(w_j｜z_k))_{j,k},\overline\sum=diag(p(z_k))_k&lt;/script&gt;

&lt;p&gt;则有&lt;script type=&quot;math/tex&quot;&gt;p=U\overline\sum V=(\sum_kp(d_i｜z_k)p(z_k)p(w_j｜z_k))_{i,j}=(p(d_j,w_j))_{i,j}&lt;/script&gt;,可见,			
&lt;script type=&quot;math/tex&quot;&gt;[U,\overline\sum,V]正是p的svd分解,p(z_k)是p的k个特征值.&lt;/script&gt;		&lt;/p&gt;

&lt;p&gt;不同的是,LSA使用特征值进进行SVD分解,则实际上是L2范数意义下对N的最好估计,而pLSA使用EM算法,使似然函数的期望达到最大.并且,pLSA的P矩阵有明确的统计意义,而LSA的这种意义不明显.&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;参考内容:&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.jqian.net/post/plsa.html&quot;&gt;主题模型之pLSA   http://blog.jqian.net/post/plsa.html&lt;/a&gt;		&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/yangliuy/article/details/8330640&quot;&gt;pLSA及EM算法    http://blog.csdn.net/yangliuy/article/details/8330640&lt;/a&gt;&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/plsa/&quot;&gt;pLSA&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on June 02, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[参数评估方法]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/parameter-estimation-approaches/" />
  <id>http://jwchennlp.github.com/parameter-estimation-approaches</id>
  <updated>2014-06-02 13:27:24 UTCT00:00:00-00:00</updated>
  <published>2014-06-02T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;pLSA和LDA主题模型是当前统计自然语言处理领域非常热门的问题,这些主题模型一般都是对文本的生成过程提出自己的概率图模型,然后利用已有的文本数据做参数评估.本文主要介绍其中会用到的三种参数评估方法,包括极大似然估计(MLE),最大后验(MAL)和贝叶斯估计.	&lt;/p&gt;

&lt;p&gt;我们主要考虑两个推理问题:		&lt;/p&gt;

&lt;p&gt;(1). 评估参数$\theta$的值以最好的拟合观察到的数据集X.		
(2). 根据已观测到的数据集X计算新的观察值$\widetilde x$的概率		&lt;/p&gt;

&lt;p&gt;第一个问题可以看成是估计问题,第二个问题可以看成是预测或是回归问题.	在贝叶斯统计中,参数估计问题可以表述为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta｜X) = \frac{p(\theta)p(X｜\theta)}{p(X)}&lt;/script&gt;

&lt;p&gt;并且我们可以用如下术语定义:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;posterior=\frac{likelihood*prior}{evidence}&lt;/script&gt;

&lt;h2 id=&quot;mle&quot;&gt;1.极大似然估计(MLE)&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;极大似然估计主要是求使似然函数值最大的参数值($\theta$),似然函数为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\theta｜X) = \prod_{x\in X}p(x｜\theta)&lt;/script&gt;

&lt;p&gt;对似然函数取对数并另偏导数为0,则可求得参数的解:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_{ML} = argmax_{\theta}L(\theta｜X) = argmax_{\theta}\sum_{x\in X}\log{p(x｜\theta)}&lt;/script&gt;

&lt;p&gt;对上述函数关于参数$\theta_k$求偏导并是的偏导值为0:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial L(\theta｜X)}{\partial \theta_k} = 0, \forall \theta_k\in theta&lt;/script&gt;

&lt;p&gt;根据已观测到的数据集X计算新的观察值$\widetilde x$的概率为:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/mle.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以抛硬币的贝努利实验为例,每次抛硬币时正面出现的概率为p(未知),假设进行抛硬币N次得到结果集合C.用极大似然估计来求解参数p:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l(p)=\sum_{i=1}^N\log{p(C=c_i｜p)} \\
	  =n^{(1)}log{p(C=1｜p)}	+n^{(0)}log{p(C=0｜p)} \\
	  =n^{(1)}log{p}+n^{(0)}log{(1-p)}&lt;/script&gt;

&lt;p&gt;其中$n^{(1)}表示N次实验结果中正面出现的次数,n^{(0)}$表示反面出现的次数.对似然函数求偏导得:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial l}{\partial p} = \frac{n^{(1)}}{p}-\frac{n^{(0)}}{1-p}=0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{p}_{ML} = \frac{n^{(1)}}{n^{(1)}+n^{(0)}}=\frac{n^{(1)}}{N}&lt;/script&gt;

&lt;p&gt;假设抛硬币20次,其中正面出现的次数为12次,则由极大似然估计得出正面出现的概率p=0.6,并且可以预测下一次抛硬币正面向上的概率为0.6．&lt;/p&gt;

&lt;h2 id=&quot;map&quot;&gt;2.最大后验估计(MAP)&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;最大后验估计(Maximum a posteriori estimation,MAP)和极大似然估计十分相似,但是最大后验估计中加入了对参数的先验信念(priori belief),它的权重设定为先验分布$p(\theta)$,最大后验估计不是要求似然函数最大化,而是要求由贝叶斯公式算出的整个后验概率最大.		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/map.png&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;和极大似然估计相比,在最大后验估计中我们需要加入先验分布的对数.先验分布可以理解为我们对事物约定俗成的看法或普遍接受的规律.例如在抛硬币的过程中,如果硬币是一枚正常的硬币,我们认为每次抛硬币正面发生的概率应该服从一个概率分布,这个概率在0.5出取得最大值,这个分布就是先验分布.先验分布的参数我们成为超参数(hyperparameter),即:	&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta) = p(\theta｜\alpha)&lt;/script&gt;

&lt;p&gt;通过最大化&lt;script type=&quot;math/tex&quot;&gt;L(\theta｜X)+\log{p(\theta)},可以得到MAP的参数估计值\hat{\theta}_{MAP}&lt;/script&gt;.当根据已有的数据预测新数据x的概率时:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\hat{x}｜X) \approx \int_{\theta\in \Theta}p(\hat{x}｜\hat{\theta}_{MAP})p(\theta｜X)d\theta=p(\hat{x}｜\hat{\theta}_{MAP})&lt;/script&gt;

&lt;p&gt;这里用beta分布来描述硬币的先验分布:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(p｜\alpha,\beta) = \frac{1}{B(\alpha,\beta)}p^{\alpha-1}(1-p)^{\beta-1}&lt;/script&gt;

&lt;p&gt;其中beta函数&lt;script type=&quot;math/tex&quot;&gt;B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}&lt;/script&gt;,函数&lt;script type=&quot;math/tex&quot;&gt;\Gamma&lt;/script&gt;是Gamma函数,可以理解为实数域的阶乘函数:&lt;script type=&quot;math/tex&quot;&gt;x!=\Gamma(x+1)&lt;/script&gt;,beta分布的变量取值范围为[0,1].下面为beta函数在不同参数($\alpha,\beta$)下的概率密度函数:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/map2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从图中可以看出,当参数取不同值时,beta函数的概率密度函数差异很大,基本上beta函数可以通过调节参数来拟合很多的概率分布.beta算是”万能”的概率分布函数.		
在前面的例子中,相信正常硬币正面发生的概率在0.5处取得最大值,所以设定$\alpha=\beta=5(其实,只要\beta=\alpha)$就能保证在0.5处的概率最大,他们的取值只是限定了他们的收敛速度(值越大概率值越密集).		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/map3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以看出与极大似然估计相比,分子项多了$\alpha-1,分母项多了\alpha+\beta-2$,这就是我们的先验信念(priori belief)在起作用,当我们对先验分布有一个很确信的认知时,如我们假设银币实验中,正面出现的概率在0.5处取最大值,并且左右波动的可能性很小,这样为了表示我们的强先验信念,我们可以将$\alpha=\beta$设定为一个大的值.这表现在公式中就可以表现为,当实验次数不多时,参数估计结果会更多的偏向于先验分布,只有当实验次数足够多时,先验估计的影响才会减弱.&lt;/p&gt;

&lt;p&gt;仍采用上面的样例,20次实验中,正面出现的次数为12次,则&lt;script type=&quot;math/tex&quot;&gt;\hat{\theta}_{MAP} = \frac{12+4}{20+8}=0.571&lt;/script&gt;,这表明”硬币是均匀的”这一先验对参数估计有影响.&lt;/p&gt;

&lt;p&gt;上面的实验是$\alpha=\beta=5$的情况,我们假设先验分布在最大值左右波动概率很大,如设定$\alpha=\beta=2$,则&lt;script type=&quot;math/tex&quot;&gt;\hat{\theta}_{MAP} = \frac{12+1}{20+2}=0.591&lt;/script&gt;,先验对参数估计的影响减弱.		&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;3.贝叶斯估计&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;贝叶斯估计对MAP做了如下扩展,参数$\theta$由一个具体的值变成参数上个的一个概率分布.这里就不再是单纯的考虑后验概率最大时的参数值,而是将参数的期望和方差信息一同考虑在内.首先通过贝叶斯准则计算后验分布:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta｜X) = \frac{p(\theta)p(X｜\theta)}{p(X)}&lt;/script&gt;

&lt;p&gt;由于我们并不是要找后验分布的最大值,所以我们需要计算P(X),由全概率公式展开的:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(X) = \int_{\theta \in \Theta}p(X｜\theta)p(\theta)d\theta&lt;/script&gt;

&lt;p&gt;当观测到新数据时,参数的后验概率会自动调整,并且通过统计分析可以最终得出后验概率分布.但是,P(X)的积分的求解十分复杂.			&lt;/p&gt;

&lt;p&gt;根据已观察到的数据来预测观测一个新数据的概率为:			&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/map4.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;对于抛硬币的贝努利实验,假设N次试验得到的试验结果集合C,这里我们加入beta(5,5)的先验信念,在MAP中我们要求后验概率的最大值,在贝叶斯估计中我们要求	满足beta分布的参数的期望.		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/map5.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$Beta(\alpha,\beta)分布的均值,&amp;lt;p｜\alpha,\beta&amp;gt;=\alpha(\alpha+\beta)^{-1},方差V(p｜\alpha,\beta)=\alpha\beta(\alpha+\beta+1)^{-1}(\alpha+\beta)^{-2}$,根据之前的统计,评估结果为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
&lt;P｜C&gt; = \frac{n^{1}+\alpha}{n^{1}+n^{0}+\alpha+\beta}=\frac{n^{1}+5}{N+10} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;V(p｜\alpha,\beta)=\frac{(n^{1}+\alpha)(n^{0}+\beta)}{(N+\alpha+\beta+1)(N+\alpha+\beta)^2}=\frac{(n^{1}+5)(n^{0}+5)}{(N+11)(N+10)^2}&lt;/script&gt;

&lt;p&gt;当20次试验中有12次出现正面时,均值为17/30=0.567,方差为17&lt;em&gt;13/(30$&lt;/em&gt;31^2$)=0.0079.		&lt;/p&gt;

&lt;p&gt;对于上述三种方法的参数估计结果如下图所示:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140530/map6.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;参考内容:&lt;/h3&gt;

&lt;p&gt;Gregor Heinrich:Parameter estimation for text analysis	&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/yangliuy/article/details/8296481&quot;&gt;文本语言模型的参数估计 http://blog.csdn.net/yangliuy/article/details/8296481&lt;/a&gt;		&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.jqian.net/post/lda.html&quot;&gt;主题模型之lda http://blog.jqian.net/post/lda.html&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/parameter-estimation-approaches/&quot;&gt;参数评估方法&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on June 02, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Latent Semantic Analysis]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/lsa-topic-model/" />
  <id>http://jwchennlp.github.com/lsa-topic-model</id>
  <updated>2014-05-30 11:01:55 UTCT00:00:00-00:00</updated>
  <published>2014-05-30T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;&lt;strong&gt;LSA的目标是在找到一个数据映射之后能很好的词汇层面信息的同时能够表示不同实体间的语义关系&lt;/strong&gt;		&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;1.向量空间模型&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;在信息检索领域,需要对文本语料进行建模,使得能够实现高效进行语料检索的同时保留文本的主要信息.当前采用较多的是向量空间模型.向量空间模型可以看作是一个文本-词项矩阵(matrix&lt;em&gt;{mn}),假设整个语料库有m篇文档,语料库的词项总数为n个,则对每一篇文档,我们用一个n维的向量来描述这个文档,向量中的每一维表示文档中词的权重,权重的度量方法可以有多种(tf,tf-idf),当我们采用tf-idf方法时,对于得到的矩阵中的某一元素,m&lt;/em&gt;{ij}表示的是此项w_j在文档d_i中的tf-idf值.向量空间模型基于词袋方法(bag of words)构建文档-词项矩阵,词袋方法也就是说我们之关注文档中出现的词,而不关注文档中词的顺序.&lt;/p&gt;

&lt;p&gt;对于用响亮空间模型来描述的文档,每个文档都是一个关于词项的向量,当我们要衡量两个文档的相似度时,我们只要求两个向量之间的相似度.当两个文档向量的相似度为1时,说明两个文档完全相同,当两个文档向量的相似度为0时,说明两个向量完全不相关.		&lt;/p&gt;

&lt;p&gt;假设我们有两篇文档$d_1,d_2$:		&lt;/p&gt;

&lt;p&gt;$d_1为”The product of apple is excellent”,d_2为”Iphone is popular in world”$,两篇文档的词袋为{the product of apple is excellent iphone,popular,in world}.如果我们按照词袋的词序用tf(词项在文档中出现的次数)描述词的权重时,两篇文档的文档向量可以表述为:		&lt;/p&gt;

&lt;p&gt;$d_1=[1,1,1,1,1,1,0,0,0,0],d_2=[0,0,0,0,1,0,1,1,1,1]$,当我们要衡量两个文档的相似度时,两个文档向量的相似度为$\frac{d_1*d_2}{｜d_1｜｜d_2｜}=0.182$,可以认为两篇文档相似度很低.其实返回文档,我们发现文档1说的是苹果公司的产品很好,文档2说的是Iphone手机很受欢迎,可以理解为apple和iphone来说是比较相近的.		&lt;/p&gt;

&lt;p&gt;向量空间模型用规范化的格式(每个文档都是一个定长的向量)来对文档进行建模,且每个词的权重可以通过tf-idf等方式进行很好的度量,所以向量空间模型在描述文档信息方面是比较有效的.但是向量空间模型很难识别文档中的同义词和一词多义情况,这从文档的向量空间模型表述中可以看出来,文档中的每一个词项都在文档向量的某一维中表述出来,所以当文档中出现相似词时,相似词的权重是在不同维度中描述的,并且当一个词在文档中有多个含义时,词的多个含义在文档向量中也只是在某一维中描述.&lt;/p&gt;

&lt;h2 id=&quot;latent-semantic-analysis&quot;&gt;2.Latent Semantic Analysis&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;针对向量空间模型的这些缺点,我们可以采用LSA方法.LSA主要是对按向量空间模型构建的文档-词项高维矩阵映射到一个低维的隐语义空间.LSA的目标是在找到一个数据映射之后能很好的词汇层面信息的同时能够表示不同实体间的语义关系.		&lt;/p&gt;

&lt;p&gt;LSA依靠奇异值分解(SVD)将文档的向量空间模型矩阵映射到低维空间.这里我们先介绍一下SVD的概念.		&lt;/p&gt;

&lt;h3 id=&quot;svd&quot;&gt;奇异值分解(SVD)&lt;/h3&gt;

&lt;p&gt;当矩阵是方阵的时候,我们可以通过球特征值,来描述矩阵中的重要特征.奇异值分解能描述任意矩阵中的重要特征,对于矩阵A:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A_{mn}=U_{mm}\sum_{mn}V^T_{mm}&lt;/script&gt;

&lt;p&gt;其中U和V都是正交矩阵,即$UU^T=VV^T=I,\sum中对角线外的其他元素都为0,对角线上元素为奇异值$.		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A^TA=(U\sum{V^T})^T(U\sum{V^T}) \\
  	 =V\sum{^T}U^TU\sum{V^T} \\
  	 =V\sum{^T}\sum{V^T}&lt;/script&gt;

&lt;p&gt;因为U为正交矩阵,所以$A^TA的的特征值为\sum{^T}\sum中对脚线上的非0值$.		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A^TAv_i=\lambda_iv_i&lt;/script&gt;

&lt;p&gt;$v_i表示上面的右奇异响亮V^T$,此外我们可以得到:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma_i=\sqrt{\lambda_i}  \\
  u_i = \frac{1}{\lambda_i}Av_i&lt;/script&gt;

&lt;p&gt;这里的$\sigma就是上面说的奇异值,u_i是有奇异向量U,奇异值矩阵\sum$中对角线上的奇异值是按从大到小顺序排列的,奇异值的大小可以理解为特征的重要程度,奇异值越大,描述的特征就越重要.&lt;/p&gt;

&lt;p&gt;现在回到LSA的讨论中,我们知道LSA通过SVD来将向量空间映射到隐语义空间,主要实现过程是,对奇异值矩阵,我们只取对角线上的前K个奇异值,其余奇异值设为0,现在我们得到的向量空间为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\overline{A} =U_{mk}\sum_{kk}V^T_{kn}\approx 	U_{mm}\sum_{mn}V^T_{nn}=A&lt;/script&gt;

&lt;p&gt;映射后的向量空间会近视等于原始的向量空间是因为,对奇异值矩阵进行了处理,只保留了前k个最大的奇异值,奇异值中值越大的说明所描述的特征越重要,奇异值越小说明所描述的特征贡献越弱,且奇异值在对角线上的减少程度很大,所以所除去前k个最大的奇异值,剩下的非0的奇异值说描述的特征贡献很弱.所以映射后的向量空间与初始向量空间接近.		&lt;/p&gt;

&lt;p&gt;说明一点:正常情况下,按照向量空间模型构建的向量空间是非常稀疏的,当采用LSA进行隐语义空间映射后,向量空间的稀疏性会减弱,这可能有助于计算文档之间的联系,尽管文档之间不存在很多相同的词项.	&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;参考资料&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html&quot;&gt;机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用 http://leftnoteasy.cnblogs.com&lt;/a&gt;		&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/kemaswill/archive/2013/04/17/3022100.html&quot;&gt;Latent Semantic Analysis(LSA/ LSI)算法简介 http://www.cnblogs.com/kemaswill/&lt;/a&gt;	&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/lsa-topic-model/&quot;&gt;Latent Semantic Analysis&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on May 30, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[EM算法]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/em-algorithm/" />
  <id>http://jwchennlp.github.com/em-algorithm</id>
  <updated>2014-05-20 02:57:12 UTCT00:00:00-00:00</updated>
  <published>2014-05-20T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;EM算法可以用于含有隐含变量的参数评估问题.		&lt;/p&gt;

&lt;h2 id=&quot;jesen-&quot;&gt;Jesen 不等式&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;当函数f为凸函数时,我们知道$f^{\prime\prime}(x)\geq0,如果函数f的输入为向量时,则其半正定矩阵H\geq0$Jesen不等式可以描述为:		&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;  f是一个凸函数,X是一个随机变量,则:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E[f(X)]\geq{f(EX)}&lt;/script&gt;

&lt;p&gt;并且如果f是严格凸函数($f^{\prime\prime}(x)&amp;gt;0),则E[f(X)]\geq{f(EX)}$当且仅当p(X)=P(EX)=1,即X是一个常数.		&lt;/p&gt;

&lt;p&gt;通过下面的图可以有个更清晰的认知:			&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0520/1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如图可知f为严格凸函数,假设x有0.5的概率取值为a(p(x=a)=0.5),有0.5的概率取值为b,则变量x的期望应当为E[X]=$\frac{a+b}{2}$,期望x值应该是a和b的中点,E(f(x))=$\frac{f(a)+f(b)}{2}$,可以知道$E[f(X)]\geq{f(EX)}$,并且我们知道,只有当X取一个值的概率为1时,有$E[f(X)]={f(EX)}$&lt;/p&gt;

&lt;h2 id=&quot;em&quot;&gt;EM算法&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;假设我们有一个关于m个独立样本集${x^{(i)},…,x^{(m)}}$的参数评估问题,样本集中包含了隐含变量z,我们需要估计模型P(x,z)的参数$\theta,参数\theta$的最大似然估计为:		
&lt;script type=&quot;math/tex&quot;&gt;l(\theta) = \sum_{i=1}^m\log{p(x^{(i)};\theta)} \\
			=\sum_{i=1}^m\log\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta)&lt;/script&gt;		&lt;/p&gt;

&lt;p&gt;其中$z^{(i)}是隐含随机变量,如果z^{(i)}是可观测的$,那么通过极大似然估计便可以求得参数解.		&lt;/p&gt;

&lt;p&gt;EM算法给出了实现参数评估的一种有效的方法,精确的最大化$l(\theta)可能很困难,这里我们可以采用如下的替代策略:在E步不断的建立l(\theta)的下界$,并且在M步优化下界.通过这两个步骤的迭代过程来实现$l(\theta)的最大化$.&lt;/p&gt;

&lt;p&gt;假设$Q_i是变量z的分布,则有\sum_zQ_i(z)=1,_i(z)\geq0$,则可以得到:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l(\theta) = \sum_{i=1}^m\log{p(x^{(i)};\theta)}  \\
			=\sum_{i=1}^m\log\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\theta) \\
			=\sum_{i=1}^m\log\sum_{z^{(i)}}Q_i{z^{(i)}}\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i{z^{(i)}}}  \\
			\geq\sum_{i=1}^m\sum_{z^{(i)}}Q_i{z^{(i)}}\log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i{z^{(i)}}}&lt;/script&gt;

&lt;p&gt;公式的第三步到第四步运用到了Jesen不等式,$\log(x)函数是严格凹函数,所以E[f(X)]\leq{f(EX)},其中Q_i{z^{(i)}}表示变量z^{i}$的概率分布,$\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i{z^{(i)}}}表示变量为z^{i}的函数$,第三步表示的是函数的期望,又由于函数是凹函数,所以其值要大于等于期望的函数.&lt;/p&gt;

&lt;p&gt;现在给定了关于隐含变量的分布$Q_i,我们可以得知l(\theta)的下界,对于Q_i有许多选择,我们该如何选择呢?当我们猜测一个初始的\theta值时$,E步所要实现的就是希望我们的替换的$l(\theta)不断的贴近真实l(\theta)的下界,我们从Jesen不等式可以知道E[f(X)]={f(EX)}$的充分必要条件是x为一个常数,也就是说:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i{z^{(i)}}}=c(常数)&lt;/script&gt;

&lt;p&gt;又$\sum_{z}Q_i(z^{(i)})=1$		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{z}p(x^{(i)},z^{(i)};\theta)=c\sum_{z}Q_i(z^{(i)})=c&lt;/script&gt;

&lt;p&gt;可以得到:			&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q_i(z^{(i)})=\frac{p(x^{(i)},z^{(i)};\theta)}{\sum_{z}p(x^{(i)},z^{(i)};\theta)} \\
			  =\frac{p(x^{(i)},z^{(i)};\theta)}{p(x^{(i)};\theta)} \\
			  = p(z^{(i)}｜x^{(i)};\theta)&lt;/script&gt;

&lt;p&gt;这样在初始猜测一个参数$\theta后,的出z^{(i)}在x^{(i)}和参数\theta下的后验概率分布,即可以得到隐含变量的分布Q^{(i)}$.		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0520/2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;证明收敛&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这里需要证明算法最终是否会收敛,假设$\theta^{(t)}和\theta^{(t+1))}为两个EM算法成功迭代的参数值,我们需要证明l(\theta^{(t)})\leq{l(\theta^{(t)})}$,如果不等式成立的话,也就是说每次迭代都使得似然估计的值变大.当我们已经通过迭代获得了$\theta^{(i)}$,我们将通过E步选择$Q_i(z^{(i)})=p(z^{(i)}｜x^{(i)};\theta),由于我们知道在E步的时候因为要建立l(\theta^{(t)})的下界$,所有根据Jesen不等式必须有:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0520/3.png&quot; alt=&quot;images&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对上面等式的右边通过极大似然估计获得$\theta^{(t+1)}$,并且:			&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0520/4.png&quot; alt=&quot;images&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;第一个不等式是是由于:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0520/5.png&quot; alt=&quot;images&quot; /&gt;	&lt;/p&gt;

&lt;p&gt;对任意的$Q^{(i)}和\theta都成立,这里设定Q^{(i)}=Q_t{(t)},\theta=\theta^{(t+1)},第二个不等式成立是因为\theta^{(t+1)}$是通过如下计算获得:			&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0520/6.png&quot; alt=&quot;images&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果我们定义:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0520/7.png&quot; alt=&quot;images&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过之前的推导我们知道$l(\theta)\geq{J(Q,\theta)}$,那么EM算法也可以看作是J函数上的坐标上升算法,E步相当依据猜测或上步迭代的$\theta来最大化Q_i,M步相当于根据根据Q_i优化\theta$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考内容&lt;/strong&gt;		&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html&quot;&gt;JeeryLead(EM算法)&lt;/a&gt;	&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/abcjennifer/article/details/8170378&quot;&gt;Rachel-Zhang(EM算法原理)&lt;/a&gt;		&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8537620&quot;&gt;zouxy09(从最大似然到EM算法浅析)&lt;/a&gt;			&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/em-algorithm/&quot;&gt;EM算法&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on May 20, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[逻辑回归]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/logistic-regression/" />
  <id>http://jwchennlp.github.com/logistic-regression</id>
  <updated>2014-05-18 11:25:41 UTCT00:00:00-00:00</updated>
  <published>2014-05-18T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;对于逻辑回归函数，我们的假设方程为：		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_\theta(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}&lt;/script&gt;

&lt;p&gt;其中，$g(z)=\frac{1}{1+e^{-z}}$称之为sigmoid函数。		&lt;/p&gt;

&lt;p&gt;那么为什么要在逻辑回归里使用sigmoid函数呢，观察逻辑回归的假设方程可以发现，如果没有使用sigmoid函数，假设方程与线性回归的假设方程是一样的。但是很显然，线性回归的假设方程的值域为$(-\infty,+\infty)$,而二分类问题一般去之都是固定的值{0,1}.这个时候我们可以使用sigmoid函数，它的作用相当与实现了一个映射，将$(-\infty,+\infty)$值域映射到（0,1）之间。		&lt;/p&gt;

&lt;p&gt;我们假定：	
&lt;script type=&quot;math/tex&quot;&gt;P(Y=1｜Ｘ;\theta)=h_\theta(x) \\
	P(Y=0｜Ｘ;\theta)=1-h_\theta(x)&lt;/script&gt;	&lt;/p&gt;

&lt;p&gt;上面公式我们可以合并成：		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y｜Ｘ;\theta)=(h_\theta(x))^y(1-h_\theta(x))^{1-y} &lt;/script&gt;

&lt;p&gt;假设有ｍ个训练集并且相互独立，这参数的似然方程可以表述为：		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\theta)=p(y｜x;\theta) \\
		   =\prod_{i=1}^mP(y^{(i)}｜x^{(i)};\theta) \\
		   =\prod_{i=1}^m(h_\theta(x^{(i)})^{y^{(i)}}(1-h_\theta(x^{(i)}))^{\left(1-y^{(i)}\right)}&lt;/script&gt;

&lt;p&gt;下面可以采用最大似然估计来求出参数值：			&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l(\theta)=logL(\theta) \\
		   =\sum_{i=1}^my^{(i)}logh(x^{(i)})+(1-y^{(i)})\log(1-h(x^{(i)}))&lt;/script&gt;

&lt;p&gt;而后对参数$\theta_j$求偏导:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial\theta_j}l(\theta) = \sum_{i=1}^n(y^{(i)}\frac{1}{g(\theta^Tx^{(i)})}-(1-y^{(i)})\frac{1}{1-g(\theta^Tx^{(i)})})\frac{\partial}{\partial\theta_j}g(\theta^Tx) \\
	= \sum_{i=1}^n(y^{(i)}\frac{1}{g(\theta^Tx^{(i)})}-(1-y^{(i)})\frac{1}{1-g(\theta^Tx^{(i)})})g(\theta^Tx)(1-g(\theta^Tx))\frac{\partial}{\partial\theta_j}\theta^Tx \\
	= \sum_{i=1}^m(y^{(i)}(1-g(\theta^Tx))-(1-y^{(i)})g(\theta^Tx))x_j \\
	=\sum_{i=1}^m(y^{(i)}-h_\theta(x))x_j&lt;/script&gt;

&lt;p&gt;可以看出，通过极大似然估计来求解参数在逻辑回归中很难实现．		&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;梯度下降&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;在线性回归中，我们的代价函数是这么定义的：		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta) = \frac{1}{m}\sum_{i=1}^m(y^{(i)}-h_\theta(x^{(i)}))^2&lt;/script&gt;

&lt;p&gt;将我们的假设方程$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$代入上面的代价方程会发现代价函数是一个非凸函数，所以很难获得最优解．		
这里我们需要重新定义代价函数：		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta) = \frac{1}{m}\sum_{i=1}^mCost(y^{(i)},h_\theta(x^{(i)}))&lt;/script&gt;

&lt;p&gt;其中　		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0518/1.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;$h&lt;em&gt;\theta(x)与Cost(y^{(i)},h&lt;/em&gt;\theta(x^{(i)}))$之间的关系如下图所示：		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0518/2.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;当ｙ＝１时，如果假设方程$h_\theta(x)=1$,代价函数为０，如果代假设方程越接近０，则代价函数越大．			&lt;/p&gt;

&lt;p&gt;当ｙ＝０时，如果假设方程$h_\theta(x)=０$,代价函数为０，如果代假设方程越接近１，则代价函数越大．		&lt;/p&gt;

&lt;p&gt;可以将代价方程组合为如下格式：		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cost(y,h_\theta(x))=-y\log{h_\theta(x)}-(1-y)\log{(1-h_\theta(x))}&lt;/script&gt;

&lt;p&gt;那么含有ｍ个样例的数据集的代价代价函数可以表示为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta)=\frac{1}{m}\sum_{i=1}^m-y^{(i)}\log{h_\theta(x^{(i)})}-(1-y^{(i)})\log{(1-h_\theta(x^{(i)}))}&lt;/script&gt;

&lt;p&gt;而后，我们可以按如下方式不断的更新$\theta$值，指导代价函数达到最优值，这个时候的所的参数便为解．		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_j  =  \theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta) \\
		   =  \theta_j-\alpha\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}&lt;/script&gt;

&lt;p&gt;在之前讨论过的文本分类问题中，我们对每一类别用互信息特征选择方法选择100个特征，文档集的特征总数为741个，用这些特征构建向量空间模型，用逻辑回归进行测试（用scikit-learn工具包），Ｆ_1值能达到86.6%,具体如下图所示：		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0518/3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;正则化&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;为了避免过拟合现象,可以采用正则化方法.正则化方法是结构风险最小化策略的实现,是在经验风险上加上一个正则化项(regularizer)或罚项(penalty).正则化项一般是模型复杂度的单调递增函数,模型越复杂,正则化值就越大.		&lt;/p&gt;

&lt;p&gt;$L_2$正则化代价函数定义为:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0518/4.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;当我们采用梯度下降发求解参数时,$\theta$按如下方式进行迭代:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0518/5.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;$L_1$正则化代价函数定义为:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\theta)=\frac{1}{m}[\sum_{i=1}^m-y^{(i)}\log{h_\theta(x^{(i)})}-(1-y^{(i)})\log{(1-h_\theta(x^{(i)}))}]+\frac{\lambda}{2m}\sum_{i=i}^n｜\theta_j｜&lt;/script&gt;

&lt;p&gt;采用$L_1$正则化一般可以产生稀疏解,也就是说我们得到的参数解$\theta中会有很多位为0,这这可以理解为\theta_j=0$对应的特征的贡献为0,我们可以直接忽略这些特征.		&lt;/p&gt;

&lt;p&gt;为了避免模型的过拟合,我们还可以通过减少特征数目,只选取对模型有很强分类能力或贡献的强特征,从而提出那些表示能力较差的弱特征.这在特征选择中有讲解.同时,我们也可以通过交叉验证的方式进行来查模型是否产生过拟合.		&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;随机梯度下降法&lt;/h2&gt;

&lt;p&gt;从上面的梯度下降可以知道,在每次对$\theta进行迭代的过程中,我们要通过整个训练集更新\theta值$.那么当训练集非常大的时候,显然更新参数将变得非常耗时.随机梯度下降法可以弥补这些缺点.&lt;/p&gt;

&lt;p&gt;在随机梯度下降法中,我们定义代价函数为一个单一训练实例的代价:		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;cost(\theta,(x^{(i)},y^{(i)}))=\frac{1}{2}(h_{theta}(x^{(i)})-y^{(i)})^2&lt;/script&gt;

&lt;p&gt;伪代码如下:		&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/0518/6.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;随机梯度下降算法在每一次计算之后便更新参数$\theta$,而不需要在整个训练集上进行迭代.随机梯度法比梯度下降法运算速度要快,但是缺点是,随机梯度下降法不是每一步都朝着”正确”的方向迈出的,因此,算法虽然会逐渐走向全局最小值的位置,但是无法达到全局最优解,而是在最优解附近振荡.		&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;在线算法和批处理算法&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;批处理和在线学习算法都是基于梯度下降原理实现的,批处理需要每次计算时都要考虑整个训练集的数据,并找到一个最快下降方向进行迭代.而在线学习算法只着眼于当前的某一观测值.前者的优点是收敛速度快,缺点是计算复杂.后者的优点是计算量小,收敛速度慢.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/logistic-regression/&quot;&gt;逻辑回归&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on May 18, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[文本分类]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/test-classification/" />
  <id>http://jwchennlp.github.com/test-classification</id>
  <updated>2014-05-14 11:01:12 UTCT00:00:00-00:00</updated>
  <published>2014-05-14T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;文本分类问题在机器学习和信息检索领域都有比较广泛的运用．这里将主要介绍自己实现的一些分类模型和实践过程中应该注意的地方．&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;朴素贝叶斯&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;朴素贝叶斯模型在很多问题的处理过程中都相当有效，因为其过程和想法都很简单，只需要对数据集进行处理而不存在训练的过程，在很多场合下都作为解决问题的一个基线.&lt;/p&gt;

&lt;p&gt;对于某一文本x,x表示文本的所有词，我们需要求文档所属的类别p(y｜x),我们可以进行如下转换:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; p(y｜x) = \frac{p(x,y)}{p(x)} ＝arg\max_yp(x｜y)P(y)　\\
          =arg\max_y\prod^n_\left(i=1\right)p(x_i｜y)P(y)
&lt;/script&gt;

&lt;p&gt;公式从第一步到第二步我们做了一个假设，也就是说在给定ｙ的情况下，$x_i$的出现与否对$x_j$的出现与否没有影响，即：      &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;p(x_j|x_i,y)=P(x_j|y)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;在实现朴素贝叶斯方法有两种操作，一种是贝努利模型，一种是事件模型，下面分开讨论.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;在计算$arg\max_y\prod^n_\left(i=1\right)p(x_i｜y)$因为分母很大，经常会出现数据过小超出所能表示的范围而使得结果为０，这里有两种处理方法:        &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;上式中分母一般为某一类别下文档数和文档类别的累加（平滑）或某一类别下文档的词数和词典大小的累加，我们可以初始设定每次都用一个常熟(100或1000)来代某一类别i的分母，而后其余类别，其分母则可以表示为100*(文档ｊ对应的词数)／（文档ｉ类别的词数）.            &lt;br /&gt;
*　也可以对上述公式&lt;script type=&quot;math/tex&quot;&gt;arg\max_y\prod^n_\left(i=1\right)p(x_i｜y)P(y)&lt;/script&gt;     &lt;br /&gt;
转换成对数公式$arg\max_y\sum^n_\left(i=1\right)\log{p(x_i｜y)}+\log{P(y)}$来进行求解.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-1&quot;&gt;贝努利模型&lt;/h3&gt;

&lt;p&gt;我们用ｘ来表示文档，那么对文档中的词，只要出现，无论出现多少次，我们都标记词的出现次数为１．可以认为贝努利模型对文档进行了单词的去重操作.如文档为＂i like you,you like me＂，那么ｘ为{i,like,you,me}     &lt;/p&gt;

&lt;p&gt;在进行文档处理的时候，我们应该进行词条化，去除标点符号，这里我用nltk工具包进行了词的小写处理.（实验数据是路透社的新闻语料）．下图为贝努利模型下朴素贝叶斯的分类结果. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140514/1.png&quot; alt=&quot;image&quot; /&gt;    &lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;事件模型&lt;/h3&gt;

&lt;p&gt;正常情况下，文档中有些词是出现多次的，对于这些词，我们不单考虑词是否出现，并且在计算的过程中考虑词出现的次数，这便是朴素贝叶斯的事件模型，这个时候的词可以表示为{$word_i:count_i,…,word_n:count_n$},上面的文档用事件模型应该表示为{i:1,like:2,you:2,me:1}.下图为事件模型下朴素贝叶斯的分类结果.        &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140514/2.png&quot; alt=&quot;image&quot; /&gt;        &lt;/p&gt;

&lt;p&gt;在次基础上，对文档进行取出停用词操作，分类结果如下：      &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140514/3.png&quot; alt=&quot;image&quot; /&gt;      &lt;/p&gt;

&lt;p&gt;发现比不去除停用词效果差一些，正常情况下停用词大多数文档中出现频率较高的无意义词，这些次对表现文档主旨是没有很大作用的，但是取出停用词可能会使得所要表达的语义不一致．      &lt;/p&gt;

&lt;h4 id=&quot;section-3&quot;&gt;拉普拉斯平滑&lt;/h4&gt;

&lt;p&gt;我们在计算$p(x_i｜y)$的时候，如果在某一类被$y_i$中，词$x_i$没有在任何一篇文档中出现，那么显然属于此类别的概率为０．并且我们知道已经标记好的训练集不可能涵盖所有的词，所以这种情况出现的概率很高．这里我们一般运用拉普拉斯平滑来处理. 
所以$p(x_i｜y)=\frac{count(x_i)+1}{count(allwords)+v}$.      &lt;/p&gt;

&lt;p&gt;当我们使用贝努利模型的时候，$count(x_i)$表示在训练集类别ｙ的所有文档中出现词$x_i$的文档个数，$count(allwords)$表示类别ｙ的所有文档中词典的大小（文档所有词去重）.V表示类别ｙ的文档的大小．      &lt;/p&gt;

&lt;p&gt;当使用事件模型的时候，$count(x_i)$表示在训练集类别ｙ的所有文档中出现词$x_i$的次数，$count(allwords)$表示类别ｙ的所有文档中总共的词数（不去重）.V表示类别ｙ的文档的词典的大小．      &lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;我们发现，采用朴素贝叶斯模型的分类效果还不错，在事件模型下F_1值能达到83%．但是贝努利模型和事件模型的效果差别比较大，并且在不同类别上的分类效果上差别比较大．我们知道事件模型考虑到了文档中词出现的次数，这是造成差异的原因，文档中的词不能单纯的只考虑词是否出现，文档中词出现的次数对文档主旨和类别的贡献还是有很大差异的．尤其是在长文档中，词频繁出现的概率会很大，所以采用贝努利模型的话会造成很大的误差．      &lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;特征选择&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;当我们想实现如逻辑回归，支持向量机这一类算法的时候，我们发现我们需要考虑关于如何表示文档的问题．在朴素贝叶斯中我们对每个文档只要维护他的词表，或是词－出现次数词典．而在逻辑回归模型中我们知道特征大多是一个定长向量的来表示的．        &lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;向量空间模型&lt;/h3&gt;

&lt;p&gt;当我们想表述一个事物时，我们会获得这个事物的若干特征，当我们获得一个事物集合时，我们可以知道这个事物集合的所有特征ｆ，那么我们便建立长度为length（ｆ）一个向量,其中向量中的每一维表示一个特征．那么当我们描述一个事物时，则初始化一个长度为ｆ的向量，并将事物出现的特征添加到向量中去.     &lt;/p&gt;

&lt;p&gt;例如，给我们一个文档语料的训练集，这个训练集的词典长度为2000，所以我们可以建立一个长为2000的向量来表示一篇文档，当然向量的每一维和每个单词是对应的（对应关系可以自己设定，如向量的第一位表示词ｉ,向量的第二个词表示you…）,当文档为｛you i you｝是，则文档响亮可以表示为[1,2,0…]         &lt;/p&gt;

&lt;p&gt;当用向量空间模型表示文档的时候，有以下两个问题：        &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;有些词只在测试集中出现而不在训练集中出现，我们知道向量是根据训练集中的词数目来建立的．所以只在测试集中出现的词不能在向量中表示(在朴素贝叶斯中通过平滑方法解决).     &lt;/li&gt;
  &lt;li&gt;当我们表示一篇文档时，文档中的词会比训练集的词典的词少很多．也就是说我们用向量表示文档时，文档中会出现很多0,这种现象称之为稀疏化．稀疏化在模型训练过程中会对训练结果产生很大的影响．同时，向量过为稀疏的话，我们将耗费大量空间来表示这些文档．并且将这些文档在内存中处理的时候，很容易导致内存溢出．如对于路透社7MB的新闻语料，词典长度为22818,用向量空间表示这些文档时，所耗费的空间为650MB.       &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们知道，训练集很难涵盖所有的特征，所以这个问题也很难解决．我们可以假设我们的训练集总够完善，则测试集中出现的新词的概率很小，对文档类别贡献很小，所以可以直接不考虑这些词．    &lt;br /&gt;
第二个问题我们可以采用主成分分析(pca)进行降维，这里我们主要考虑一些常用的特征抽选择方法．&lt;/p&gt;

&lt;p&gt;特征选择有以下两个目的:        &lt;/p&gt;

&lt;p&gt;1 通过减小有效的词汇空间来提高分类器训练和应用的效率．      &lt;br /&gt;
2 特征选择能够去除噪音特征，从而提高分类的精度．　&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;互信息&lt;/h3&gt;

&lt;p&gt;一个常用的计算互信息的方法是计算词项t和类别c的MI(expected mutual information,期望互信息)作为A(t,c).MI度量的是词项的存在与否的给类别c的正确判断所带来的信息.MI的形式化定义如下：     &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I(U;C) = \sum_\left(e_t\in{0,1}\right)\sum_\left(e_c\in{0,1}\right)P{(U=e_t,C=e_c)}\log\frac{P(U=e^t,C=e_c)}{P(U=e_t)P{(C=e_c)}}&lt;/script&gt;

&lt;p&gt;其中，Ｕ是一个二值随机变量，当文档包含词项t时，$e_t=1$,否则取值为0．而c也是一个二值随机变量，当文档属于类别c时，$e_c=1$,否则为0.   &lt;br /&gt;
当我们采用MLE(maximize likehood estimate，极大似然估计),公式等价于:      &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I(U;C)=\frac{N_{11}}{N}\log\frac{NN_{11}}{N_1N_1}+\frac{N_{01}}{N}\log\frac{NN_{01}}{N_0N_1}+\frac{N_{10}}{N}\log\frac{NN_{10}}{N_1N_0}+\frac{N_{00}}{N}\log\frac{NN_{00}}{N_0N_0}&lt;/script&gt;

&lt;p&gt;其实可以这么理解，$N_11$表示的是类别为正例，且词项出现的文档数目，而对数中的$N_1N_1$表示的是类别问正例的文档数和词项在文档中出现的文档数，为了简化，表示符号一样，但是前者用于表示类别，后者用于表示词项．        &lt;/p&gt;

&lt;p&gt;同时，我们可以用熵来表示互信息，他是指两个信息之间的相关性.两个时间X和Y的互信息定义为：     &lt;br /&gt;
I(X;Y) = H(X) - H(X｜Y)=H(Y) - H(Y｜X) = H(Y)+H(X) - H(X,Y)&lt;/p&gt;

&lt;p&gt;对每个类别用互信息最高的抽取10个词,结果如下：        &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140515/1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以发现，每个类别下的词与此类别都是很相关的．      &lt;/p&gt;

&lt;p&gt;在实验过程中我们对每个类别取用互信息最高100个词进行特征，这里采用贝努利事件模型进行训练，分类结果如下：      &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140515/2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;发现F_1值有了很大的提升，也就是说互信息在特这个选择的时候可以良好的去除噪声特征．并且极大的提高了运行效率．     &lt;/p&gt;

&lt;p&gt;等等，结果好像不对，分类效果会有提升，但是不会提升这么多.检查代码后确实发现了错误，我们知道我们用对每个类别用互信息选择出了k个词，那么我们在朴素贝叶斯的计算过程如何表示文档呢？这个时候我们应该确定一点的就是我们的特征（词）应该是每个类别的k个词所组成的并集，所以我们在对训练集和测试集中的文档进行特征选择时，我们的参考系应该是所有类别的k个词组成的并集，而不能是某个类别的词。这点要注意…       &lt;/p&gt;

&lt;p&gt;下面是每个类别抽取互信息最高的特征词采用朴素贝叶斯事件模型的分类效果。       &lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;特征数&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;F_1值(%)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;79.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;20&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;80.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;50&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;82.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;100&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;85.5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;x2&quot;&gt;$X^2$统计量&lt;/h3&gt;

&lt;p&gt;在统计学中，$X^2$统计量常常用于检测两个事件的独立性。两个事件A和B独立，是指A和B两个事件的概率满足P(AB)=P(A)P(B)或者P(B|A)=P(B).在特征选择中，两个事件分别表示词项的出现和类别的出现。此时我们按照如下公式计算：     &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;X^2(D,t,c)=\sum_{e_t\in{0,1}}\sum_{e_c\in{0,1}}\frac{(N_{e_te_c}-E_{e_te_c})^2}{E_{e_te_c}}&lt;/script&gt;     &lt;/p&gt;

&lt;p&gt;$X^2$度量的是期望值N和观测值E的偏离程度。$X^2$统计量大则意味着独立性假设不成立，此时期望值和观测值相差不大。如果两个事件独立，那么词项的出现也会使得某个类别的出现更加可能或更加不可能，因此它适合于作为特征被选出来。这就是$X^2$特征选择方法的基本原理。       &lt;/p&gt;

&lt;p&gt;如P($X^2$&amp;gt;6.63)&amp;lt;0.01,也就是说如果两个事件的$X^2$统计量大于6.63,那么有99%的可能性来拒绝两个事件的独立性假设。      &lt;/p&gt;

&lt;p&gt;我们用P($X^2$&amp;gt;6.63)&amp;lt;0.01来做特征选择，采用朴素贝叶斯时间模型的分类效果如下： &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/140515/x.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-8&quot;&gt;基于频度的特征选择方法&lt;/h3&gt;

&lt;p&gt;基于频度的特征选择方法是选择那些在类别中出现频率较高的词项作为特征，这里的频度可以定义为文档频率(类别c中包含词项t的文档数目)或文档集频率(类别c中所包含的文档中t出现的总次数)，文档频率适合于贝努利模型，而文档集频率更适合于多项式模型。&lt;/p&gt;

&lt;p&gt;这里要注意一点，我们知道在用互信息或卡方检验来实现特征抽取时，我们的参考点是类别c和词项t之间的关系，也就是说对文档集来说可能有多个类别，每个类别都维护一个词典，那么现在便是对每个类别及这个类别中的词典中的词来计算互信息或卡方统计量，并且将每个类别中取出一些特征最后所有这些特征进行融合，组成整个文档的特征。那我们用频率统计的时候，便不用这么麻烦了，我们需要维护整个文档集的词典，并且在整个文档集下进行计算，找出频度最高的k个词作为文档集的特征。&lt;/p&gt;

&lt;p&gt;采用基于文档频率的方法可能会将很多常用词当作特征抽取出现，但是这些词对类别的贡献很小，如i,he，she，如果对文档进行那个预处理，去除停用词后在用基于频度的方法选取特征，效果会更好。		&lt;/p&gt;

&lt;h3 id=&quot;section-9&quot;&gt;信息增益&lt;/h3&gt;

&lt;p&gt;熵是随机变量不确定性的度量，设X是一个取有限个值的离散随机变量，其概率分布为：		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X=x_i)=P_i,i=1,2,...,n&lt;/script&gt;

&lt;p&gt;则随机变量X的熵定义为：		&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(X)=-\sum_{i=1}^np_i\log(p_i)&lt;/script&gt;

&lt;p&gt;若$p_i=0$,则定义$0log0=0$,熵只依赖于X的分布，与X的取值无关。熵越大，随机变量的不确定性就越大。条件熵H(Y｜X)表示在已知随机变量X的条件下Y的不确定性，随机变量X给定条件下Y的条件熵H（Y｜X）定义为X给定条件下Y的概率分布的熵对X的数学期望。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(Y｜X)=\sum_{i=1}^np_iH(Y｜X=x_i),这里p_i=P(X=x_i),i=1,2...n&lt;/script&gt;

&lt;p&gt;信息增益（information gain）表示得知X的特征信息而使得类Y的信息不确定性减少的程度。		&lt;/p&gt;

&lt;p&gt;特征A对训练数据集D的信息增益g(D,A)，定义为数据集D的经验熵H(D)与特征A给定条件下的经验条件熵H(D｜A)之差，即：			&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g(D,A)=H(D)-H(D｜A)&lt;/script&gt;

&lt;p&gt;具体到文本分类过程中某一词项ｔ的信息增益可以表述为：      &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(C｜t)=P_tH(C｜t)+P_{\overline{t}}H(C｜\overline{t}) \\
        =-P_t\sum_{i=1}^{k}P(C_i｜t)-P_{\overline{t}}\sum_{i=1}{k}P(C_i｜\overline{t})&lt;/script&gt;

&lt;p&gt;上面的公式中$p_t$表示在文档集中词项ｔ出现的文档的比例．&lt;/p&gt;

&lt;h2 id=&quot;section-10&quot;&gt;不同特征选取方法的比较&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;MI和$X^2$是完全不同的两种特征选择方法。即使词项t几乎不携带任何有关文档归属类别c的信息，t和c的独立性假设有时也可能在置信度很高的情况下被拒绝，对于罕见词尤其如此。由于$X^2$基于显著统计性来选择特征，因此他会比MI选出更多的罕见词，而这些词项对于分类是不太可靠的。对于两种特征选择方法来说，最小效果基本相当，对于$X^2$特征选择方法，最优解来的迟一些，则可能是因为$X^2$开始选择的具有统计显著性的词没有覆盖类别中的所有文档。然而，在特征空间数量增多时，$X^2$表现出比MI更好的效果。&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/test-classification/&quot;&gt;文本分类&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on May 14, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[阿里大数据竞赛方法总结]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/odps-model/" />
  <id>http://jwchennlp.github.com/odps-model</id>
  <updated>2014-05-09 06:17:38 UTCT00:00:00-00:00</updated>
  <published>2014-05-09T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;section&quot;&gt;逻辑回归&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;特征抽取&lt;/h3&gt;
&lt;p&gt;将前四个月的数据切分成4:1,为了训练模型，前一部分数据用于抽取特征ｘ，后一部分用于获取类别ｙ．具体描述为，根据每个用户对每个物品的行为没一个数据，如果行为在第一部分，但是在第二部分没有购买行为，这类别为负例，若在第二部分出现购买行为，这此行为为正例．如果行为只在第二部分产生，则次用户对物品的行为无效，直接剔除．  &lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;模型训练&lt;/h3&gt;
&lt;p&gt;在得出了模型的正例和负例之后，因为正例负例差很多，不能直接进行训练．这里采取的策略是按比例对负例进行采样，采样后结合正例进行训练．模型训练直接用xlab平台的逻辑回归进行训练．    &lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;预测结果&lt;/h3&gt;
&lt;p&gt;在训练完模型之后，我们按照相同的方法对所有前４个月的数据进行特征抽取．并用训练好的模型进行预测．预测后，会返回每个数据属于哪一类别的概率，我们可以通过限定概率值得到最终结果．&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;存在改进的地方&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;没有对数据进行去噪声操作．     &lt;/li&gt;
  &lt;li&gt;对负例的采样比例的设定．      &lt;/li&gt;
  &lt;li&gt;模型训练时的迭代次数，及是否可以通过多次采样对多次结果进行加权获取最终结果．&lt;/li&gt;
&lt;/ul&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/odps-model/&quot;&gt;阿里大数据竞赛方法总结&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on May 09, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[支持向量机]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/support-vector-machine/" />
  <id>http://jwchennlp.github.com/support-vector-machine</id>
  <updated>2014-05-08 06:22:02 UTCT00:00:00-00:00</updated>
  <published>2014-05-08T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;section&quot;&gt;问题引出&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;在面对一个最简单的二分类问题，并且假设数据集可分的情况下．具体如下图所示．当我们采用逻辑回归实现分类时，我们用一个分类超平面（决策边界）对数据进行数据进行划分，并在划分后，不同类别的数据分布在分类超平面的两边，这表示分类成功．其实，在数据可分的情况下，我们发现可以有很多条这样的分类超平面，并且都能达到正确分类的效果,这个时候我们可能要问，这些分类超平面的效果一样吗？是否存在一个最优的分类超平面．
&lt;img src=&quot;../images/140508/1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;函数间隔和几何间隔&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;函数间隔&lt;/h3&gt;

&lt;p&gt;对于上面数据集，我们计算出了一个超平面$w^Tx+b=０$.对于某一个数据点x我们需要判断其内别,如果$w^Tx+b＞0$，则其类ｙ=1，并且如果$w^Tx+b＞0$并且$w^Tx+b$值越大，则这个点的类别为正例的置信度就越高．当$w^Tx+b＜0$时,点所属类别为－１，并且$w^Tx+b$值越小，这这个点类别为负例的置信度就越高．并且当点ｘ被正确分类时，$y(w^T+b)$为正数．从上面图中可以看出，我们设定分类超平面的上部为正例，A,B,C三个的点都被标记为正例，但是C离决策边界最近，可能稍微变化决策边界就可能导致分类错误，所以C分类正确的置信读低．A离决策边界最远，所以Ｃ被分为正例的置信读高.对于点$\left(x^\left(i\right),y^\left(i\right)\right)$为了获得更好的分类效果，我们希望$y\left(i\right)(w^Tx+b)$尽量大，则分类的置信度就越高．&lt;/p&gt;

&lt;p&gt;所以，对数据$\left(x^\left(i\right),y^\left(i\right)\right)$，我们就定义$y\left(i\right)(w^Tx+b)$为此数据点的函数间隔，并且如果使得每个点的函数间隔都倾向于一个大值，则分类置信度越高，分类效果越好．   &lt;/p&gt;

&lt;p&gt;给定训练集合S={($x^\left(i\right),y^\left(i\right)）$,i=1,…m},我们需要计算每一个样本点到分类超平面的函数间隔.在这里，我们需要求出最小的函数间隔，并且通过修改分类超平面使得最小函数间隔尽可能大，则分类效果更好．     &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\widehat{\gamma}=\min_{i=1,...,m}\widehat\gamma^\left(i\right)&lt;/script&gt;

&lt;p&gt;利用函数间隔来衡量分类效果的置信度有一个缺陷，当我们确定某一个分类超平面$w^Tx+b=0$，我们对ｗ,b同时增加ｋ倍,函数间隔由原来的$y\left(w^Tx+b\right)$变成$ky\left(w^Tx+b\right)$．也就是说某一数据点的函数间隔可以可以任意的缩放或增加．&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;几何间隔&lt;/h3&gt;

&lt;p&gt;在确定分类超平面之后，任一数据点到分类超平面的距离应该是不变的．如果我们用这个距离来衡量分类置信度的话，效果会很好．    &lt;br /&gt;
&lt;img src=&quot;../images/140508/2.png&quot; alt=&quot;image&quot; /&gt;  &lt;br /&gt;
点A到平面的距离设为$\gamma$,知道分类超平面的法向量为ｗ，那么将A投影到分类超平面上的点B的坐标为$x-\frac{w}{\left|w\right|}\gamma$,且点在决策边界$w^Tx+b=0$上，所以有:        &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^T\left(x-\frac{w}{｜w｜}\gamma\right)+b=0&lt;/script&gt;

&lt;p&gt;求解得$\gamma=\frac{w}{｜w｜}x+\frac{b}{｜w｜}$,所以对所有的样本点点$\left(x^\left(i\right),y^\left(i\right)\right)$,我们求得每个样本点的几何间隔为:      &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma^\left(i\right)=y^\left(i\right)\left(\frac{w}{｜w｜}x^\left(i\right)+\frac{b}{｜w｜}\right)&lt;/script&gt;

&lt;p&gt;给定训练集合S={($x^\left(i\right),y^\left(i\right)）$,i=1,…m},我们需要计算每一个样本点到分类超平面的几何距离.在这里，我们需要求出最小的几何距离，并且通过修改分类超平面使得最小几何距离尽可能大，则分类效果更好．        &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma=\min_{i=1,...,m}\gamma^\left(i\right)&lt;/script&gt;

&lt;h2 id=&quot;section-4&quot;&gt;最优间隔分类器&lt;/h2&gt;

&lt;p&gt;当给定训练集之后，按照前面分析直观上最好的分类效果是找到决策边界使得(几何)间隔最大化.因为我们的决策是使得最小几何间隔最大化，则显然对所有点的分类的置信度很高．所以当对于一个线性可分的数据集，我们要通过一个分类超平面来分割所有的正例和负例．那么我们的问题可以转化成下面的优化问题:   &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_{\gamma,w,b}   \gamma \\
 s.t.    y^\left(i\right)\left(\frac{w}{|w|}x^\left(i\right)+\frac{b}{|w|}\right)\geq\gamma,i=1,...,m
&lt;/script&gt;

&lt;p&gt;由于我们知道在确定了(w,b)之后，我们可以通过同比例的缩放或增加(w,b),所以我们可以通过相应的扩张比例使得｜w｜的值为１．所以优化问题转化成如下形式：     &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_{\gamma,w,b}   \gamma \\
 s.t.    y^\left(i\right)\left(wx^\left(i\right)+b\right)\geq\gamma,i=1,...,m　\\
 |w|=1
&lt;/script&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;通过约束&lt;/td&gt;
      &lt;td&gt;w&lt;/td&gt;
      &lt;td&gt;=1,使得函数间隔等于几何间隔．但是因为如上的优化问题是非凸问题，我们很难通过软件来进行求解．所以我们将第一个问题转化成如下问题:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_{\gamma,w,b}:  \frac{\widehat\gamma}{|w|} \\
 s.t.    y^\left(i\right)\left(wx^\left(i\right)+b\right)\geq\widehat\gamma,i=1,...,m
&lt;/script&gt;

&lt;p&gt;其中$\widehat\gamma$代表的是最小函数间隔，我们知道函数间隔是可以通过(w,b)的同比例变化而变化，这里为了为了简化计算，我们将$\widehat\gamma$设为１．那么如上的优化问题变为:     &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_{\gamma,w,b}:  \frac{1}{|w|} \\
 s.t.    y^\left(i\right)\left(wx^\left(i\right)+b\right)\geq 1,i=1,...,m
&lt;/script&gt;

&lt;p&gt;进一步转变，优化问题变成如下格式：       &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\gamma,w,b}: \frac{1}{2}w^2 \\
 s.t.    y^\left(i\right)\left(wx^\left(i\right)+b\right)\geq 1,i=1,...,m
&lt;/script&gt;

&lt;h2 id=&quot;section-5&quot;&gt;拉格朗日算子&lt;/h2&gt;

&lt;p&gt;对于如下的原始优化问题：    &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; \min_w:f(w) \\
s.t.:g_i(w)\leq0,i=1,...k  \\
h_i(w)=0,i=1,...l   
&lt;/script&gt;

&lt;p&gt;其拉格朗日算子为&lt;script type=&quot;math/tex&quot;&gt;L(w,\alpha,\beta)=f(w)+\sum_\left(i=1\right)^k\alpha_ig_i(w)+\sum_\left(i=1\right)^l\beta_ih_i(w)&lt;/script&gt;,其中$\alpha_i,\beta_i$为拉格朗日乘数．      &lt;br /&gt;
考虑如下等式：     &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_p(w)=\max_\left(\alpha,\beta:\alpha_i\geq0\right)L(w,\alpha,\beta)&lt;/script&gt;

&lt;p&gt;其中ｐ表示原始的,我们发现当给定ｗ，并且ｗ满足我们原始问题的约束（$g_i(w)\leq0，h_i(w)=0$），如果ｗ违背这些约束，则显然$\theta_p(w)=\infty$,当ｗ满足原始问题约束时，$\theta_p(w)=０$．那么可以的出如下结论：  &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_w\theta_p(w)=\min_w\max_\left(\alpha,\beta:\alpha_i\geq0\right)L(w,\alpha,\beta)&lt;/script&gt;

&lt;p&gt;同时我们定义$p^*=\min_w\theta_p(w)$为原始问题的解．   &lt;br /&gt;
现在对应它的对偶问题：     &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_\left(\alpha,\beta:\alpha_i\geq0\right)\theta_d(p)=\max_\left(\alpha,\beta:\alpha_i\geq0\right)\min_wL(w,\alpha,\beta)&lt;/script&gt;

&lt;p&gt;我们知道，最大最小问题的解小于最小最大问题的解：     &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d^*=\max_\left(\alpha,\beta:\alpha_i\geq0\right)\min_wL(w,\alpha,\beta)\leq\min_w\max_\left(\alpha,\beta:\alpha_i\geq0\right)L(w,\alpha,\beta)=p^*&lt;/script&gt;

&lt;p&gt;当ｆ和$g_i$为凸函数时，$h_i$为仿射函数(仿射变换的定义是在几何空间中，一个向量空间进行一次线性变换并接上一个平移，变换成另一个向量空间)，有$d^＊=p^＊$，在这些约束下，一定存在一个$w^＊$是原始问题的解，$\alpha^＊,\beta^＊$是对偶问题的解，并且有$d^＊=p^＊=L(w^＊,\alpha^＊,\beta^＊)$,同时这３个参数满足KKT条件，KKT条件描述如下：    &lt;br /&gt;
&lt;img src=&quot;../images/140508/3.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;其中第三个约束称为对偶互补条件，并且当$a_i＞０$时，$g_i(w^*)=0$,满足这些条件的点所对应的几何间隔便是最小几何间隔．这些点称为支持向量.&lt;/p&gt;

&lt;p&gt;现在回到优化边界分类器部分,我们的原始问题定义为：       &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\gamma,w,b}: \frac{1}{2}w^2 \\
 s.t.    y^\left(i\right)\left(wx^\left(i\right)+b\right)\geq 1,i=1,...,m
&lt;/script&gt;

&lt;p&gt;约束条件可以表示为：        &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;g_i(w)=-y^\left(i\right)(w^Tx\left(i\right)+b)+1\leq0&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;../images/140508/4.png&quot; alt=&quot;image&quot; /&gt;    &lt;/p&gt;

&lt;p&gt;我们可以看到，有最小几何间隔的点离决策边界最近．我们知道这些点$\left(x^\left(i\right),y\left(i\right)\right)$满足$g_i(w)=0$.我们将这些点称之为支持向量．从上图知道，数据集中有３个支持向量，一般来说支持向量的个数会明显小于数据集的大小，这在后面会相当有用．      &lt;/p&gt;

&lt;p&gt;原始问题的拉格朗日算子可以表示为：      &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(w,b,\alpha)=\frac{1}{2}w^2-\sum_{i=1}^m\alpha_i[y^\left(i\right)(w^Tx\left(i\right)+b)+1]&lt;/script&gt;

&lt;p&gt;这个时候我们通过求对偶问题$\theta_p(w)$来求原始问题的解．具体方法是对Ｌ函数关于参数ｗ和ｂ求偏导数：    &lt;br /&gt;
&lt;img src=&quot;../images/140508/5.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;../images/140508/6.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;../images/140508/7.png&quot; alt=&quot;image&quot; /&gt;      &lt;br /&gt;
将得到的约束代回到上面的拉格朗日算子中．得到：          &lt;br /&gt;
&lt;img src=&quot;../images/140508/8.png&quot; alt=&quot;image&quot; /&gt;
&lt;img src=&quot;../images/140508/9.png&quot; alt=&quot;image&quot; /&gt;      &lt;br /&gt;
最后原始问题的对偶优化问题可以定义为：            &lt;br /&gt;
&lt;img src=&quot;../images/140508/10.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在假定我们已经求得对偶问题最优解的$\alpha_i$，那么我们是如何做预测的呢？对于一个新的数据点ｘ，我们知道预测是通过判断$w^Tx+b$的值来判定的，如果大于０，类别为正例，如果小于０，类别为负例,我们将上面求解的ｗ值代入：         &lt;br /&gt;
&lt;img src=&quot;../images/140508/11.png&quot; alt=&quot;image&quot; /&gt;		&lt;/p&gt;

&lt;p&gt;我们知道$\alpha_i\geq0$,且根据KKT约束条件中的对偶互补条件$\alpha_ig_i(w)\geq0$,并且$\alpha&amp;gt;0$时，$g_i(w)=0$,表示这些点有最小的几何间隔，也就是说这些点表示支持向量．我们知道，在判断ｘ类别的时候，我们只需要考虑$\alpha_i&amp;gt;0$的情况，也对应的我们只需要考虑数据集中的支持向量．同时，支持向量想对于数据集来说是小很多的．这样很显然可以进行高效求解.&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/support-vector-machine/&quot;&gt;支持向量机&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on May 08, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[生成模型和判别模型]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/generative-model-and-discriminative-model/" />
  <id>http://jwchennlp.github.com/generative-model-and-discriminative-model</id>
  <updated>2014-05-07 11:40:02 UTCT00:00:00-00:00</updated>
  <published>2014-05-07T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;section&quot;&gt;定义&lt;/h2&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
  &lt;p&gt;生成方法由数据学习联合概率分布P(x,y)，然后求出条件概率分布P(y｜ｘ)作为预测的模
型，即成生模型:  &lt;br /&gt;
&lt;img src=&quot;../images/140507/1.png&quot; alt=&quot;image&quot; /&gt; &lt;br /&gt;
这样的方法成为生成方法，是因为模型表示了给定输入ｘ产生输出ｙ的生成关系．典型的生成模型有，朴素贝叶斯和隐马尔可夫模型．  &lt;br /&gt;
判别方法是由数据直接学习决策函数ｆ(x)或者条件概率分布P(y｜x)作为预测的模型，即判别模型，判别方法关心的是对给定的输入x,应该预测什么样的输出ｙ，典型的方法包括感知机，决策树，逻辑回归．   &lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-1&quot;&gt;理解&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;在面对猫狗分类问题时，我们该如何实现呢？  &lt;br /&gt;
方法一：当我们利用逻辑回归或是感知机模型时，我们需要数据集所投射的空间中，找到一个决策边界，在决策边界一边的属于一类动物，在决策边界另一边的属于另一种动物．当来一个我们不知道的动物时，我们将它放入空间中，通过判断它在决策边界的那一侧来判断是猫还是狗． &lt;br /&gt;
方法二：将数据集中的猫都拿出来，建立一个关于猫的特征的模型．按同样的方法建立一个关于狗的模型．这样，当判断一个动物时，我们分别查看它在猫模型中属于猫的概率和在狗模型中属于狗的概率，哪个值大，便说明属于哪个模型．   &lt;/p&gt;

&lt;p&gt;方法一通过对数据集训练出一个模型，并通过判断P(y|x)下的条件概率来判断ｙ的类别．这种方法成为判别方法，对应建立的模型属于判别模型．   &lt;br /&gt;
方法二对数据集的每一个类别建立一个模型，并通过联合概率P(x,y)来判断ｘ特征所应对应的类别．这种方法成为生成方法．  &lt;/p&gt;

&lt;p&gt;其实通过联合概率来判断类别进行了一个变形，一般我们是要判断P(y|x)下的概率，可以进行如下转换： &lt;br /&gt;
&lt;img src=&quot;../images/140507/1.png&quot; alt=&quot;image&quot; /&gt;  &lt;br /&gt;
对于某个参数ｘ，其概率值P(x)值在所有类别下都是相同的，所以问题便等同于如下问题：            &lt;br /&gt;
&lt;img src=&quot;../images/140507/2.png&quot; alt=&quot;image&quot; /&gt;        &lt;/p&gt;

&lt;p&gt;不妨通过一个朴素贝叶斯生成模型来了解生成模型的判定过程．
如图，训练集包含４篇文档，我们需要验证测试集中的文档类别： &lt;br /&gt;
&lt;img src=&quot;../images/140507/3.png&quot; alt=&quot;iamge&quot; /&gt;    &lt;/p&gt;

&lt;p&gt;我们需要计算每一个类别下P(x｜y)P(y)的概率，并且概率最大的那一类便是文档所属类别．即计算P((Chinese,chinese,Chinese,Tokyo,Japan)｜y=c)P(y=c)和P((Chinese,chinese,Chinese,Tokyo,Japan)｜y=$\bar{c}$)P(y=$\bar{c}$)．&lt;/p&gt;

&lt;p&gt;之后利用朴素贝叶斯的的条件独立定义进行求解便能获知测试及属于哪个类别．&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/generative-model-and-discriminative-model/&quot;&gt;生成模型和判别模型&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on May 07, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[索引压缩]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/index-compress/" />
  <id>http://jwchennlp.github.com/index-compress</id>
  <updated>2014-05-06 09:01:16 UTCT00:00:00-00:00</updated>
  <published>2014-05-06T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h3 id=&quot;section&quot;&gt;为什么要进行索引压缩？&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;进行索引压缩有以下优点：  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;节省磁盘空间．  &lt;/li&gt;
  &lt;li&gt;增加高速缓存(cache)的利用率.&lt;br /&gt;
倒排索引词典是放在内存中的，倒排记录表放在磁盘上．对与到拍记录上的某些词项ｔ，我们是需要经常访问的，如果将这次词项ｔ所对应的到拍记录表压缩后放在高速缓存中，只要采用得当的解压缩算法，那么当查询词项ｔ的倒排记录表时，只需要访问cache，而不用从磁盘读取数据，能充分减少IR系统的响应时间． &lt;/li&gt;
  &lt;li&gt;压缩能够加快从磁盘读取数据的速度．&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;压缩技术分为有损压缩和无损压缩，有损压缩指的是压缩后，原始数据的所有信息都保存下来了．词干还原，大小写转换都属于有损压缩．   &lt;/p&gt;

&lt;h3 id=&quot;heaps&quot;&gt;Heaps定律：词项数目的估计&lt;/h3&gt;

&lt;p&gt;heaps定律认为，文档集大小和词汇量之间存在对数上的线性关系.它将词项的数目估计为文档集大小的函数:&lt;script type=&quot;math/tex&quot;&gt;M=kT^b&lt;/script&gt;,其中Ｔ代表文档集合中的词条的个数． &lt;/p&gt;

&lt;p&gt;不同文档集下ｋ取值差异较大，因为词汇量大小取决于文档本身以及对他进行处理的方式．当进行词干还原，大小写转换时将降低词汇量增长的速度，允许加入数字和容忍拼写错误则会增加增长率．无论参数取值如何，heaps定律满足一下两条性质：    &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;词汇量会随着文档集的增加而增加，不会趋于一个定值．     &lt;/li&gt;
  &lt;li&gt;大规模文档集的词汇量也会很大．       &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;zipf&quot;&gt;Zipf定律：词项在文档中的分布&lt;/h3&gt;
&lt;p&gt;Zipf定律用于估计词项在文档中分布，假设$t_1$用于表示文档集中出现最多的词，$t_2$用于表示文档集中出现第二多的词，文档集合中出现第i多的词的文档频率$cf_i$与$\frac{1}{i}$成正比:   &lt;br /&gt;
    &lt;script type=&quot;math/tex&quot;&gt;cf_i=k\frac{1}{i}&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;词典压缩&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;section-2&quot;&gt;为什么要进行词典压缩&lt;/h3&gt;
&lt;p&gt;理想情况下在建立好索引后，我们希望将词典存放在内存中，但是这往往很难实现，尤其是对于实用的搜索引擎和嵌入式系统．限制IR系统的响应之间的一个因素包多对磁盘的访问次数．所以，如果通过压缩来讲所有的或大部分的词典存入内存，将大大加快IR系统的响应速度．    &lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;将词典看作单一字符串的压缩方法&lt;/h3&gt;
&lt;p&gt;采用如下的数据结构进行存储：一个定长的数组用于存储词项（２０Ｂ），４Ｂ的空间用于存储文档频率，４Ｂ的空间用于存储指向倒排记录表的指针．对于一个包含Ｍ个词项的文档空间来说，词典的总空间为M*(20+4+4),当Ｍ＝400,000时，占用空间为11.2MB.
&lt;img src=&quot;../images/1/dic_compress_1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种方法存在很大的不足，首先大部分的英文词平均长度为8B,这显然造成了大部分的空间浪费，其次也存在有些词的长度超过20B,导致的结果便是不能存储这些词．&lt;/p&gt;

&lt;p&gt;我们可以采用如下的改进措施，我们建立一个字符串在存储字典中的所有词项,4B的空间存储文档频率,4B的空间存储倒排记录表的指针，这个指针指向前面所有词典构成的长字符串，在长字符串中我们需要每一个词加入一个定位指针，用于指定下一个词的开始位置和当前词的结束位置，由于有400,000个词，每个词为８B,所以寻址空间为400,000&lt;em&gt;8=3.2&lt;/em&gt;$10^6$,所以可以用一个长为$\log{3.2&lt;em&gt;10^6}$$\approx$22b，即３Ｂ的指针来表示．词典的总空间为M&lt;/em&gt;(4+4+3+8)=7.6MB．  &lt;br /&gt;
&lt;img src=&quot;../images/1/1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;按块存储&lt;/h3&gt;
&lt;p&gt;对上面的压缩方法进行一个变形，这里不再对每个词项都维护一个指向字符串(所有词的组合)的指针．我们首先将我们的词典按块进行划分，例如每５个词为一块，这样对没一个块只需要维护一个这个块指向字符串的指针，同时在长字符串中，我们需要加入一个空间用于指定当前词的长度．在这种机制下，假设一个块内有ｋ个词，我们减少了(k-1)个指针的空间，但是我们需要在字符串中对没个词增加空间以记录其词的长度．假设每个块内有４个词，减少的指针空间为9B,同时对４个词需要增加４Ｂ的空间用于记录词的长度，所以没４个词产生了5B的压缩，所以压缩的空间为400,000*$\frac{1}{4}$*5=0.5MB.    &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;我们在这里维护了两个指针，一个用于指向倒排记录表，一个指向字符串用词项的位置，我们压缩的部分是词项指针．   &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/1/2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们发现，每个块内的词越多时，则可以压缩的空间越大．但是并非块内词越多越好，在进行词项查找时，对于块间的词我们可以通过二分查找快速定位，但是在快内查找时则是简单的线性遍历，所以我们必须在查找速度和空间压缩见进行权衡．    &lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;倒排记录表的压缩&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;倒排记录表的压缩基于下面一个前提，当用文档ID来表示倒排记录表，对与高频词来说，倒排记录表中的记录多并且相邻的记录之间差距会很小，当某高频词出现在某篇文档中时，将其相近的文档中出现高频词的概率会很大．这就给我们提供了对倒排记录表进行压缩的灵感，正常情况下我们对到拍记录表中的每个文档id,都是用定长的空间来存储的，那么对那些高频词的话，我可以通过存储他们倒排记录表相邻的距离（明显小于存储文档id的长度）来达到压缩的目的．     &lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;可变字节码&lt;/h3&gt;
&lt;p&gt;VB(Variable byte,可变字节)码的思想为，我们采用整数个字节来存储文档id,每个字节的后７位为有效编码，第一位为延续位，表示本次编码的结束与否,’1’表示结束．     &lt;/p&gt;

&lt;p&gt;可变字节码的解码过程如下，根据延续位（一直获取字节直到字节的首位为１）来获取编码结果，对编码结果进行以下处理，去除所有的延续位，剩余有效编码表示间隔位，将此编码值与前一个编码的结果进行累加即表示文档的ID. 
&lt;img src=&quot;../images/1/3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-7&quot;&gt;γ编码&lt;/h3&gt;

&lt;p&gt;一元编码：将数值为ｎ的数用ｎ个１并在之后加上一个０来表示的编码方式．  &lt;/p&gt;

&lt;p&gt;γ编码主要由两部分组成，偏移量(offset)和长度(length)．长度是数组的二进制编码，但是去除了首位１，长度则是偏移量的长度，但是是通过一元编码的方式实现．对于数值5,二进制编码是101,去掉首位的１，其偏移量是01,偏移量长度为２，则由一元编码表示为110,所以数值５的γ编码为11001.
&lt;img src=&quot;../images/1/4.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们发现对数值为Ｋ的数进行二进制编码，其偏移量的长度为$\lfloor\log{k}\rfloor$,其长度的长度为$\lfloor\log{k}\rfloor$+1,所以，数的γ编码长度为２$\lfloor\log{k}\rfloor$＋１．      &lt;/p&gt;

&lt;p&gt;有一点不太明白的是采用γ编码是如何实现数据压缩的呢？书的原文是这么说的：      &lt;br /&gt;
&lt;img src=&quot;../images/1/5.png&quot; alt=&quot;image&quot; /&gt;
按上面理解，采用ｎ为进行进行表示，那么间距在1~$2^\left(n-1\right)－１$之间都将产生浪费，并在在间距为$2^n$时不能表示．&lt;/p&gt;

&lt;p&gt;我的理解是这样的，我们有对倒排记录表的实现一般也是通过链表或是定长数组来实现的，当采用定长的编码格式来存储每个文档ＩＤ时，必然会产生很大的浪费．那么如何通过变长的编码格式并且不需要额外的数组或指针来表明文档的长度，这边是γ编码所做的事了，让我们看一下γ编码的的解码过程：11001,我们首先遍历该编码，知道遇到０时停止，发现长度为２，剩下的偏移量为01,我们知道实际的二进制数为101,也就是说我们通过编码本身可以确定文档id,不需要进行额外的存储．&lt;/p&gt;

&lt;h4 id=&quot;section-8&quot;&gt;参考资料&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://www.google.com.hk/search?q=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;oq=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;aqs=chrome..69i57j69i65j69i61l3j0.3218j0j1&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;索引压缩&lt;/a&gt;     &lt;br /&gt;
&lt;strong&gt;说明：&lt;/strong&gt;文章主要内容和图片来自信息检索导论一书。&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/index-compress/&quot;&gt;索引压缩&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on May 06, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[odps_sql]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/odps-sql/" />
  <id>http://jwchennlp.github.com/odps-sql</id>
  <updated>2014-04-26 14:45:37 UTCT00:00:00-00:00</updated>
  <published>2014-04-26T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;odps(open data processing service，开源数据处理服务)是阿里巴巴的分布式计算平台。&lt;/p&gt;

&lt;p&gt;数据以sql表格的形式存放在odps中，我们可以是使用类似与sql命令的方式对数据进行操作。当让sql中嵌入了odps平台自己的函数和命令。&lt;/p&gt;

&lt;p&gt;文档学习ing…&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;表格建立&lt;/h2&gt;

&lt;p&gt;创建表格语句如下：   &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;&lt;span class=&quot;lineno&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;lineno&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shop_name&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;      
&lt;span class=&quot;lineno&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;     
&lt;span class=&quot;lineno&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitioned&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sale_date&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;region&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;     
&lt;span class=&quot;lineno&quot;&gt;5&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;--创建一张分区表sales&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;partitioned by指定了分区字段，采用分区字段主要是在跟新，新增和读取分区数据时不需要做全表扫描，可以提高效率。       &lt;/p&gt;

&lt;p&gt;可以用命令create table…as select…来新建表格，如：        &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;&lt;span class=&quot;lineno&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sales1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;      
&lt;span class=&quot;lineno&quot;&gt;2&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;这样在建立表格的同时，将sales的数据复制到新表中，但是原表格的分区字段没有复制到新表中。如果希望新表格和原表格有相同的数据和表结构（分区属性）.可以用create table… like …命令：    &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;&lt;span class=&quot;lineno&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sales1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;like&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sales&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/odps-sql/&quot;&gt;odps_sql&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 26, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[索引构建]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/index-construction/" />
  <id>http://jwchennlp.github.com/index-construction</id>
  <updated>2014-04-24 06:09:41 UTCT00:00:00-00:00</updated>
  <published>2014-04-24T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;索引构建主要是对建立好的词典中的每个词项，构建词项关于文档集合的索引记录表。一般索引构建算法会受硬件设施的制约。    &lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;硬件基础&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;构建信息检索系统时，很多决策都依赖于系统所运行的硬件环境。与信息检索系统相关的硬件基本性能参数如下：      &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;系统访问内存中数据的速度比访问硬盘中数据要快的多，访问内存中的一个字节只需要几个时钟周期（大约5×10-9s），从磁盘传输一个字节的时间则长得多（大概2×10-8s）。因此，为了更快的响应速度，我们应该尽可能将数据放在内存中，特别是那种频繁访问的数据。这种将频繁使用的数据放入内存中的机制称为caching（缓存）。    &lt;/li&gt;
  &lt;li&gt;进行磁盘读写时，磁头移动到数据所在的磁道需要一定的时间，该时间称为寻道时间，对典型的磁盘来说平均在5ms左右。寻道过程中并不进行数据的传输。于是，为了时数据传输率最大，连续读取的数据块也应该在磁盘上连续存放。      &lt;/li&gt;
  &lt;li&gt;操作系统往往以数据块为单位进行读写。因此，从磁盘读取一个字节和一个数据块所耗费的时间可能一样多。我们将内存中保存读写块的那块区域称之为缓冲区（buffer）。       &lt;/li&gt;
  &lt;li&gt;数据从磁盘传输到内存是由系统总线而不是处理器来实现的，这以为着在磁盘I/O时处理器仍然可以处理数据。我们可以利用这一点来加速数据的传输过程，比如将数据压缩后存储在磁盘上。假定采用一种高效的解压缩算法的话，那么从磁盘读取压缩数据再解压缩所花时间往往比直接读取未压缩数据所花时间少。       &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;基于块的排序索引方法&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;第一章建立倒排索引时，所有的处理过程都是在内存中完成的。我们将文档一次性读入内存，而后建立文档的词典，并建立词典中的词项的倒排记录表。如果当文档集过大，大到难以一次性读入内存时，上述方法便失效。   &lt;/p&gt;

&lt;p&gt;由于内存的不足，我们可以采用磁盘的外部排序的方法（external sorting algorithm）。我们知道读取数据过程中的寻道时间与数据传输相比是十分耗时的，所以我们应该尽量将数据按块的方式存储以减少寻道的次数。BSBI（blocked sort-based indexing algorithm，基于块的排序索引算法）是一种解决的方法。算法实现如下：     &lt;br /&gt;
第1步：将文档切分成均匀的若干个部分。   &lt;br /&gt;
第2步：对每个部分的词项ID-文档ID对排序。  &lt;br /&gt;
第3步：将中间产生的临时排序结果存储在磁盘上。   &lt;br /&gt;
第4步：将所有的中间文件合并形成最终结果。   &lt;/p&gt;

&lt;p&gt;在第2步中我们将词项用词项id代替，词项id是能代表词项的唯一标识，这样做能提高索引构建效率。&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;      
           
&lt;span class=&quot;n&quot;&gt;BSBIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;construction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;     
&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;      
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;documents&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;have&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;been&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;processed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;        
&lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;                 
    &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ParseNextBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;       
    &lt;span class=&quot;n&quot;&gt;BSBI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INVERT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;            
    &lt;span class=&quot;n&quot;&gt;WriteBlockToDisk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      
    &lt;span class=&quot;n&quot;&gt;MergeBlocks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmerge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      
             
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;合并时，同时打开所有块对应的文件，内存中维护10个块的读缓冲区和一个为最终合并索引准备的写缓冲区。每次迭代中，利用优先级队列（即堆结构）或者类似的数据结构选择最小的未处理词项id进行处理。读入该词项的倒排记录表进行合并，合并结果返回磁盘中。需要时，再次从文件中读入数据到每个读缓冲区。  &lt;/p&gt;

&lt;p&gt;由于该算法主要的时间耗费在排序上，因此其时间复杂度为O（T*logT),其中T是要排序的项目数的上界（即词项ID-文档—ID对的个数），然而，实际的索引构建的时间往往取决与文档温习（ParseNextBlock）和最后合并（MergeBlocks）。&lt;/p&gt;

&lt;p&gt;由于我们知道，为了提高索引构建效率，我们将词项映射成词项ID，初始的倒排记录表形式为：     &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;      
    &lt;span class=&quot;n&quot;&gt;wordi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;doc2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.....|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;docn&lt;/span&gt;                    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;在进行词项id的映射之后，每个词项ID-文档ID对就是简单的（wid,did）的形式了。这样做为什么能提高效率呢？虽然映射过程需要话费一定的时间，可是映射之后，每个块得到的都是这样的二值对，这样可以以词项ID为主键，以文档ID为次键按照快速排序一类方法进行排序，这样使得倒排记录的构建变得简单。     &lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;内存式单遍扫描索引构建方法&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;BSBI方法需要将词项映射成词项ID，所以必须在内存中维护一个（词项，词项ID）表的数据结构。当对大规模文档来说，这种数据结构的大小将超过内存大小。
SPIMI（single-pass in-memory indexing,内存式单遍扫描索引构建算法）使用词项而不是词项ID作为词典，它将为个块的词典读入磁盘，对于下一个块则采用新的词典。只要硬盘空间足够大，SPIMI就能够索引任何大小的文档集。     &lt;/p&gt;

&lt;p&gt;SPIMI算法流程如下所示：      &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;c&quot;&gt;&lt;span class=&quot;lineno&quot;&gt; 1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SPIMI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Invert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      
&lt;span class=&quot;lineno&quot;&gt; 2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NewFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;     
&lt;span class=&quot;lineno&quot;&gt; 3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NewHash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;      
&lt;span class=&quot;lineno&quot;&gt; 4&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;free&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;        
&lt;span class=&quot;lineno&quot;&gt; 5&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      
&lt;span class=&quot;lineno&quot;&gt; 6&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;        
&lt;span class=&quot;lineno&quot;&gt; 7&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;then&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;posting_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AddToDictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;     
&lt;span class=&quot;lineno&quot;&gt; 8&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;posting_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GetPostingList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;      
&lt;span class=&quot;lineno&quot;&gt; 9&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;posting_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;       
&lt;span class=&quot;lineno&quot;&gt;10&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;then&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;posting_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DoublePostingList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;       
&lt;span class=&quot;lineno&quot;&gt;11&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;AddToPostingList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;posting_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dicID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;     
&lt;span class=&quot;lineno&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sorted_term&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SortTerms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;        
&lt;span class=&quot;lineno&quot;&gt;13&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WriteBlockToDisk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sorted_term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;        
&lt;span class=&quot;lineno&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_file&lt;/span&gt;      
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;bsbispimi&quot;&gt;BSBI和SPIMI的区别&lt;/h4&gt;
&lt;p&gt;BSBI在读入一块内存中的文档内容时，会构建这块文档的词项ID—文档ID对序列，在对序列进行排序后，构建这块文档的倒排索引表，也就是说倒排索引的构建是对读入的整个文件块这个整体。SPIMI当然也是将初始大规模文档划分成等大小的块，并按块读入内存，新建一个初始为空的字典，首先他直接以词项作为词典单位，也就是说在遍历内存中的文档时，对文档进行词条话和词干化后，查看每个词，如果这个词不再字典中，则将词加如词典中，并新建一个关于此词项的倒排记录表，如果词项在字典中存在，则需要在此词项的到拍记录表的基础上进行添加操作。由于实现并不清楚每个词项的倒排记录表的长度，所以初始设定倒排记录表的长度为某个较小的值，当倒排记录表已满时，可以按倍数进行扩展。&lt;/p&gt;

&lt;p&gt;SPIMI的倒排记录表是动态增长的，同时立刻就可以实现全体倒排记录表的收集。这样做有两个好处： &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;由于不需要排序操作，所以处理的速度更快。  &lt;/li&gt;
  &lt;li&gt;由于保留了倒排记录表对词项的归属关系，因此能够节省内存，词项的ID也不需要保存。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SPIMI算法的时间负责度是O（T），因为它不需要对词项ID-文档ID排序，所以操作最多和文档集大小成线性关系。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;分布式索引构建方法&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;实际中，文档集合一般相当大，一台计算机很难实现高效的实现索引构建。尤其是对于万维网来说。因此Web搜索引擎通常使用分布式索引构建（distribuction index）算法来构建索引，其索引结果也是分布式的，它往往按照词项或是文档分割后分布在多台计算机上。   &lt;/p&gt;

&lt;p&gt;这里介绍的分布式索引构建方法是MapReduce的一个应用。MapReduce是一个分布式的计算框架，它面向大规模计算机集群而设计。集群中有一个主控节点（master node）,主要负责任务在工作节点的分配和重分配。重分配是实现分布式框架的鲁棒性，因为集群在工作当中，可能工作节点会出现故障，这个时候主节点应当能识别这些故障并将故障机器的任务重新分配给其它可工作的工作节点。    &lt;/p&gt;

&lt;p&gt;一般来说MapReduce会通过键-值对（Key-Value pair）的转换处理，将一个大型的计算问题转换成较小的子问题。在索引构建中，键-值对就是（词项ID,文档ID）。在分布式索引构建中，词项到词项ID的映射同样要分布式进行，因此分布式的索引构建方法要比单机上的索引构建方法复杂的多。一种简单方法就是维护一张高频词到其ID的映射表，并将它复制到所有节点的计算机上，而对低频词则直接使用词项本身。&lt;/p&gt;

&lt;p&gt;MapReduce的Map过程将输入的数据片映射成键值对，这个映射过程对英语BSBI和SPIMI算法中的分析任务，执行Map过程的机器也称之为分析器（parser）。每个分析器将输出结果保存在本地的中间文件。&lt;/p&gt;

&lt;p&gt;Reduce主要是对中间结果进行合并，形成最终的索引。对每个词项（键值），获取此词项的所有文档集合并构建词项的倒排记录表主要通过倒排器来实现。   &lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;动态索引构建方法&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;上述建立索引的方法都是基于静态文档的，在很多情况下，文档都会随着时间动态变化的。那么，当文档更新速度很慢时，我们可以采用定期更新索引的策略。如果文档更新速度很快时，则实时更新索引的方法将十分耗时。&lt;/p&gt;

&lt;p&gt;可以采用如下方法实现动态索引的构建，这里我们主要维护两个索引，第一个主索引是对初始的文档集构建的索引，第二个辅助索引是在主索引建立之后随着时间推移，而更新的索引，辅助索引存放在内存中，这样实时检索时通过查询主索引和辅助索引实现。如果是对主索引在未来时间的更新，可以通过一个无效位向量实现，用无效位向量来标致文档的删除，同时在辅助索引中加入此文档的更新，便实现了主索引内容的更新。同时随着时间的推移，辅助索引的容量是不断增大的。当辅助索引长度大一某一值时，我们可以将辅助索引并入到主索引中。&lt;/p&gt;

&lt;p&gt;将辅助索引并入主索引的开销主要取决于索引为文件中的存储方式。如果将每个词项对应的倒排记录表存储为一个文件，则此词项的辅助索引和主索引的合并通过简单的将辅助索引扩展到主索引的倒排记录表即可。显示情况是因为文件管理的各种限制，将所有词项的倒排记录表分别存储为文件是不可行的。替代方案是将所有词项的倒排记录表存储为一个大的文件。&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/index-construction/&quot;&gt;索引构建&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 24, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[词典及容错式检索]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/dic-and-fault-tolerance-retrieve/" />
  <id>http://jwchennlp.github.com/dic-and-fault-tolerance-retrieve</id>
  <updated>2014-04-22T00:00:00-00:00</updated>
  <published>2014-04-22T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;section&quot;&gt;词典搜索的数据结构&lt;/h2&gt;

&lt;p&gt;在给定倒排索引和查询，首要任务是确定查询中的各个查询词是否在词汇表中，如果在则返回该词所对应的倒排记录表的指针。词汇表的查找操作通常采用一种称之为词典的数据结构，主要有两种解决方案：&lt;strong&gt;哈希表方式&lt;/strong&gt;和&lt;strong&gt;搜索树方式&lt;/strong&gt;。通常在选择选用何种解决方式时，我们需要考虑如下问题：                       &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;关键字的数目    &lt;/li&gt;
  &lt;li&gt;关键字的数目是经常变化还是相对固定，在变化的情况下，是只插入新关键字还是同时要删除某些旧关键字。  &lt;/li&gt;
  &lt;li&gt;不同关键字的相对访问频率如何。   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于哈希表，词汇表中的每个词通过哈希函数映射成一个数，可以认为这个数代表这个词的存储地址。所以对于query里面的查询词来说，同样通过哈希函数应查看查询词映射到的地址，如果此地址存在数，则表示该查询词存在词典中。采用哈希表方式时，存在以下问题：          &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;哈希函数的空间要足够大，并且不易扩展。哈希函数必须要有足够大的空间来               存储字典，同时它的空间很难实时扩展，如需扩展，需要更改哈希映射函数，使得整个数据结构都发生变化。 &lt;/li&gt;
  &lt;li&gt;冲突问题的解决，因为哈希函数可能使得两个不同的词映射到统一地址，如何减少映射冲突也是一个要考虑的问题。   &lt;/li&gt;
  &lt;li&gt;哈希表方式很难解决前缀式查询，因为在不知道整体词的情况下，哈希映射函数是失效的。  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;搜索树可以很好的解决上述问题，它支持前缀式查询。最出名的搜索树是二叉树，每个内部节点都有两个字节点。在二叉树中搜索词要从根节点开始，每个内部节点代表一个二值测试，测试的结果用于确定下一步应该搜索的子树。二叉树的平衡性是实现高效搜索的关键，，平衡二叉树指的是任何节点的两个子树的高度相差小于等于1.下图为一个二叉树表示的词典的例子。为了实现搜索树的平衡性，我们必须在加入增加或删除节点时对树进行处理以保持树的平衡性，这里用B-树实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/binary-tree.png&quot; alt=&quot;image&quot; /&gt;   	&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;通配符查询&lt;/h2&gt;

&lt;p&gt;通配符通常用于以下情形：  &lt;br /&gt;
1. 用户不确定查询查询词的拼写。 &lt;br /&gt;
2. 用户知道某个查询词项可能有不同的拼写版本，并且要把包含这些版本的文档都查找出来。       &lt;br /&gt;
3. 用户查找某个查询词项的所有变形，这些词项还做了词干还原，但是用户并不知道搜索引擎是否做了词干还原。  &lt;br /&gt;
4. 用户不确定一个外来词或者短语的正确拼写形式。   &lt;/p&gt;

&lt;p&gt;当通配符出现在一个查询词的尾部时，如ca&lt;em&gt;，则是需要查找词典中所有词前两个字母是ca的所有词的文档。我们可以通过搜索树来实现这一查找，在搜索树的根（root）节点,首先我们确定首字母为c所指定的分支，而后在以分支作为搜索树查询a所对应的分支，这样这个分支下的所有单词都为符号ca&lt;/em&gt;查询的单词。   &lt;br /&gt;
然后，当通配符出现在词的首部时，如&lt;em&gt;ay,需要查找词典中后两个字母是ay的所有词项，显然用之前的搜索树不能实现这一查询。这里我们可以引入词典的反向B-树结构。前面的词典的B-树的构建是从词项的首字母开始，接着词的第二个字母知道最后一个字母构建B-树。反向B-树恰恰相反，它是从词典的尾字母开始，依次到倒数第二个字母直到第一个字母构建B-树。这样的反向B-树便能匹配通配符出现在词首部的查询。
那么对于通配符出现在查询词中间的查询，如t&lt;/em&gt;o,我们可以采用如下策略，首先用构建的B-树查找t&lt;em&gt;的所有词，而后采用构建的反向B-树查找符合&lt;/em&gt;o的所有词，最后两个查询的词求交集便是所查找的词。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;轮排索引&lt;/h3&gt;
&lt;p&gt;轮排索引是一种用于一般通配符查询的索引，它是倒排索引的一种特殊方式。它的工作原理为，首先引入一终结符$，对词项集合中的每个词在其末尾增加$符号。如词项hello扩展成hello$,随后我们需要按如下方式建立词的轮排索引，对词hello$连续进行首位翻转，将出现的所有形式记录的集合称之为轮排词汇表。hello$的轮排索引如图所示: &lt;br /&gt;
&lt;img src=&quot;../images/permutern-index.png&quot; alt=&quot;image&quot; /&gt;   &lt;br /&gt;
那么如何用轮排索引实现通配符查询呢，由上图我们知道轮排索引中的任何一个状态都指向词项hello，也就是说ello$h或者llo$he的查询过程都会通过轮排索引指向词项hello的查询过程。所以例如查询通配符h&lt;em&gt;llo,处理的关键是将通配符&lt;/em&gt;移动到词的尾部，将h&lt;em&gt;llo转换成h&lt;/em&gt;llo$,接着进行翻转得到llo$h&lt;em&gt;,接着在轮排索引中查找该字符串，我们发现llo$h&lt;/em&gt;与hello词的轮排索引中的llo$he一致，所以hello是满足条件的查询结果。     &lt;br /&gt;
对于查询中存在多个通配符的情况，如查询（fi&lt;em&gt;mo&lt;/em&gt;er）,我们可以按如下方式进行处理，首先查找er$fi*的所有结果，接着可以通过穷举法过滤出包含mo的词，这些词便是符合通配符查询的结果。 &lt;/p&gt;

&lt;h3 id=&quot;k-gram&quot;&gt;支持通配符查询的k-gram索引&lt;/h3&gt;
&lt;p&gt;上面介绍的轮排索引结构简单，但是在构建轮排索引的过程中，我们需要对词进行旋转并记录所有旋转的结果，这会引起存储空间的急剧增加。     &lt;/p&gt;

&lt;p&gt;k-gram索引是如下的倒排索引机制，它将原始词典中的所有词项进行拆分，每个词项都拆分成若干个长度为k的新的词项，并根据这些新的词项构建倒排索引，如happy按照3-gram拆分成的新词词项有$ha,hap,app,ppy,py$,这里用$来对词的开始和结束进行标记。这里倒排索引的构建方式与第一章提到的略微不同，之前的倒排索引是词典是文档中经过词条化和语言话处理的所有词，而倒排记录表是这些词所出现的文档。而这里词典则是文档中的所有词根据k-gram拆分的所有新词，倒排记录表这是包含这些长度为k的新词的原始词。如3-gram的新词etr对应的倒排记录表为,词项为etr，倒排记录表为所有包含etr的词：    &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/k-gram-index.png&quot; alt=&quot;image&quot; /&gt;    &lt;/p&gt;

&lt;p&gt;那么k-gram是如何实现通配符查询的呢，如查询he&lt;em&gt;lo,是要查询首字符为he，尾字符为lo的所有词，根据3-gram索引，我们可以够找如下的布尔查询$heANDlo$,则3-gram的查询词便是所期望的
结果。k-gram索引有时也会导致非预期的结果，如查询red&lt;/em&gt;,根据3-gram索引构建的布尔查询为$reANDred,其返回结果可能包含retired，但显然这个词并不符合初始期望。为了解决这一问题，我们可以引入一个后过滤的步骤，实现方式很简单，用初始的查询词与返回的词进行匹配，那些成功匹配的词便是符合要求的词。&lt;br /&gt;
通配符查找往往是非常耗时的，对于单个通配符查询，我们可能要构建轮排索引或者k-gram索引来返回中间结果，并且对这中间结果要求交集来返回确切的要查找的词，最后才依据这些词通过倒排索引来查找这些词所对应的文档。    &lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;拼写校正&lt;/h2&gt;
&lt;p&gt;拼写校正是在用户输入某个查询词或查询短语时，用户能识别其中词的拼写错误并返回正确词的查询结果。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;拼写校正的实现&lt;/h3&gt;

&lt;p&gt;对于大多数拼写校正算法而言，有以下两条基本规则：        &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对于一个错误拼写的查询中，则需要在其所有正确的拼写中，返回最近的正确拼写的查询。&lt;/li&gt;
  &lt;li&gt;当两个正确拼写查询临近度相等时，则需要返回更常见的那个正确查询。更常见可以通过以下两个方式衡量，可以统计文档集合中两个查询出现的次数，出现次数高的标记为“更常见”。也可以统计用户查询日志中两个查询的出现次数，出现次数更高的标记为”更常见”。  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-5&quot;&gt;拼写校正的方法&lt;/h3&gt;
&lt;p&gt;词独立校正:不管查询是单个词还是多个词构成的短语，对查询的词的拼写校正是独立进行的，也就是说是上下文独立的，即某个词是否校正与上下文语境没有关联。校正方法主要有编辑距离方法和k-gram重合度方法。 &lt;br /&gt;
上下文敏感校正:则是在校正过程中，会根据上下文信息来决定词的校正。&lt;/p&gt;

&lt;h4 id=&quot;section-6&quot;&gt;编辑距离&lt;/h4&gt;

&lt;p&gt;给定两个字符串S1和S2，两者的编辑距离定义为由S1转换成S2的最小编辑操作数。通常这些编辑操作包括：     &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将一个字符插入字符串   &lt;/li&gt;
  &lt;li&gt;将一个字符从字符串中删除  &lt;/li&gt;
  &lt;li&gt;将字符串中的一个字符替换成另一个字符    &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以在O(S1*S2）的时间复杂度下计算S1和S2之间的编辑距离，主要方法是采用动态规划的思想（类似于动态规划中的求最长公共子串问题），其中S1和S2以字符数组方式进行存放。整数矩阵m的行数和列书分表代表两个字符串的长度，算法在运行过程中不断填写矩阵元素。例如，在算法结束时，m[i,j]表示S1的前i个字符和S2的前j个字符的编辑距离。其代码实现如下：&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt; 
       
&lt;span class=&quot;n&quot;&gt;EditDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;—&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      
&lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;       
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;—&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      
&lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;—&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      
&lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;—&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;       
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;       
        &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;       
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;       
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;        
&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;加入对于某个拼写错误查询q，我们需要从词典W中找出与q相邻最近的正确词项，最简单的方法是便利W中的所有词项wi，计算wi和q之间的编辑距离，最后返回和q最近编辑距离的词项wi，并返回wi所指向的文档。很显然，这种遍历的方法是十分低效的，我们可以采用如下的启发式优化策略，我们将搜索限定在首字母相同的词典词项上，对于查询q，我们认为错误不出现在首字符上，这样对于词典W，我们只计算与q有相同首字符的词项与q之间的编辑距离。当然在此基础上更复杂的方法是加入轮排索引，对于词错误拼写查询helo，忽略词的终结符$,构建词的轮排索引{helo，ohel，lohe，eloh}，对轮排索引中的每个词，按照上述的启发式规则与词典W中查找最近编辑距离的正确拼写。（个人理解）&lt;/p&gt;

&lt;h4 id=&quot;k-gram-1&quot;&gt;拼写校正中的k-gram索引&lt;/h4&gt;

&lt;p&gt;对与某一个错误拼写查询，我们可以根据之前的构建k-gram索引来实现拼写校正，过程如下：
对于错误的拼写单词，我们可以将此单词拆分成长度为k的多个字符串，并查找这些字符串所对应的倒排索引表，这些倒排索引表分别表示包含这些字符串的拼写正确的单词，这里我们认为，只要一个单词在在写倒排索引表中出现次数超过某一阀值m，则认为这个词是原错误拼写的正确拼写结果。例如错误拼写bord，其2-gram索引拆分成的新词有{$b,bo,or,rd,d$},这里去除词$b和d$,从文档集合中查找bo，or，rd对应的倒排记录表，如下所示：    &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/sc-k-gram-index.png&quot; alt=&quot;image&quot; /&gt; &lt;/p&gt;

&lt;p&gt;随后，我们只要遍历这些倒排记录表，找到那些在倒排记录表中出现次数高的词，便是正确的拼写词。k-gram索引的缺点像boardroom这种不可能是bord的正确拼写形式的词也会被检索出来。所以我们需要计算词汇表中词项与查询q之间的更精确的重合度计算方法。可以采用雅可比系数对先前的线性扫描合并方法进行修正。雅可比系数的计算公式是length(AandB)/length(AorB)，其中A和B分别表示查询q和词汇表词项中的k-gram集合。当扫描到词t时，计算出q和t的雅可比系数，如果系数大于某一阀值，则将词t返回。
采用雅可比系数进行验证的时候，我们需要知道q和t的k-gram索引，首先q的k-gram索引是已知的，那么在验证的过程中我们需要遍历所有q的k-gram索引中出现的词t的k-gram索引，如果穷举词t的k-gram索引是个缓慢的过程。我们可以通过一下方式来进行简化处理，当我们知道词t的长度时，可以认为他的k-gram长度为length(t)-k+1,这样能快速计算出雅可比系数。&lt;/p&gt;

&lt;h4 id=&quot;section-7&quot;&gt;上下文敏感的拼写校正&lt;/h4&gt;

&lt;p&gt;当查询的短语中每个单词都是正确的单词，但是返回的查询结果很少时，我们可以认为单词中存在拼写错误，并对其中的单词查找其正确的拼写结果，并返回修正后的短语的查询结果。当采用这种穷举法对词语中的词进行拼写校正时，工作量大，效率低。这时可以采用启发式的方法通过用户的查询日志来统计最有查询短语拼写校正后最有可能出现的短语。&lt;/p&gt;

&lt;h4 id=&quot;section-8&quot;&gt;参考资料&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://www.google.com.hk/search?q=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;oq=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;aqs=chrome..69i57j69i65j69i61l3j0.3218j0j1&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;信息检索导论-词典及容错式检索&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;说明：&lt;/strong&gt;文章主要内容和图片来自信息检索导论一书。&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/dic-and-fault-tolerance-retrieve/&quot;&gt;词典及容错式检索&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 22, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[词典和倒排记录表的建立]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/ir-dic-inverted-index/" />
  <id>http://jwchennlp.github.com/ir-dic-inverted-index</id>
  <published>2014-04-18T00:00:00-04:00</published>
  <updated>2014-04-18T00:00:00-04:00</updated>
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;建立倒排索引的过程可概括为:&lt;br /&gt;
* 收集用于建立索引的文档&lt;br /&gt;
* 词条化&lt;br /&gt;
* 对词条进行处理,得到词项&lt;br /&gt;
* 根据词项和文档建立索引  &lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;文档单位的选择&lt;/h4&gt;
&lt;p&gt;在收集索引文档的过程中,会比较直观的理解每篇文档是便是用于建立索引的索引单位.但很多情况下并非如此,如传统的Unix文件系统将某个目录下的文件都放在一个文件中,我们更倾向以对每个邮件建立一个文档索引,其中邮件中存在附件时,我们希望将附件解压缩并将解压缩文件中的每个文件作为文档建立索引.所以,对收集的文档集合我们应该确定用于建立索引的最小单位(文档).
在长文档中,更一般的说法是存在一个&lt;strong&gt;“索引粒度”&lt;/strong&gt;的问题,对一个书库而言,将一本书当作索引单位(文档)效果会很不理想.例如,查询query是”chinese toys”,那么可能返回这样一本书,第一章中出现”chinese”,最后一章中出现”toys”词,但是这本书跟query的相关性应该是很低的.所以,一个比较可取的方法是对书的每一章或每一段看作文档来建立索引,这样的匹配结果会跟query更相关.当然,索引粒度也不是越小越好,比如,如果我们以句子作为索引单位时,可能要查找的query的分布在几个句子中,这样这几个句子形成的段落是比较相关的结果.这种细粒度的索引会使得准确率升高而召回率降低,索引粒度太效果相反.所以为了权衡召回率和准确率,我们应该设选择合理的索引粒度.&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;词条化&lt;/h4&gt;
&lt;p&gt;词条化主要是将文档中的字符序列才分成一系列子序列的过程,其中每个子序列称之为(token).在这个过程中会进行一系列特殊处理,如删除标点符号等. &lt;br /&gt;
&lt;code&gt;
      输入: I hava a dream,become a good programer!       
      输出: I have a dream become a good programer
&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;词条指的是文档集合中出现的字符序列的实例,词条类是指相同词条构成的集合.  &lt;/li&gt;
  &lt;li&gt;词项指的是在信息检索系统词典中所包含的某个经过归一化处理的词条类&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;词项集合和词条集合可以完全不同,例如词条集合是篮球,足球一类的词汇,此类词条集合的词项可以表示为体育.在实际的信息检索系统中,词项往往和词条密切相关.但是,词项未必就是原始的词条,实际上它往往需要对词条进行归一化处理来得到.&lt;/p&gt;

&lt;p&gt;词条化的主要任务是确定哪些才是正确的词条.在英文文档中,大多是简单的按空格将字符序列进行划分生成词条.可是在有些情况处理会变得复杂,如应为中的上撇号”’“,它可以用来代表所有关系,也有用来代表缩写.如:&lt;br /&gt;
&lt;code&gt;
		Mr.O'Neill thinks that the boy's stories about the Chile's capital aren't amusing.  
&lt;/code&gt;
对于O’Neill来说,词条化结果可以是:{neil},{oneill},{o’neill},{o’,neil},{o,neil}.   &lt;br /&gt;
这里就需要采用词条化工具来对这类情况进行字符序列的词条化,应该注意的是,&lt;strong&gt;对query的词条化处理和对文档集合的词条化处理应该采用相同的机制&lt;/strong&gt;.  &lt;/p&gt;

&lt;p&gt;在进行词条化的时候要考虑”C++”,”C#”等一类的特定领域词,”New York”,”Los Angle”名称词,新出现的词或连字符连接的词.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;停用词:&lt;/strong&gt;指的是在文档中出现频率高,但是与文档主题关系不大的词.在某些情况下,停用词在文档和用户query进行匹配时价值不大,可以用词汇表中去除.&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;词条归一化&lt;/h4&gt;
&lt;p&gt;词条归一化(token normalization)是指将看起来不完全一致,但表述意思相近的多个词条归纳成一个等价类,以便在它们之间进行匹配的过程.主要有以下两种方法:  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;隐式的建立等价类:例如,采用去掉链接字符的映射规则来建立等价类,将moto-car和motocar映射成词项motocar,这样,对任何一个词进行查询,都会返回包含另一个词的文档.  &lt;/li&gt;
  &lt;li&gt;维护多个非归一化词条之间的关联关系,可以进一步扩展为构建同义词词表的手工构建.比如将car和automobile归为同义词.有以下两种方法: &lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;采用非归一化的词条建立索引,并为某个查询词项维护一个有多个词组成的查询扩展词表.当输入一个查询词项时,则根据扩展词表进行扩展并将扩展后得到的所有词的倒排记录表进行合并.   &lt;/li&gt;
      &lt;li&gt;在索引构建时就对词进行扩展.比如对于包含automobile的文档(文档中不包括词car),正常只建立automobile的索引,此时需要同时建立
  automobilt和car的索引.第一种方法需要维护一个词的扩展词表,在查询时需要访问该词表,更耗时.第二个则实在建立索引时便已经构建扩展词表的索引,更好空间.   &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-3&quot;&gt;词干还原和词形归并&lt;/h4&gt;
&lt;p&gt;词干还原和词形归并是为了减少词的曲折变化的形式，并且有时候会将派生词转化成基本形式。因为在语法中，有些词在不同的语境中包含不同的形态，如origanize，oraginizes，originizing。同时语言中也存在大量的同源词，如democracy，democratic，democratization。那么，在检索过程同，如果根据搜索词返回其同源词的文档，能返回更多相关的结果。	
&lt;strong&gt;词干还原&lt;/strong&gt;通常是用启发式的规则对词两端的词缀进行粗略进行处理的过程。&lt;strong&gt;词形归并&lt;/strong&gt;通常是利用词汇表和词形分析来去除屈折词缀，从而返回词的原型或词典中的词的过程，返回的结果称为词元。两者的&lt;em&gt;区别&lt;/em&gt;还在于：词干还原一般情况下会将多个派生相关词合并在一起，词形归并通常只将同一词元的不同曲折形式进行合并。	&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;基于跳表的倒排记录表快速合并算法&lt;/h3&gt;
&lt;p&gt;我们知道，初始的最两个排序好的倒排记录表进行合并（求交集）时，只要维护倒排记录表的指针，并遍历两个表，时间复杂度为O（m+n），（m，n为表的长度）。
跳表的主要思想时，我们在表中加入一些位置加入一些跳表指针，这样在比较的过程中可以考虑是否从当前的条表指针直接跳到下一个跳表指针，忽略中间的那些倒排记录。这里需要考虑的问题是条表步长的问题（相邻条表指针间元素个数），步长短，则所需的存储空间大，能通过跳转指针进行跳转的机会变大。步长长，所需存储空间小，在遍历过程中进行跳转的几率小。主要以空间换取时间来提高合并效率。		&lt;/p&gt;

&lt;p&gt;索引相对固定时，建立有效的跳表比较固定。但是如果倒排记录表由于经常更新而发生变化，那么条表指针的建立比较困难。		&lt;/p&gt;

&lt;h4 id=&quot;section-5&quot;&gt;处理短语查询&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;二元词索引&lt;/strong&gt;是将检索短语且分成相邻两个词的元组，并对这些元组当做词项进行检索，将所有词项检索所的结果通过布尔查询的与操作获取结果。如：		
&lt;code&gt;
	短语：$w_1$,$w_2$,...,$w_m$	
	二元词词项：$w_1$$w_2$,$w_2$$W_3$,...,$w_m-1$$w_m$	
&lt;/code&gt;
其实，在检索过程中，用名词或名词短语来表示用户查询的概念具有相当特殊的地位。但是相关的名词往往被各种虚词隔开，所以在处理短语查询时，可以先对短语进行词条化，之后再进行词性标注，这样在对里面的名词按照二元词索引的思想来查找结果。	&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;位置信息索引&lt;/strong&gt;,采用位置信息索引时，需要建立每个文档中的每个词在文档中出现的位置的索引。词wi在dj中的倒排索引可以表述为：		
&lt;code&gt;
	文档dj：（位置1,位置2,....）
&lt;/code&gt;
那么利用位置信息索引如何实现短语查询呢？对于相邻的两个词，我们首先计算出他们的倒排记录表并进行合并，对合并的结果进行如下处理，对结果中的每一个文档，我们需要查找两个词在文档中的位置索引表，如果两个词各自的位置索引表中存在两个词的位置也是相邻的并且次序准确的话（计算词之间的偏移距离），这这个文档符合要求。如此往复便能得到结果。		
采用位置索引会增加存储空间，并且会使倒排记录表的合并复杂性增加。	&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;混合索引机制&lt;/strong&gt;，对有些查询使用二元词索引，而对其它短语查询使用位置信息索引。二元词索引中的短语可以根据用户日志统计得出。处理开销最大的短语往往是这样的短语，短语中的每个词在文档中十分常见，但是组合起来却很少见。	&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考资料&lt;/strong&gt;		
&lt;a href=&quot;https://www.google.com.hk/search?q=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;oq=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;aqs=chrome..69i57j69i65j69i61l3j0.3218j0j1&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;信息检索-词项词典及倒排索引表&lt;/a&gt;		&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/ir-dic-inverted-index/&quot;&gt;词典和倒排记录表的建立&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 18, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[IR 倒排索引和布尔查询]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/ir-inverted-index/" />
  <id>http://jwchennlp.github.com/ir-inverted-index</id>
  <updated>2014-04-16T00:00:00-00:00</updated>
  <published>2014-04-16T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;&lt;strong&gt;信息检索&lt;/strong&gt;的定义是从大规模非结构化数据(通常为文本)的集合中找出满足用户需求的资料(通常是文档)的过程.
检索的过程可理解为用户输入query,从文档集合中找出与query相关的文档并展示.最简单的检索方式是线性查询,根据query遍历所有的文档集合,	查找出那些文档集合与query是相关的.这种方式存在以下问题:                                                                  &lt;br /&gt;
  1. 文档规模很大时,对所有文档的遍历查找是个费时的过程&lt;br /&gt;
  2. 不能满足灵活匹配方式的要求(如两个词在同一句话中出现).&lt;br /&gt;
  3. 无法对结果进行排序.检索结果应该按照相关性等需求返回最佳答案.  &lt;/p&gt;

&lt;p&gt;可以采用如下方法替代线性扫描方式,对于所有的文档集合,构建一个词项-文档的矩阵,其中词项表示文档集合中的所有词列表,
文档表示所有集合中的文档,矩阵中的元素M(i,j)则表示词i是否在文档j中出现(M(i,j)为1时表示出现).矩阵的每一行表示词在文档集合中的出现情况,矩阵的没一列表示相应的文档中的词的集合.这样当检索query的时候,只需要根据query中的词在矩阵中查找词在文档中的出现情况,最后进行结果合并便可的出结果.&lt;/p&gt;

&lt;p&gt;上述方法相对现行扫描在时间效率上有了很大提升.如果文档集合有1000万,文档集合的词集合有50万个,则需要维护一个50万*1000万的矩阵,		真实情况是这个矩阵会非常洗漱,因为一篇文档只包含50万词表中的少数词,同时一个词只在少数的文档中出现.而我们关心的只是M(i,j)不为0的元素.采用只存储词项-文档矩阵中元素不为0的数据结构效果会更好.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;倒排索引&lt;/strong&gt;是一种索引方法,被用来存储在全文搜索下某个单词在一个文档或一组文档中的存储位置的映射.
假设有三个检索文本:   &lt;br /&gt;
* $T_0$=”it is what it is”&lt;br /&gt;
* $T_1$=”what is it”    &lt;br /&gt;
* $T_2$=”it is a banana” &lt;br /&gt;
根据以上文档当初的到拍索引为:   &lt;/p&gt;

&lt;p&gt;```
 “a”:      {2}    &lt;/p&gt;

&lt;p&gt;“banana”: {2}   &lt;/p&gt;

&lt;p&gt;“is”:     {0, 1, 2}    &lt;/p&gt;

&lt;p&gt;“it”:     {0, 1, 2}  &lt;br /&gt;
```   &lt;/p&gt;

&lt;p&gt;倒排索引的建立规则如下,首先要建立词典,词典中的词为文档中词的集合,对于词典中的每个词都有一个记录该词在文档中的出现列表,这个表成为倒排记录.倒排索引的词典部分存放在内存中,而每个词指向的倒排记录表存放在词典中.&lt;/p&gt;

&lt;p&gt;**用倒排索引和基本布尔检索模型来处理一个查询 **
一般的检索的query由若干个词组成,可以用基本的布尔查询(与,或,非)在连接这些词.
对于查询 word1 And word2
其检索过程如下:
  * 在词典中定位world1
  * 返回词word1的倒排记录表
  * 在词典中定位word2
  * 返回词word2的倒排记录表
  * 对倒排记录表求交集,所对应的文档既为结果&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;交集处理:&lt;/strong&gt;对于倒排索引表求交集的过程,可以通过以下方法进行优化&lt;br /&gt;
  * 构建倒排索引时,倒排记录表是有序构建的,如对文档进行编号,,倒排记录表按照文档标号从小到达顺序生成&lt;br /&gt;
  * 在求交集的过程中,对两个倒排记录表分别维护一个指针,当指针所指元素相同时,保留元素并同时指针后移,当指针所指元素不同时,将元素较小指针向后移动,最后保留的元素既为交集,时间复杂度为O($N_1$+$N_2$),N为两个索引记录表的长度.&lt;br /&gt;
  * 对于多个倒排索引表,可以按照倒排记录表的长度从小到大进行处理,优先对两个最短的倒排记录表求交集.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;布尔检索优缺点&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;
  1.布尔检索表达上精确,文档要么满足,要么不满足,可以让用户对返回结果拥有更好的控制力和透明度.
  2.对某些领域信息,布尔检索内部也可以提供排序机制
&lt;strong&gt;缺点:&lt;/strong&gt;
  1.布尔检索不能满足灵活匹配方式的要求.&lt;br /&gt;
  2.采用AND操作符产生的结果正确率高而召回率低,采用OR操作符召回率高而正确率低.&lt;br /&gt;
  3.只记录词项存在文档中存在或不存在,但是我们往往需要累加各种证据来得到文档相关性的可信度.&lt;br /&gt;
  4.布尔模型返回的是一个无序的结果,但是我们往往需要对返回的结果进行排序.  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考资料&lt;/strong&gt;
&lt;a href=&quot;http://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95#.E4.BE.8B.E5.AD.90&quot;&gt;倒排索引-维基百科&lt;/a&gt;
&lt;a href=&quot;https://www.google.com.hk/search?q=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;oq=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;aqs=chrome..69i57j69i65j69i61l3j0.3218j0j1&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;信息检索导论-布尔检索&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/ir-inverted-index/&quot;&gt;IR 倒排索引和布尔查询&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 16, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Sample Post]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/hello-world/" />
  <id>http://jwchennlp.github.com/hello-world</id>
  <updated>2014-04-13T00:00:00-00:00</updated>
  <published>2014-04-13T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;你好，哈尔滨！&lt;/p&gt;

&lt;h2 id=&quot;why&quot;&gt;why&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;怎么感觉有些问题呢    &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;c&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  

&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/hello-world/&quot;&gt;Sample Post&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 13, 2014.&lt;/p&gt;</content>
</entry>

</feed>
