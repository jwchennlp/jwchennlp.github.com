<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">My blog</title>
<generator uri="https://github.com/mojombo/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://jwchennlp.github.com/feed.xml" />
<link rel="alternate" type="text/html" href="http://jwchennlp.github.com" />
<updated>2014-04-23T05:17:59-04:00</updated>
<id>http://jwchennlp.github.com/</id>
<author>
  <name>jwchen</name>
  <uri>http://jwchennlp.github.com/</uri>
  <email>hit1093710417@email.com</email>
</author>


<entry>
  <title type="html"><![CDATA[IR ]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/highlight/" />
  <id>http://jwchennlp.github.com/highlight</id>
  <updated>2014-04-23T00:00:00-00:00</updated>
  <published>2014-04-23T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;whydont-know-why&quot;&gt;why,don’t know why&lt;/h2&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;      
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;        
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;     
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;      
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;      
      
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&quot;why&quot;&gt;why&lt;/h2&gt;
&lt;p&gt;a littlt puzzled&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/highlight/&quot;&gt;IR &lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 23, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[词典及容错式检索]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/dic-and-fault-tolerance-retrieve/" />
  <id>http://jwchennlp.github.com/dic-and-fault-tolerance-retrieve</id>
  <updated>2014-04-22T00:00:00-00:00</updated>
  <published>2014-04-22T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;h2 id=&quot;section&quot;&gt;词典搜索的数据结构&lt;/h2&gt;

&lt;p&gt;在给定倒排索引和查询，首要任务是确定查询中的各个查询词是否在词汇表中，如果在则返回该词所对应的倒排记录表的指针。词汇表的查找操作通常采用一种称之为词典的数据结构，主要有两种解决方案：&lt;strong&gt;哈希表方式&lt;/strong&gt;和&lt;strong&gt;搜索树方式&lt;/strong&gt;。通常在选择选用何种解决方式时，我们需要考虑如下问题：                       &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;关键字的数目    &lt;/li&gt;
  &lt;li&gt;关键字的数目是经常变化还是相对固定，在变化的情况下，是只插入新关键字还是同时要删除某些旧关键字。  &lt;/li&gt;
  &lt;li&gt;不同关键字的相对访问频率如何。   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于哈希表，词汇表中的每个词通过哈希函数映射成一个数，可以认为这个数代表这个词的存储地址。所以对于query里面的查询词来说，同样通过哈希函数应查看查询词映射到的地址，如果此地址存在数，则表示该查询词存在词典中。采用哈希表方式时，存在以下问题：          &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;哈希函数的空间要足够大，并且不易扩展。哈希函数必须要有足够大的空间来               存储字典，同时它的空间很难实时扩展，如需扩展，需要更改哈希映射函数，使得整个数据结构都发生变化。 &lt;/li&gt;
  &lt;li&gt;冲突问题的解决，因为哈希函数可能使得两个不同的词映射到统一地址，如何减少映射冲突也是一个要考虑的问题。   &lt;/li&gt;
  &lt;li&gt;哈希表方式很难解决前缀式查询，因为在不知道整体词的情况下，哈希映射函数是失效的。  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;搜索树可以很好的解决上述问题，它支持前缀式查询。最出名的搜索树是二叉树，每个内部节点都有两个字节点。在二叉树中搜索词要从根节点开始，每个内部节点代表一个二值测试，测试的结果用于确定下一步应该搜索的子树。二叉树的平衡性是实现高效搜索的关键，，平衡二叉树指的是任何节点的两个子树的高度相差小于等于1.下图为一个二叉树表示的词典的例子。为了实现搜索树的平衡性，我们必须在加入增加或删除节点时对树进行处理以保持树的平衡性，这里用B-树实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/binary-tree.png&quot; alt=&quot;image&quot; /&gt;   	&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;通配符查询&lt;/h2&gt;

&lt;p&gt;通配符通常用于以下情形：  &lt;br /&gt;
1. 用户不确定查询查询词的拼写。 &lt;br /&gt;
2. 用户知道某个查询词项可能有不同的拼写版本，并且要把包含这些版本的文档都查找出来。       &lt;br /&gt;
3. 用户查找某个查询词项的所有变形，这些词项还做了词干还原，但是用户并不知道搜索引擎是否做了词干还原。  &lt;br /&gt;
4. 用户不确定一个外来词或者短语的正确拼写形式。   &lt;/p&gt;

&lt;p&gt;当通配符出现在一个查询词的尾部时，如ca&lt;em&gt;，则是需要查找词典中所有词前两个字母是ca的所有词的文档。我们可以通过搜索树来实现这一查找，在搜索树的根（root）节点,首先我们确定首字母为c所指定的分支，而后在以分支作为搜索树查询a所对应的分支，这样这个分支下的所有单词都为符号ca&lt;/em&gt;查询的单词。   &lt;br /&gt;
然后，当通配符出现在词的首部时，如&lt;em&gt;ay,需要查找词典中后两个字母是ay的所有词项，显然用之前的搜索树不能实现这一查询。这里我们可以引入词典的反向B-树结构。前面的词典的B-树的构建是从词项的首字母开始，接着词的第二个字母知道最后一个字母构建B-树。反向B-树恰恰相反，它是从词典的尾字母开始，依次到倒数第二个字母直到第一个字母构建B-树。这样的反向B-树便能匹配通配符出现在词首部的查询。
那么对于通配符出现在查询词中间的查询，如t&lt;/em&gt;o,我们可以采用如下策略，首先用构建的B-树查找t&lt;em&gt;的所有词，而后采用构建的反向B-树查找符合&lt;/em&gt;o的所有词，最后两个查询的词求交集便是所查找的词。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;轮排索引&lt;/h3&gt;
&lt;p&gt;轮排索引是一种用于一般通配符查询的索引，它是倒排索引的一种特殊方式。它的工作原理为，首先引入一终结符$，对词项集合中的每个词在其末尾增加$符号。如词项hello扩展成hello$,随后我们需要按如下方式建立词的轮排索引，对词hello$连续进行首位翻转，将出现的所有形式记录的集合称之为轮排词汇表。hello$的轮排索引如图所示: &lt;br /&gt;
&lt;img src=&quot;../images/permutern-index.png&quot; alt=&quot;image&quot; /&gt;   &lt;br /&gt;
那么如何用轮排索引实现通配符查询呢，由上图我们知道轮排索引中的任何一个状态都指向词项hello，也就是说ello$h或者llo$he的查询过程都会通过轮排索引指向词项hello的查询过程。所以例如查询通配符h&lt;em&gt;llo,处理的关键是将通配符&lt;/em&gt;移动到词的尾部，将h&lt;em&gt;llo转换成h&lt;/em&gt;llo$,接着进行翻转得到llo$h&lt;em&gt;,接着在轮排索引中查找该字符串，我们发现llo$h&lt;/em&gt;与hello词的轮排索引中的llo$he一致，所以hello是满足条件的查询结果。     &lt;br /&gt;
对于查询中存在多个通配符的情况，如查询（fi&lt;em&gt;mo&lt;/em&gt;er）,我们可以按如下方式进行处理，首先查找er$fi*的所有结果，接着可以通过穷举法过滤出包含mo的词，这些词便是符合通配符查询的结果。 &lt;/p&gt;

&lt;h3 id=&quot;k-gram&quot;&gt;支持通配符查询的k-gram索引&lt;/h3&gt;
&lt;p&gt;上面介绍的轮排索引结构简单，但是在构建轮排索引的过程中，我们需要对词进行旋转并记录所有旋转的结果，这会引起存储空间的急剧增加。     &lt;/p&gt;

&lt;p&gt;k-gram索引是如下的倒排索引机制，它将原始词典中的所有词项进行拆分，每个词项都拆分成若干个长度为k的新的词项，并根据这些新的词项构建倒排索引，如happy按照3-gram拆分成的新词词项有$ha,hap,app,ppy,py$,这里用$来对词的开始和结束进行标记。这里倒排索引的构建方式与第一章提到的略微不同，之前的倒排索引是词典是文档中经过词条化和语言话处理的所有词，而倒排记录表是这些词所出现的文档。而这里词典则是文档中的所有词根据k-gram拆分的所有新词，倒排记录表这是包含这些长度为k的新词的原始词。如3-gram的新词etr对应的倒排记录表为,词项为etr，倒排记录表为所有包含etr的词：    &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/k-gram-index.png&quot; alt=&quot;image&quot; /&gt;    &lt;/p&gt;

&lt;p&gt;那么k-gram是如何实现通配符查询的呢，如查询he&lt;em&gt;lo,是要查询首字符为he，尾字符为lo的所有词，根据3-gram索引，我们可以够找如下的布尔查询$heANDlo$,则3-gram的查询词便是所期望的
结果。k-gram索引有时也会导致非预期的结果，如查询red&lt;/em&gt;,根据3-gram索引构建的布尔查询为$reANDred,其返回结果可能包含retired，但显然这个词并不符合初始期望。为了解决这一问题，我们可以引入一个后过滤的步骤，实现方式很简单，用初始的查询词与返回的词进行匹配，那些成功匹配的词便是符合要求的词。&lt;br /&gt;
通配符查找往往是非常耗时的，对于单个通配符查询，我们可能要构建轮排索引或者k-gram索引来返回中间结果，并且对这中间结果要求交集来返回确切的要查找的词，最后才依据这些词通过倒排索引来查找这些词所对应的文档。    &lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;拼写校正&lt;/h2&gt;
&lt;p&gt;拼写校正是在用户输入某个查询词或查询短语时，用户能识别其中词的拼写错误并返回正确词的查询结果。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;拼写校正的实现&lt;/h3&gt;

&lt;p&gt;对于大多数拼写校正算法而言，有以下两条基本规则：        &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对于一个错误拼写的查询中，则需要在其所有正确的拼写中，返回最近的正确拼写的查询。&lt;/li&gt;
  &lt;li&gt;当两个正确拼写查询临近度相等时，则需要返回更常见的那个正确查询。更常见可以通过以下两个方式衡量，可以统计文档集合中两个查询出现的次数，出现次数高的标记为“更常见”。也可以统计用户查询日志中两个查询的出现次数，出现次数更高的标记为”更常见”。  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-5&quot;&gt;拼写校正的方法&lt;/h3&gt;
&lt;p&gt;词独立校正:不管查询是单个词还是多个词构成的短语，对查询的词的拼写校正是独立进行的，也就是说是上下文独立的，即某个词是否校正与上下文语境没有关联。校正方法主要有编辑距离方法和k-gram重合度方法。 &lt;br /&gt;
上下文敏感校正:则是在校正过程中，会根据上下文信息来决定词的校正。&lt;/p&gt;

&lt;h4 id=&quot;section-6&quot;&gt;编辑距离&lt;/h4&gt;

&lt;p&gt;给定两个字符串S1和S2，两者的编辑距离定义为由S1转换成S2的最小编辑操作数。通常这些编辑操作包括：     &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将一个字符插入字符串   &lt;/li&gt;
  &lt;li&gt;将一个字符从字符串中删除  &lt;/li&gt;
  &lt;li&gt;将字符串中的一个字符替换成另一个字符    &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以在O(S1*S2）的时间复杂度下计算S1和S2之间的编辑距离，主要方法是采用动态规划的思想（类似于动态规划中的求最长公共子串问题），其中S1和S2以字符数组方式进行存放。整数矩阵m的行数和列书分表代表两个字符串的长度，算法在运行过程中不断填写矩阵元素。例如，在算法结束时，m[i,j]表示S1的前i个字符和S2的前j个字符的编辑距离。其代码实现如下：&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt; 

&lt;span class=&quot;n&quot;&gt;EditDistance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;—&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      
&lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;       
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;—&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      
&lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;—&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      
&lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;—&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;       
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;       
        &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;       
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;       
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;        
&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;加入对于某个拼写错误查询q，我们需要从词典W中找出与q相邻最近的正确词项，最简单的方法是便利W中的所有词项wi，计算wi和q之间的编辑距离，最后返回和q最近编辑距离的词项wi，并返回wi所指向的文档。很显然，这种遍历的方法是十分低效的，我们可以采用如下的启发式优化策略，我们将搜索限定在首字母相同的词典词项上，对于查询q，我们认为错误不出现在首字符上，这样对于词典W，我们只计算与q有相同首字符的词项与q之间的编辑距离。当然在此基础上更复杂的方法是加入轮排索引，对于词错误拼写查询helo，忽略词的终结符$,构建词的轮排索引{helo，ohel，lohe，eloh}，对轮排索引中的每个词，按照上述的启发式规则与词典W中查找最近编辑距离的正确拼写。（个人理解）&lt;/p&gt;

&lt;h4 id=&quot;k-gram-1&quot;&gt;拼写校正中的k-gram索引&lt;/h4&gt;

&lt;p&gt;对与某一个错误拼写查询，我们可以根据之前的构建k-gram索引来实现拼写校正，过程如下：
对于错误的拼写单词，我们可以将此单词拆分成长度为k的多个字符串，并查找这些字符串所对应的倒排索引表，这些倒排索引表分别表示包含这些字符串的拼写正确的单词，这里我们认为，只要一个单词在在写倒排索引表中出现次数超过某一阀值m，则认为这个词是原错误拼写的正确拼写结果。例如错误拼写bord，其2-gram索引拆分成的新词有{$b,bo,or,rd,d$},这里去除词$b和d$,从文档集合中查找bo，or，rd对应的倒排记录表，如下所示：    &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/sc-k-gram-index.png&quot; alt=&quot;image&quot; /&gt; &lt;/p&gt;

&lt;p&gt;随后，我们只要遍历这些倒排记录表，找到那些在倒排记录表中出现次数高的词，便是正确的拼写词。k-gram索引的缺点像boardroom这种不可能是bord的正确拼写形式的词也会被检索出来。所以我们需要计算词汇表中词项与查询q之间的更精确的重合度计算方法。可以采用雅可比系数对先前的线性扫描合并方法进行修正。雅可比系数的计算公式是length(AandB)/length(AorB)，其中A和B分别表示查询q和词汇表词项中的k-gram集合。当扫描到词t时，计算出q和t的雅可比系数，如果系数大于某一阀值，则将词t返回。
采用雅可比系数进行验证的时候，我们需要知道q和t的k-gram索引，首先q的k-gram索引是已知的，那么在验证的过程中我们需要遍历所有q的k-gram索引中出现的词t的k-gram索引，如果穷举词t的k-gram索引是个缓慢的过程。我们可以通过一下方式来进行简化处理，当我们知道词t的长度时，可以认为他的k-gram长度为length(t)-k+1,这样能快速计算出雅可比系数。&lt;/p&gt;

&lt;h4 id=&quot;section-7&quot;&gt;上下文敏感的拼写校正&lt;/h4&gt;

&lt;p&gt;当查询的短语中每个单词都是正确的单词，但是返回的查询结果很少时，我们可以认为单词中存在拼写错误，并对其中的单词查找其正确的拼写结果，并返回修正后的短语的查询结果。当采用这种穷举法对词语中的词进行拼写校正时，工作量大，效率低。这时可以采用启发式的方法通过用户的查询日志来统计最有查询短语拼写校正后最有可能出现的短语。&lt;/p&gt;

&lt;h4 id=&quot;section-8&quot;&gt;参考资料&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://www.google.com.hk/search?q=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;oq=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;aqs=chrome..69i57j69i65j69i61l3j0.3218j0j1&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;信息检索导论-词典及容错式检索&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;说明：&lt;/strong&gt;文章主要内容和图片来自信息检索导论一书。&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/dic-and-fault-tolerance-retrieve/&quot;&gt;词典及容错式检索&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 22, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[词典和倒排记录表的建立]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/ir-dic-inverted-index/" />
  <id>http://jwchennlp.github.com/ir-dic-inverted-index</id>
  <updated>2014-04-18T00:00:00-00:00</updated>
  <published>2014-04-18T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;建立倒排索引的过程可概括为:&lt;br /&gt;
* 收集用于建立索引的文档&lt;br /&gt;
* 词条化&lt;br /&gt;
* 对词条进行处理,得到词项&lt;br /&gt;
* 根据词项和文档建立索引  &lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;文档单位的选择&lt;/h4&gt;
&lt;p&gt;在收集索引文档的过程中,会比较直观的理解每篇文档是便是用于建立索引的索引单位.但很多情况下并非如此,如传统的Unix文件系统将某个目录下的文件都放在一个文件中,我们更倾向以对每个邮件建立一个文档索引,其中邮件中存在附件时,我们希望将附件解压缩并将解压缩文件中的每个文件作为文档建立索引.所以,对收集的文档集合我们应该确定用于建立索引的最小单位(文档).
在长文档中,更一般的说法是存在一个&lt;strong&gt;“索引粒度”&lt;/strong&gt;的问题,对一个书库而言,将一本书当作索引单位(文档)效果会很不理想.例如,查询query是”chinese toys”,那么可能返回这样一本书,第一章中出现”chinese”,最后一章中出现”toys”词,但是这本书跟query的相关性应该是很低的.所以,一个比较可取的方法是对书的每一章或每一段看作文档来建立索引,这样的匹配结果会跟query更相关.当然,索引粒度也不是越小越好,比如,如果我们以句子作为索引单位时,可能要查找的query的分布在几个句子中,这样这几个句子形成的段落是比较相关的结果.这种细粒度的索引会使得准确率升高而召回率降低,索引粒度太效果相反.所以为了权衡召回率和准确率,我们应该设选择合理的索引粒度.&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;词条化&lt;/h4&gt;
&lt;p&gt;词条化主要是将文档中的字符序列才分成一系列子序列的过程,其中每个子序列称之为(token).在这个过程中会进行一系列特殊处理,如删除标点符号等. &lt;br /&gt;
&lt;code&gt;
      输入: I hava a dream,become a good programer!       
      输出: I have a dream become a good programer
&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;词条指的是文档集合中出现的字符序列的实例,词条类是指相同词条构成的集合.  &lt;/li&gt;
  &lt;li&gt;词项指的是在信息检索系统词典中所包含的某个经过归一化处理的词条类&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;词项集合和词条集合可以完全不同,例如词条集合是篮球,足球一类的词汇,此类词条集合的词项可以表示为体育.在实际的信息检索系统中,词项往往和词条密切相关.但是,词项未必就是原始的词条,实际上它往往需要对词条进行归一化处理来得到.&lt;/p&gt;

&lt;p&gt;词条化的主要任务是确定哪些才是正确的词条.在英文文档中,大多是简单的按空格将字符序列进行划分生成词条.可是在有些情况处理会变得复杂,如应为中的上撇号”’“,它可以用来代表所有关系,也有用来代表缩写.如:&lt;br /&gt;
&lt;code&gt;
		Mr.O'Neill thinks that the boy's stories about the Chile's capital aren't amusing.  
&lt;/code&gt;
对于O’Neill来说,词条化结果可以是:{neil},{oneill},{o’neill},{o’,neil},{o,neil}.   &lt;br /&gt;
这里就需要采用词条化工具来对这类情况进行字符序列的词条化,应该注意的是,&lt;strong&gt;对query的词条化处理和对文档集合的词条化处理应该采用相同的机制&lt;/strong&gt;.  &lt;/p&gt;

&lt;p&gt;在进行词条化的时候要考虑”C++”,”C#”等一类的特定领域词,”New York”,”Los Angle”名称词,新出现的词或连字符连接的词.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;停用词:&lt;/strong&gt;指的是在文档中出现频率高,但是与文档主题关系不大的词.在某些情况下,停用词在文档和用户query进行匹配时价值不大,可以用词汇表中去除.&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;词条归一化&lt;/h4&gt;
&lt;p&gt;词条归一化(token normalization)是指将看起来不完全一致,但表述意思相近的多个词条归纳成一个等价类,以便在它们之间进行匹配的过程.主要有以下两种方法:  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;隐式的建立等价类:例如,采用去掉链接字符的映射规则来建立等价类,将moto-car和motocar映射成词项motocar,这样,对任何一个词进行查询,都会返回包含另一个词的文档.  &lt;/li&gt;
  &lt;li&gt;维护多个非归一化词条之间的关联关系,可以进一步扩展为构建同义词词表的手工构建.比如将car和automobile归为同义词.有以下两种方法: &lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;采用非归一化的词条建立索引,并为某个查询词项维护一个有多个词组成的查询扩展词表.当输入一个查询词项时,则根据扩展词表进行扩展并将扩展后得到的所有词的倒排记录表进行合并.   &lt;/li&gt;
      &lt;li&gt;在索引构建时就对词进行扩展.比如对于包含automobile的文档(文档中不包括词car),正常只建立automobile的索引,此时需要同时建立
  automobilt和car的索引.第一种方法需要维护一个词的扩展词表,在查询时需要访问该词表,更耗时.第二个则实在建立索引时便已经构建扩展词表的索引,更好空间.   &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-3&quot;&gt;词干还原和词形归并&lt;/h4&gt;
&lt;p&gt;词干还原和词形归并是为了减少词的曲折变化的形式，并且有时候会将派生词转化成基本形式。因为在语法中，有些词在不同的语境中包含不同的形态，如origanize，oraginizes，originizing。同时语言中也存在大量的同源词，如democracy，democratic，democratization。那么，在检索过程同，如果根据搜索词返回其同源词的文档，能返回更多相关的结果。	
&lt;strong&gt;词干还原&lt;/strong&gt;通常是用启发式的规则对词两端的词缀进行粗略进行处理的过程。&lt;strong&gt;词形归并&lt;/strong&gt;通常是利用词汇表和词形分析来去除屈折词缀，从而返回词的原型或词典中的词的过程，返回的结果称为词元。两者的&lt;em&gt;区别&lt;/em&gt;还在于：词干还原一般情况下会将多个派生相关词合并在一起，词形归并通常只将同一词元的不同曲折形式进行合并。	&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;基于跳表的倒排记录表快速合并算法&lt;/h3&gt;
&lt;p&gt;我们知道，初始的最两个排序好的倒排记录表进行合并（求交集）时，只要维护倒排记录表的指针，并遍历两个表，时间复杂度为O（m+n），（m，n为表的长度）。
跳表的主要思想时，我们在表中加入一些位置加入一些跳表指针，这样在比较的过程中可以考虑是否从当前的条表指针直接跳到下一个跳表指针，忽略中间的那些倒排记录。这里需要考虑的问题是条表步长的问题（相邻条表指针间元素个数），步长短，则所需的存储空间大，能通过跳转指针进行跳转的机会变大。步长长，所需存储空间小，在遍历过程中进行跳转的几率小。主要以空间换取时间来提高合并效率。		&lt;/p&gt;

&lt;p&gt;索引相对固定时，建立有效的跳表比较固定。但是如果倒排记录表由于经常更新而发生变化，那么条表指针的建立比较困难。		&lt;/p&gt;

&lt;h4 id=&quot;section-5&quot;&gt;处理短语查询&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;二元词索引&lt;/strong&gt;是将检索短语且分成相邻两个词的元组，并对这些元组当做词项进行检索，将所有词项检索所的结果通过布尔查询的与操作获取结果。如：		
&lt;code&gt;
	短语：$w_1$,$w_2$,...,$w_m$	
	二元词词项：$w_1$$w_2$,$w_2$$W_3$,...,$w_m-1$$w_m$	
&lt;/code&gt;
其实，在检索过程中，用名词或名词短语来表示用户查询的概念具有相当特殊的地位。但是相关的名词往往被各种虚词隔开，所以在处理短语查询时，可以先对短语进行词条化，之后再进行词性标注，这样在对里面的名词按照二元词索引的思想来查找结果。	&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;位置信息索引&lt;/strong&gt;,采用位置信息索引时，需要建立每个文档中的每个词在文档中出现的位置的索引。词wi在dj中的倒排索引可以表述为：		
&lt;code&gt;
	文档dj：（位置1,位置2,....）
&lt;/code&gt;
那么利用位置信息索引如何实现短语查询呢？对于相邻的两个词，我们首先计算出他们的倒排记录表并进行合并，对合并的结果进行如下处理，对结果中的每一个文档，我们需要查找两个词在文档中的位置索引表，如果两个词各自的位置索引表中存在两个词的位置也是相邻的并且次序准确的话（计算词之间的偏移距离），这这个文档符合要求。如此往复便能得到结果。		
采用位置索引会增加存储空间，并且会使倒排记录表的合并复杂性增加。	&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;混合索引机制&lt;/strong&gt;，对有些查询使用二元词索引，而对其它短语查询使用位置信息索引。二元词索引中的短语可以根据用户日志统计得出。处理开销最大的短语往往是这样的短语，短语中的每个词在文档中十分常见，但是组合起来却很少见。	&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考资料&lt;/strong&gt;		
&lt;a href=&quot;https://www.google.com.hk/search?q=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;oq=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;aqs=chrome..69i57j69i65j69i61l3j0.3218j0j1&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;信息检索-词项词典及倒排索引表&lt;/a&gt;		&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/ir-dic-inverted-index/&quot;&gt;词典和倒排记录表的建立&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 18, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[IR 倒排索引和布尔查询]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/ir-inverted-index/" />
  <id>http://jwchennlp.github.com/ir-inverted-index</id>
  <updated>2014-04-16T00:00:00-00:00</updated>
  <published>2014-04-16T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;&lt;strong&gt;信息检索&lt;/strong&gt;的定义是从大规模非结构化数据(通常为文本)的集合中找出满足用户需求的资料(通常是文档)的过程.
检索的过程可理解为用户输入query,从文档集合中找出与query相关的文档并展示.最简单的检索方式是线性查询,根据query遍历所有的文档集合,	查找出那些文档集合与query是相关的.这种方式存在以下问题:                                                                  &lt;br /&gt;
  1. 文档规模很大时,对所有文档的遍历查找是个费时的过程&lt;br /&gt;
  2. 不能满足灵活匹配方式的要求(如两个词在同一句话中出现).&lt;br /&gt;
  3. 无法对结果进行排序.检索结果应该按照相关性等需求返回最佳答案.  &lt;/p&gt;

&lt;p&gt;可以采用如下方法替代线性扫描方式,对于所有的文档集合,构建一个词项-文档的矩阵,其中词项表示文档集合中的所有词列表,
文档表示所有集合中的文档,矩阵中的元素M(i,j)则表示词i是否在文档j中出现(M(i,j)为1时表示出现).矩阵的每一行表示词在文档集合中的出现情况,矩阵的没一列表示相应的文档中的词的集合.这样当检索query的时候,只需要根据query中的词在矩阵中查找词在文档中的出现情况,最后进行结果合并便可的出结果.&lt;/p&gt;

&lt;p&gt;上述方法相对现行扫描在时间效率上有了很大提升.如果文档集合有1000万,文档集合的词集合有50万个,则需要维护一个50万*1000万的矩阵,		真实情况是这个矩阵会非常洗漱,因为一篇文档只包含50万词表中的少数词,同时一个词只在少数的文档中出现.而我们关心的只是M(i,j)不为0的元素.采用只存储词项-文档矩阵中元素不为0的数据结构效果会更好.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;倒排索引&lt;/strong&gt;是一种索引方法,被用来存储在全文搜索下某个单词在一个文档或一组文档中的存储位置的映射.
假设有三个检索文本:   &lt;br /&gt;
* $T_0$=”it is what it is”&lt;br /&gt;
* $T_1$=”what is it”    &lt;br /&gt;
* $T_2$=”it is a banana” &lt;br /&gt;
根据以上文档当初的到拍索引为:   &lt;/p&gt;

&lt;p&gt;```
 “a”:      {2}    &lt;/p&gt;

&lt;p&gt;“banana”: {2}   &lt;/p&gt;

&lt;p&gt;“is”:     {0, 1, 2}    &lt;/p&gt;

&lt;p&gt;“it”:     {0, 1, 2}  &lt;br /&gt;
```   &lt;/p&gt;

&lt;p&gt;倒排索引的建立规则如下,首先要建立词典,词典中的词为文档中词的集合,对于词典中的每个词都有一个记录该词在文档中的出现列表,这个表成为倒排记录.倒排索引的词典部分存放在内存中,而每个词指向的倒排记录表存放在词典中.&lt;/p&gt;

&lt;p&gt;**用倒排索引和基本布尔检索模型来处理一个查询 **
一般的检索的query由若干个词组成,可以用基本的布尔查询(与,或,非)在连接这些词.
对于查询 word1 And word2
其检索过程如下:
  * 在词典中定位world1
  * 返回词word1的倒排记录表
  * 在词典中定位word2
  * 返回词word2的倒排记录表
  * 对倒排记录表求交集,所对应的文档既为结果&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;交集处理:&lt;/strong&gt;对于倒排索引表求交集的过程,可以通过以下方法进行优化&lt;br /&gt;
  * 构建倒排索引时,倒排记录表是有序构建的,如对文档进行编号,,倒排记录表按照文档标号从小到达顺序生成&lt;br /&gt;
  * 在求交集的过程中,对两个倒排记录表分别维护一个指针,当指针所指元素相同时,保留元素并同时指针后移,当指针所指元素不同时,将元素较小指针向后移动,最后保留的元素既为交集,时间复杂度为O($N_1$+$N_2$),N为两个索引记录表的长度.&lt;br /&gt;
  * 对于多个倒排索引表,可以按照倒排记录表的长度从小到大进行处理,优先对两个最短的倒排记录表求交集.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;布尔检索优缺点&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;
  1.布尔检索表达上精确,文档要么满足,要么不满足,可以让用户对返回结果拥有更好的控制力和透明度.
  2.对某些领域信息,布尔检索内部也可以提供排序机制
&lt;strong&gt;缺点:&lt;/strong&gt;
  1.布尔检索不能满足灵活匹配方式的要求.&lt;br /&gt;
  2.采用AND操作符产生的结果正确率高而召回率低,采用OR操作符召回率高而正确率低.&lt;br /&gt;
  3.只记录词项存在文档中存在或不存在,但是我们往往需要累加各种证据来得到文档相关性的可信度.&lt;br /&gt;
  4.布尔模型返回的是一个无序的结果,但是我们往往需要对返回的结果进行排序.  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考资料&lt;/strong&gt;
&lt;a href=&quot;http://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95#.E4.BE.8B.E5.AD.90&quot;&gt;倒排索引-维基百科&lt;/a&gt;
&lt;a href=&quot;https://www.google.com.hk/search?q=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;oq=%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%AF%BC%E8%AE%BA&amp;amp;aqs=chrome..69i57j69i65j69i61l3j0.3218j0j1&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;信息检索导论-布尔检索&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/ir-inverted-index/&quot;&gt;IR 倒排索引和布尔查询&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 16, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Sample Post]]></title>
 <link rel="alternate" type="text/html" href="http://jwchennlp.github.com/hello-world/" />
  <id>http://jwchennlp.github.com/hello-world</id>
  <updated>2014-04-13T00:00:00-00:00</updated>
  <published>2014-04-13T00:00:00-04:00</published>
  
  <author>
    <name>jwchen</name>
    <uri>http://jwchennlp.github.com</uri>
    <email>hit1093710417@email.com</email>
  </author>
  <content type="html">&lt;p&gt;你好，哈尔滨！&lt;/p&gt;

&lt;h2 id=&quot;why&quot;&gt;why&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;怎么感觉有些问题呢    &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;c&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  

&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


  &lt;p&gt;&lt;a href=&quot;http://jwchennlp.github.com/hello-world/&quot;&gt;Sample Post&lt;/a&gt; was originally published by jwchen at &lt;a href=&quot;http://jwchennlp.github.com&quot;&gt;My blog&lt;/a&gt; on April 13, 2014.&lt;/p&gt;</content>
</entry>

</feed>
